id,title,abstract,categories,authors,published_date,updated_date,clean_abstract,clean_title,keywords,target
2503.15835v1,BARD-GS: Blur-Aware Reconstruction of Dynamic Scenes via Gaussian Splatting,"3D Gaussian Splatting (3DGS) has shown remarkable potential for static scene
reconstruction, and recent advancements have extended its application to
dynamic scenes. However, the quality of reconstructions depends heavily on
high-quality input images and precise camera poses, which are not that trivial
to fulfill in real-world scenarios. Capturing dynamic scenes with handheld
monocular cameras, for instance, typically involves simultaneous movement of
both the camera and objects within a single exposure. This combined motion
frequently results in image blur that existing methods cannot adequately
handle. To address these challenges, we introduce BARD-GS, a novel approach for
robust dynamic scene reconstruction that effectively handles blurry inputs and
imprecise camera poses. Our method comprises two main components: 1) camera
motion deblurring and 2) object motion deblurring. By explicitly decomposing
motion blur into camera motion blur and object motion blur and modeling them
separately, we achieve significantly improved rendering results in dynamic
regions. In addition, we collect a real-world motion blur dataset of dynamic
scenes to evaluate our approach. Extensive experiments demonstrate that BARD-GS
effectively reconstructs high-quality dynamic scenes under realistic
conditions, significantly outperforming existing methods.",['cs.CV'],"['Yiren Lu', 'Yunlai Zhou', 'Disheng Liu', 'Tuo Liang', 'Yu Yin']",2025-03-20,2025-03-20,3D Gaussian Splatting 3DGS has shown remarkable potential for static scene reconstruction and recent advancements have extended its application to dynamic scenes. However the quality of reconstructions depends heavily on high quality input images and precise camera poses which are not that trivial to fulfill in real world scenarios. Capturing dynamic scenes with handheld monocular cameras for instance typically involves simultaneous movement of both the camera and objects within a single exposure. This combined motion frequently results in image blur that existing methods cannot adequately handle. To address these challenges we introduce BARD GS a novel approach for robust dynamic scene reconstruction that effectively handles blurry inputs and imprecise camera poses. Our method comprises two main components 1 camera motion deblurring and 2 object motion deblurring. By explicitly decomposing motion blur into camera motion blur and object motion blur and modeling them separately we achieve significantly improved rendering results in dynamic regions. In addition we collect a real world motion blur dataset of dynamic scenes to evaluate our approach. Extensive experiments demonstrate that BARD GS effectively reconstructs high quality dynamic scenes under realistic conditions significantly outperforming existing methods.,BARD GS Blur Aware Reconstruction of Dynamic Scenes via Gaussian Splatting,"['motion', 'dynamic', 'blur', 'camera', 'dynamic scenes', 'motion blur', 'scenes', 'quality', 'approach', 'bard']",3D Gaussian Splatting 3DGS has shown remarkable potential for static scene reconstruction and recent advancements have extended its application to dynamic scenes.
2503.15108v1,VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making,"While Large Language Models (LLMs) excel at reasoning on text and
Vision-Language Models (VLMs) are highly effective for visual perception,
applying those models for visual instruction-based planning remains a widely
open problem. In this paper, we introduce VIPER, a novel framework for
multimodal instruction-based planning that integrates VLM-based perception with
LLM-based reasoning. Our approach uses a modular pipeline where a frozen VLM
generates textual descriptions of image observations, which are then processed
by an LLM policy to predict actions based on the task goal. We fine-tune the
reasoning module using behavioral cloning and reinforcement learning, improving
our agent's decision-making capabilities. Experiments on the ALFWorld benchmark
show that VIPER significantly outperforms state-of-the-art visual
instruction-based planners while narrowing the gap with purely text-based
oracles. By leveraging text as an intermediate representation, VIPER also
enhances explainability, paving the way for a fine-grained analysis of
perception and reasoning components.","['cs.LG', 'cs.AI', 'cs.RO']","['Mohamed Salim Aissi', 'Clemence Grislain', 'Mohamed Chetouani', 'Olivier Sigaud', 'Laure Soulier', 'Nicolas Thome']",2025-03-19,2025-03-19,While Large Language Models LLMs excel at reasoning on text and Vision Language Models VLMs are highly effective for visual perception applying those models for visual instruction based planning remains a widely open problem. In this paper we introduce VIPER a novel framework for multimodal instruction based planning that integrates VLM based perception with LLM based reasoning. Our approach uses a modular pipeline where a frozen VLM generates textual descriptions of image observations which are then processed by an LLM policy to predict actions based on the task goal. We fine tune the reasoning module using behavioral cloning and reinforcement learning improving our agent s decision making capabilities. Experiments on the ALFWorld benchmark show that VIPER significantly outperforms state of the art visual instruction based planners while narrowing the gap with purely text based oracles. By leveraging text as an intermediate representation VIPER also enhances explainability paving the way for a fine grained analysis of perception and reasoning components.,VIPER Visual Perception and Explainable Reasoning for Sequential Decision Making,"['based', 'reasoning', 'instruction', 'instruction based', 'models', 'perception', 'text', 'viper', 'visual', 'based planning']",While Large Language Models LLMs excel at reasoning on text and Vision Language Models VLMs are highly effective for visual perception applying those models for visual instruction based planning remains a widely open problem.
2503.15105v1,"Control, Optimal Transport and Neural Differential Equations in Supervised Learning","From the perspective of control theory, neural differential equations (neural
ODEs) have become an important tool for supervised learning. In the fundamental
work of Ruiz-Balet and Zuazua (SIAM REVIEW 2023), the authors pose an open
problem regarding the connection between control theory, optimal transport
theory, and neural differential equations. More precisely, they inquire how one
can quantify the closeness of the optimal flows in neural transport equations
to the true dynamic optimal transport. In this work, we propose a construction
of neural differential equations that converge to the true dynamic optimal
transport in the limit, providing a significant step in solving the formerly
mentioned open problem.","['math.NA', 'cs.LG', 'cs.NA', 'math.OC']","['Minh-Nhat Phung', 'Minh-Binh Tran']",2025-03-19,2025-03-19,From the perspective of control theory neural differential equations neural ODEs have become an important tool for supervised learning. In the fundamental work of Ruiz Balet and Zuazua SIAM REVIEW 2023 the authors pose an open problem regarding the connection between control theory optimal transport theory and neural differential equations. More precisely they inquire how one can quantify the closeness of the optimal flows in neural transport equations to the true dynamic optimal transport. In this work we propose a construction of neural differential equations that converge to the true dynamic optimal transport in the limit providing a significant step in solving the formerly mentioned open problem.,Control Optimal Transport and Neural Differential Equations in Supervised Learning,"['neural', 'equations', 'optimal', 'transport', 'differential', 'differential equations', 'neural differential', 'optimal transport', 'theory', 'control']",From the perspective of control theory neural differential equations neural ODEs have become an important tool for supervised learning.
2503.16171v1,Guardians of Generation: Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation,"Modern text-to-image generative models can inadvertently reproduce
copyrighted content memorized in their training data, raising serious concerns
about potential copyright infringement. We introduce Guardians of Generation, a
model agnostic inference time framework for dynamic copyright shielding in AI
image generation. Our approach requires no retraining or modification of the
generative model weights, instead integrating seamlessly with existing
diffusion pipelines. It augments the generation process with an adaptive
guidance mechanism comprising three components: a detection module, a prompt
rewriting module, and a guidance adjustment module. The detection module
monitors user prompts and intermediate generation steps to identify features
indicative of copyrighted content before they manifest in the final output. If
such content is detected, the prompt rewriting mechanism dynamically transforms
the user's prompt by sanitizing or replacing references that could trigger
copyrighted material while preserving the prompt's intended semantics. The
adaptive guidance module adaptively steers the diffusion process away from
flagged content by modulating the model's sampling trajectory. Together, these
components form a robust shield that enables a tunable balance between
preserving creative fidelity and ensuring copyright compliance. We validate our
method on a variety of generative models such as Stable Diffusion, SDXL, and
Flux, demonstrating substantial reductions in copyrighted content generation
with negligible impact on output fidelity or alignment with user intent. This
work provides a practical, plug-and-play safeguard for generative image models,
enabling more responsible deployment under real-world copyright constraints.
Source code is available at: https://respailab.github.io/gog",['cs.CV'],"['Soham Roy', 'Abhishek Mishra', 'Shirish Karande', 'Murari Mandal']",2025-03-19,2025-03-19,Modern text to image generative models can inadvertently reproduce copyrighted content memorized in their training data raising serious concerns about potential copyright infringement. We introduce Guardians of Generation a model agnostic inference time framework for dynamic copyright shielding in AI image generation. Our approach requires no retraining or modification of the generative model weights instead integrating seamlessly with existing diffusion pipelines. It augments the generation process with an adaptive guidance mechanism comprising three components a detection module a prompt rewriting module and a guidance adjustment module. The detection module monitors user prompts and intermediate generation steps to identify features indicative of copyrighted content before they manifest in the final output. If such content is detected the prompt rewriting mechanism dynamically transforms the user s prompt by sanitizing or replacing references that could trigger copyrighted material while preserving the prompt s intended semantics. The adaptive guidance module adaptively steers the diffusion process away from flagged content by modulating the model s sampling trajectory. Together these components form a robust shield that enables a tunable balance between preserving creative fidelity and ensuring copyright compliance. We validate our method on a variety of generative models such as Stable Diffusion SDXL and Flux demonstrating substantial reductions in copyrighted content generation with negligible impact on output fidelity or alignment with user intent. This work provides a practical plug and play safeguard for generative image models enabling more responsible deployment under real world copyright constraints. Source code is available at https respailab.github.io gog,Guardians of Generation Dynamic Inference Time Copyright Shielding with Adaptive Guidance for AI Image Generation,"['content', 'generation', 'module', 'copyright', 'copyrighted', 'generative', 'prompt', 'copyrighted content', 'diffusion', 'guidance']",Modern text to image generative models can inadvertently reproduce copyrighted content memorized in their training data raising serious concerns about potential copyright infringement.
2503.16075v1,3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge,"Lightsheet microscopy is a powerful 3-D imaging technique that addresses
limitations of traditional optical and confocal microscopy but suffers from a
low penetration depth and reduced image quality at greater depths. Multiview
lightsheet microscopy improves 3-D resolution by combining multiple views but
simultaneously increasing the complexity and the photon budget, leading to
potential photobleaching and phototoxicity. The FuseMyCells challenge,
organized in conjunction with the IEEE ISBI 2025 conference, aims to benchmark
deep learning-based solutions for fusing high-quality 3-D volumes from single
3-D views, potentially simplifying procedures and conserving the photon budget.
In this work, we propose a contribution to the FuseMyCells challenge based on a
two-step procedure. The first step processes a downsampled version of the image
to capture the entire region of interest, while the second step uses a
patch-based approach for high-resolution inference, incorporating adversarial
loss to enhance visual outcomes. This method addresses challenges related to
high data resolution, the necessity of global context, and the preservation of
high-frequency details. Experimental results demonstrate the effectiveness of
our approach, highlighting its potential to improve 3-D image fusion quality
and extend the capabilities of lightsheet microscopy. The average SSIM for the
nucleus and membranes is greater than 0.85 and 0.91, respectively.","['eess.IV', 'cs.AI', 'cs.CV']","['Marek Wodzinski', 'Henning MÃ¼ller']",2025-03-20,2025-03-20,Lightsheet microscopy is a powerful 3 D imaging technique that addresses limitations of traditional optical and confocal microscopy but suffers from a low penetration depth and reduced image quality at greater depths. Multiview lightsheet microscopy improves 3 D resolution by combining multiple views but simultaneously increasing the complexity and the photon budget leading to potential photobleaching and phototoxicity. The FuseMyCells challenge organized in conjunction with the IEEE ISBI 2025 conference aims to benchmark deep learning based solutions for fusing high quality 3 D volumes from single 3 D views potentially simplifying procedures and conserving the photon budget. In this work we propose a contribution to the FuseMyCells challenge based on a two step procedure. The first step processes a downsampled version of the image to capture the entire region of interest while the second step uses a patch based approach for high resolution inference incorporating adversarial loss to enhance visual outcomes. This method addresses challenges related to high data resolution the necessity of global context and the preservation of high frequency details. Experimental results demonstrate the effectiveness of our approach highlighting its potential to improve 3 D image fusion quality and extend the capabilities of lightsheet microscopy. The average SSIM for the nucleus and membranes is greater than 0.85 and 0.91 respectively.,3 D Image to Image Fusion in Lightsheet Microscopy by Two Step Adversarial Network Contribution to the FuseMyCells Challenge,"['high', 'microscopy', 'based', 'image', 'lightsheet', 'lightsheet microscopy', 'quality', 'resolution', 'step', 'addresses']",Lightsheet microscopy is a powerful 3 D imaging technique that addresses limitations of traditional optical and confocal microscopy but suffers from a low penetration depth and reduced image quality at greater depths.
2503.15267v1,Learning to quantify graph nodes,"Network Quantification is the problem of estimating the class proportions in
unlabeled subsets of graph nodes. When prior probability shift is at play, this
task cannot be effectively addressed by first classifying the nodes and then
counting the class predictions. In addition, unlike non-relational
quantification on i.i.d. datapoints, Network Quantification demands enhanced
flexibility to capture a broad range of connectivity patterns, resilience to
the challenge of heterophily, and efficiency to scale to larger networks. To
meet these stringent requirements we introduce XNQ, a novel method that
synergizes the flexibility and efficiency of the unsupervised node embeddings
computed by randomized recursive Graph Neural Networks, with an
Expectation-Maximization algorithm that provides a robust quantification-aware
adjustment to the output probabilities of a calibrated node classifier. We
validate the design choices underpinning our method through comprehensive
ablation experiments. In an extensive evaluation, we find that our approach
consistently and significantly improves on the best Network Quantification
methods to date, thereby setting the new state of the art for this challenging
task. Simultaneously, it provides a training speed-up of up to 10x-100x over
other graph learning based methods.",['cs.LG'],"['Alessio Micheli', 'Alejandro Moreo', 'Marco Podda', 'Fabrizio Sebastiani', 'William Simoni', 'Domenico Tortorella']",2025-03-19,2025-03-19,Network Quantification is the problem of estimating the class proportions in unlabeled subsets of graph nodes. When prior probability shift is at play this task cannot be effectively addressed by first classifying the nodes and then counting the class predictions. In addition unlike non relational quantification on i.i.d. datapoints Network Quantification demands enhanced flexibility to capture a broad range of connectivity patterns resilience to the challenge of heterophily and efficiency to scale to larger networks. To meet these stringent requirements we introduce XNQ a novel method that synergizes the flexibility and efficiency of the unsupervised node embeddings computed by randomized recursive Graph Neural Networks with an Expectation Maximization algorithm that provides a robust quantification aware adjustment to the output probabilities of a calibrated node classifier. We validate the design choices underpinning our method through comprehensive ablation experiments. In an extensive evaluation we find that our approach consistently and significantly improves on the best Network Quantification methods to date thereby setting the new state of the art for this challenging task. Simultaneously it provides a training speed up of up to 10x 100x over other graph learning based methods.,Learning to quantify graph nodes,"['quantification', 'graph', 'network', 'network quantification', 'class', 'efficiency', 'flexibility', 'method', 'methods', 'networks']",Network Quantification is the problem of estimating the class proportions in unlabeled subsets of graph nodes.
2503.15438v1,VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning,"Natural language processing (NLP) has significantly influenced scientific
domains beyond human language, including protein engineering, where pre-trained
protein language models (PLMs) have demonstrated remarkable success. However,
interdisciplinary adoption remains limited due to challenges in data
collection, task benchmarking, and application. This work presents
VenusFactory, a versatile engine that integrates biological data retrieval,
standardized task benchmarking, and modular fine-tuning of PLMs. VenusFactory
supports both computer science and biology communities with choices of both a
command-line execution and a Gradio-based no-code interface, integrating $40+$
protein-related datasets and $40+$ popular PLMs. All implementations are
open-sourced on https://github.com/tyang816/VenusFactory.","['cs.CL', 'cs.AI', 'q-bio.QM']","['Yang Tan', 'Chen Liu', 'Jingyuan Gao', 'Banghao Wu', 'Mingchen Li', 'Ruilin Wang', 'Lingrong Zhang', 'Huiqun Yu', 'Guisheng Fan', 'Liang Hong', 'Bingxin Zhou']",2025-03-19,2025-03-19,Natural language processing NLP has significantly influenced scientific domains beyond human language including protein engineering where pre trained protein language models PLMs have demonstrated remarkable success. However interdisciplinary adoption remains limited due to challenges in data collection task benchmarking and application. This work presents VenusFactory a versatile engine that integrates biological data retrieval standardized task benchmarking and modular fine tuning of PLMs. VenusFactory supports both computer science and biology communities with choices of both a command line execution and a Gradio based no code interface integrating 40 protein related datasets and 40 popular PLMs. All implementations are open sourced on https github.com tyang816 VenusFactory.,VenusFactory A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine Tuning,"['language', 'plms', 'protein', 'venusfactory', '40', 'benchmarking', 'data', 'task', 'task benchmarking', '40 popular']",Natural language processing NLP has significantly influenced scientific domains beyond human language including protein engineering where pre trained protein language models PLMs have demonstrated remarkable success.
2503.15851v1,Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion,"Animatable head avatar generation typically requires extensive data for
training. To reduce the data requirements, a natural solution is to leverage
existing data-free static avatar generation methods, such as pre-trained
diffusion models with score distillation sampling (SDS), which align avatars
with pseudo ground-truth outputs from the diffusion model. However, directly
distilling 4D avatars from video diffusion often leads to over-smooth results
due to spatial and temporal inconsistencies in the generated video. To address
this issue, we propose Zero-1-to-A, a robust method that synthesizes a spatial
and temporal consistency dataset for 4D avatar reconstruction using the video
diffusion model. Specifically, Zero-1-to-A iteratively constructs video
datasets and optimizes animatable avatars in a progressive manner, ensuring
that avatar quality increases smoothly and consistently throughout the learning
process. This progressive learning involves two stages: (1) Spatial Consistency
Learning fixes expressions and learns from front-to-side views, and (2)
Temporal Consistency Learning fixes views and learns from relaxed to
exaggerated expressions, generating 4D avatars in a simple-to-complex manner.
Extensive experiments demonstrate that Zero-1-to-A improves fidelity, animation
quality, and rendering speed compared to existing diffusion-based methods,
providing a solution for lifelike avatar creation. Code is publicly available
at: https://github.com/ZhenglinZhou/Zero-1-to-A.",['cs.CV'],"['Zhou Zhenglin', 'Ma Fan', 'Fan Hehe', 'Chua Tat-Seng']",2025-03-20,2025-03-20,Animatable head avatar generation typically requires extensive data for training. To reduce the data requirements a natural solution is to leverage existing data free static avatar generation methods such as pre trained diffusion models with score distillation sampling SDS which align avatars with pseudo ground truth outputs from the diffusion model. However directly distilling 4D avatars from video diffusion often leads to over smooth results due to spatial and temporal inconsistencies in the generated video. To address this issue we propose Zero 1 to A a robust method that synthesizes a spatial and temporal consistency dataset for 4D avatar reconstruction using the video diffusion model. Specifically Zero 1 to A iteratively constructs video datasets and optimizes animatable avatars in a progressive manner ensuring that avatar quality increases smoothly and consistently throughout the learning process. This progressive learning involves two stages 1 Spatial Consistency Learning fixes expressions and learns from front to side views and 2 Temporal Consistency Learning fixes views and learns from relaxed to exaggerated expressions generating 4D avatars in a simple to complex manner. Extensive experiments demonstrate that Zero 1 to A improves fidelity animation quality and rendering speed compared to existing diffusion based methods providing a solution for lifelike avatar creation. Code is publicly available at https github.com ZhenglinZhou Zero 1 to A.,Zero 1 to A Zero Shot One Image to Animatable Head Avatars Using Video Diffusion,"['avatar', 'diffusion', 'avatars', 'learning', 'video', 'zero', '4d', 'consistency', 'data', 'spatial']",Animatable head avatar generation typically requires extensive data for training.
2503.16542v1,Defending Against Gradient Inversion Attacks for Biomedical Images via Learnable Data Perturbation,"The increasing need for sharing healthcare data and collaborating on clinical
research has raised privacy concerns. Health information leakage due to
malicious attacks can lead to serious problems such as misdiagnoses and patient
identification issues. Privacy-preserving machine learning (PPML) and
privacy-enhancing technologies, particularly federated learning (FL), have
emerged in recent years as innovative solutions to balance privacy protection
with data utility; however, they also suffer from inherent privacy
vulnerabilities. Gradient inversion attacks constitute major threats to data
sharing in federated learning. Researchers have proposed many defenses against
gradient inversion attacks. However, current defense methods for healthcare
data lack generalizability, i.e., existing solutions may not be applicable to
data from a broader range of populations. In addition, most existing defense
methods are tested using non-healthcare data, which raises concerns about their
applicability to real-world healthcare systems. In this study, we present a
defense against gradient inversion attacks in federated learning. We achieve
this using latent data perturbation and minimax optimization, utilizing both
general and medical image datasets. Our method is compared to two baselines,
and the results show that our approach can outperform the baselines with a
reduction of 12.5% in the attacker's accuracy in classifying reconstructed
images. The proposed method also yields an increase of over 12.4% in Mean
Squared Error (MSE) between the original and reconstructed images at the same
level of model utility of around 90% client classification accuracy. The
results suggest the potential of a generalizable defense for healthcare data.","['cs.CV', 'cs.LG']","['Shiyi Jiang', 'Farshad Firouzi', 'Krishnendu Chakrabarty']",2025-03-19,2025-03-19,The increasing need for sharing healthcare data and collaborating on clinical research has raised privacy concerns. Health information leakage due to malicious attacks can lead to serious problems such as misdiagnoses and patient identification issues. Privacy preserving machine learning PPML and privacy enhancing technologies particularly federated learning FL have emerged in recent years as innovative solutions to balance privacy protection with data utility however they also suffer from inherent privacy vulnerabilities. Gradient inversion attacks constitute major threats to data sharing in federated learning. Researchers have proposed many defenses against gradient inversion attacks. However current defense methods for healthcare data lack generalizability i.e. existing solutions may not be applicable to data from a broader range of populations. In addition most existing defense methods are tested using non healthcare data which raises concerns about their applicability to real world healthcare systems. In this study we present a defense against gradient inversion attacks in federated learning. We achieve this using latent data perturbation and minimax optimization utilizing both general and medical image datasets. Our method is compared to two baselines and the results show that our approach can outperform the baselines with a reduction of 12.5 in the attacker s accuracy in classifying reconstructed images. The proposed method also yields an increase of over 12.4 in Mean Squared Error MSE between the original and reconstructed images at the same level of model utility of around 90 client classification accuracy. The results suggest the potential of a generalizable defense for healthcare data.,Defending Against Gradient Inversion Attacks for Biomedical Images via Learnable Data Perturbation,"['data', 'healthcare', 'privacy', 'attacks', 'defense', 'healthcare data', 'learning', 'federated', 'federated learning', 'gradient']",The increasing need for sharing healthcare data and collaborating on clinical research has raised privacy concerns.
2503.16974v1,Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks,"This study provides the first comprehensive assessment of consistency and
reproducibility in Large Language Model (LLM) outputs in finance and accounting
research. We evaluate how consistently LLMs produce outputs given identical
inputs through extensive experimentation with 50 independent runs across five
common tasks: classification, sentiment analysis, summarization, text
generation, and prediction. Using three OpenAI models (GPT-3.5-turbo,
GPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse
financial source texts and data, covering MD&As, FOMC statements, finance news
articles, earnings call transcripts, and financial statements. Our findings
reveal substantial but task-dependent consistency, with binary classification
and sentiment analysis achieving near-perfect reproducibility, while complex
tasks show greater variability. More advanced models do not consistently
demonstrate better consistency and reproducibility, with task-specific patterns
emerging. LLMs significantly outperform expert human annotators in consistency
and maintain high agreement even where human experts significantly disagree. We
further find that simple aggregation strategies across 3-5 runs dramatically
improve consistency. Simulation analysis reveals that despite measurable
inconsistency in LLM outputs, downstream statistical inferences remain
remarkably robust. These findings address concerns about what we term
""G-hacking,"" the selective reporting of favorable outcomes from multiple
Generative AI runs, by demonstrating that such risks are relatively low for
finance and accounting tasks.","['q-fin.GN', 'cs.AI', 'cs.CE', 'cs.CL', 'cs.LG']","['Julian Junyan Wang', 'Victor Xiaoqi Wang']",2025-03-21,2025-03-21,This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model LLM outputs in finance and accounting research. We evaluate how consistently LLMs produce outputs given identical inputs through extensive experimentation with 50 independent runs across five common tasks classification sentiment analysis summarization text generation and prediction. Using three OpenAI models GPT 3.5 turbo GPT 4o mini and GPT 4o we generate over 3.4 million outputs from diverse financial source texts and data covering MD As FOMC statements finance news articles earnings call transcripts and financial statements. Our findings reveal substantial but task dependent consistency with binary classification and sentiment analysis achieving near perfect reproducibility while complex tasks show greater variability. More advanced models do not consistently demonstrate better consistency and reproducibility with task specific patterns emerging. LLMs significantly outperform expert human annotators in consistency and maintain high agreement even where human experts significantly disagree. We further find that simple aggregation strategies across 3 5 runs dramatically improve consistency. Simulation analysis reveals that despite measurable inconsistency in LLM outputs downstream statistical inferences remain remarkably robust. These findings address concerns about what we term G hacking the selective reporting of favorable outcomes from multiple Generative AI runs by demonstrating that such risks are relatively low for finance and accounting tasks.,Assessing Consistency and Reproducibility in the Outputs of Large Language Models Evidence Across Diverse Finance and Accounting Tasks,"['consistency', 'outputs', 'analysis', 'finance', 'gpt', 'reproducibility', 'runs', 'tasks', '4o', 'accounting']",This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model LLM outputs in finance and accounting research.
2503.15566v1,Enforcing Consistency and Fairness in Multi-level Hierarchical Classification with a Mask-based Output Layer,"Traditional Multi-level Hierarchical Classification (MLHC) classifiers often
rely on backbone models with $n$ independent output layers. This structure
tends to overlook the hierarchical relationships between classes, leading to
inconsistent predictions that violate the underlying taxonomy. Additionally,
once a backbone architecture for an MLHC classifier is selected, adapting the
model to accommodate new tasks can be challenging. For example, incorporating
fairness to protect sensitive attributes within a hierarchical classifier
necessitates complex adjustments to maintain the class hierarchy while
enforcing fairness constraints. In this paper, we extend this concept to
hierarchical classification by introducing a fair, model-agnostic layer
designed to enforce taxonomy and optimize specific objectives, including
consistency, fairness, and exact match. Our evaluations demonstrate that the
proposed layer not only improves the fairness of predictions but also enforces
the taxonomy, resulting in consistent predictions and superior performance.
Compared to Large Language Models (LLMs) employing in-processing de-biasing
techniques and models without any bias correction, our approach achieves better
outcomes in both fairness and accuracy, making it particularly valuable in
sectors like e-commerce, healthcare, and education, where predictive
reliability is crucial.",['cs.LG'],"['Shijing Chen', 'Shoaib Jameel', 'Mohamed Reda Bouadjenek', 'Feilong Tang', 'Usman Naseem', 'Basem Suleiman', 'Hakim Hacid', 'Flora D. Salim', 'Imran Razzak']",2025-03-19,2025-03-19,Traditional Multi level Hierarchical Classification MLHC classifiers often rely on backbone models with n independent output layers. This structure tends to overlook the hierarchical relationships between classes leading to inconsistent predictions that violate the underlying taxonomy. Additionally once a backbone architecture for an MLHC classifier is selected adapting the model to accommodate new tasks can be challenging. For example incorporating fairness to protect sensitive attributes within a hierarchical classifier necessitates complex adjustments to maintain the class hierarchy while enforcing fairness constraints. In this paper we extend this concept to hierarchical classification by introducing a fair model agnostic layer designed to enforce taxonomy and optimize specific objectives including consistency fairness and exact match. Our evaluations demonstrate that the proposed layer not only improves the fairness of predictions but also enforces the taxonomy resulting in consistent predictions and superior performance. Compared to Large Language Models LLMs employing in processing de biasing techniques and models without any bias correction our approach achieves better outcomes in both fairness and accuracy making it particularly valuable in sectors like e commerce healthcare and education where predictive reliability is crucial.,Enforcing Consistency and Fairness in Multi level Hierarchical Classification with a Mask based Output Layer,"['fairness', 'hierarchical', 'models', 'predictions', 'taxonomy', 'backbone', 'classification', 'classifier', 'hierarchical classification', 'layer']",Traditional Multi level Hierarchical Classification MLHC classifiers often rely on backbone models with n independent output layers.
2503.17136v1,CoKe: Customizable Fine-Grained Story Evaluation via Chain-of-Keyword Rationalization,"Evaluating creative text such as human-written stories using language models
has always been a challenging task -- owing to the subjectivity of
multi-annotator ratings. To mimic the thinking process of humans, chain of
thought (CoT) generates free-text explanations that help guide a model's
predictions and Self-Consistency (SC) marginalizes predictions over multiple
generated explanations. In this study, we discover that the widely-used
self-consistency reasoning methods cause suboptimal results due to an objective
mismatch between generating 'fluent-looking' explanations vs. actually leading
to a good rating prediction for an aspect of a story. To overcome this
challenge, we propose $\textbf{C}$hain-$\textbf{o}$f-$\textbf{Ke}$ywords
(CoKe), that generates a sequence of keywords $\textit{before}$ generating a
free-text rationale, that guide the rating prediction of our evaluation
language model. Then, we generate a diverse set of such keywords, and aggregate
the scores corresponding to these generations. On the StoryER dataset, CoKe
based on our small fine-tuned evaluation models not only reach human-level
performance and significantly outperform GPT-4 with a 2x boost in correlation
with human annotators, but also requires drastically less number of parameters.",['cs.CL'],"['Brihi Joshi', 'Sriram Venkatapathy', 'Mohit Bansal', 'Nanyun Peng', 'Haw-Shiuan Chang']",2025-03-21,2025-03-21,Evaluating creative text such as human written stories using language models has always been a challenging task owing to the subjectivity of multi annotator ratings. To mimic the thinking process of humans chain of thought CoT generates free text explanations that help guide a model s predictions and Self Consistency SC marginalizes predictions over multiple generated explanations. In this study we discover that the widely used self consistency reasoning methods cause suboptimal results due to an objective mismatch between generating fluent looking explanations vs. actually leading to a good rating prediction for an aspect of a story. To overcome this challenge we propose textbf C hain textbf o f textbf Ke ywords CoKe that generates a sequence of keywords textit before generating a free text rationale that guide the rating prediction of our evaluation language model. Then we generate a diverse set of such keywords and aggregate the scores corresponding to these generations. On the StoryER dataset CoKe based on our small fine tuned evaluation models not only reach human level performance and significantly outperform GPT 4 with a 2x boost in correlation with human annotators but also requires drastically less number of parameters.,CoKe Customizable Fine Grained Story Evaluation via Chain of Keyword Rationalization,"['explanations', 'human', 'text', 'textbf', 'coke', 'consistency', 'evaluation', 'free', 'free text', 'generates']",Evaluating creative text such as human written stories using language models has always been a challenging task owing to the subjectivity of multi annotator ratings.
2503.15412v1,Learn Your Scales: Towards Scale-Consistent Generative Novel View Synthesis,"Conventional depth-free multi-view datasets are captured using a moving
monocular camera without metric calibration. The scales of camera positions in
this monocular setting are ambiguous. Previous methods have acknowledged scale
ambiguity in multi-view data via various ad-hoc normalization pre-processing
steps, but have not directly analyzed the effect of incorrect scene scales on
their application. In this paper, we seek to understand and address the effect
of scale ambiguity when used to train generative novel view synthesis methods
(GNVS). In GNVS, new views of a scene or object can be minimally synthesized
given a single image and are, thus, unconstrained, necessitating the use of
generative methods. The generative nature of these models captures all aspects
of uncertainty, including any uncertainty of scene scales, which act as
nuisance variables for the task. We study the effect of scene scale ambiguity
in GNVS when sampled from a single image by isolating its effect on the
resulting models and, based on these intuitions, define new metrics that
measure the scale inconsistency of generated views. We then propose a framework
to estimate scene scales jointly with the GNVS model in an end-to-end fashion.
Empirically, we show that our method reduces the scale inconsistency of
generated views without the complexity or downsides of previous scale
normalization methods. Further, we show that removing this ambiguity improves
generated image quality of the resulting GNVS model.",['cs.CV'],"['Fereshteh Forghani', 'Jason J. Yu', 'Tristan Aumentado-Armstrong', 'Konstantinos G. Derpanis', 'Marcus A. Brubaker']",2025-03-19,2025-03-19,Conventional depth free multi view datasets are captured using a moving monocular camera without metric calibration. The scales of camera positions in this monocular setting are ambiguous. Previous methods have acknowledged scale ambiguity in multi view data via various ad hoc normalization pre processing steps but have not directly analyzed the effect of incorrect scene scales on their application. In this paper we seek to understand and address the effect of scale ambiguity when used to train generative novel view synthesis methods GNVS . In GNVS new views of a scene or object can be minimally synthesized given a single image and are thus unconstrained necessitating the use of generative methods. The generative nature of these models captures all aspects of uncertainty including any uncertainty of scene scales which act as nuisance variables for the task. We study the effect of scene scale ambiguity in GNVS when sampled from a single image by isolating its effect on the resulting models and based on these intuitions define new metrics that measure the scale inconsistency of generated views. We then propose a framework to estimate scene scales jointly with the GNVS model in an end to end fashion. Empirically we show that our method reduces the scale inconsistency of generated views without the complexity or downsides of previous scale normalization methods. Further we show that removing this ambiguity improves generated image quality of the resulting GNVS model.,Learn Your Scales Towards Scale Consistent Generative Novel View Synthesis,"['scale', 'gnvs', 'scene', 'ambiguity', 'effect', 'methods', 'scales', 'generated', 'generative', 'image']",Conventional depth free multi view datasets are captured using a moving monocular camera without metric calibration.
2503.14395v1,Weakly Supervised Spatial Implicit Neural Representation Learning for 3D MRI-Ultrasound Deformable Image Registration in HDR Prostate Brachytherapy,"Purpose: Accurate 3D MRI-ultrasound (US) deformable registration is critical
for real-time guidance in high-dose-rate (HDR) prostate brachytherapy. We
present a weakly supervised spatial implicit neural representation (SINR)
method to address modality differences and pelvic anatomy challenges.
  Methods: The framework uses sparse surface supervision from MRI/US
segmentations instead of dense intensity matching. SINR models deformations as
continuous spatial functions, with patient-specific surface priors guiding a
stationary velocity field for biologically plausible deformations. Validation
included 20 public Prostate-MRI-US-Biopsy cases and 10 institutional HDR cases,
evaluated via Dice similarity coefficient (DSC), mean surface distance (MSD),
and 95% Hausdorff distance (HD95).
  Results: The proposed method achieved robust registration. For the public
dataset, prostate DSC was $0.93 \pm 0.05$, MSD $0.87 \pm 0.10$ mm, and HD95
$1.58 \pm 0.37$ mm. For the institutional dataset, prostate CTV achieved DSC
$0.88 \pm 0.09$, MSD $1.21 \pm 0.38$ mm, and HD95 $2.09 \pm 1.48$ mm. Bladder
and rectum performance was lower due to ultrasound's limited field of view.
Visual assessments confirmed accurate alignment with minimal discrepancies.
  Conclusion: This study introduces a novel weakly supervised SINR-based
approach for 3D MRI-US deformable registration. By leveraging sparse surface
supervision and spatial priors, it achieves accurate, robust, and
computationally efficient registration, enhancing real-time image guidance in
HDR prostate brachytherapy and improving treatment precision.","['physics.med-ph', 'cs.CV']","['Jing Wang', 'Ruirui Liu', 'Yu Lei', 'Michael J. Baine', 'Tian Liu', 'Yang Lei']",2025-03-18,2025-03-18,Purpose Accurate 3D MRI ultrasound US deformable registration is critical for real time guidance in high dose rate HDR prostate brachytherapy. We present a weakly supervised spatial implicit neural representation SINR method to address modality differences and pelvic anatomy challenges. Methods The framework uses sparse surface supervision from MRI US segmentations instead of dense intensity matching. SINR models deformations as continuous spatial functions with patient specific surface priors guiding a stationary velocity field for biologically plausible deformations. Validation included 20 public Prostate MRI US Biopsy cases and 10 institutional HDR cases evaluated via Dice similarity coefficient DSC mean surface distance MSD and 95 Hausdorff distance HD95 . Results The proposed method achieved robust registration. For the public dataset prostate DSC was 0.93 pm 0.05 MSD 0.87 pm 0.10 mm and HD95 1.58 pm 0.37 mm. For the institutional dataset prostate CTV achieved DSC 0.88 pm 0.09 MSD 1.21 pm 0.38 mm and HD95 2.09 pm 1.48 mm. Bladder and rectum performance was lower due to ultrasound s limited field of view. Visual assessments confirmed accurate alignment with minimal discrepancies. Conclusion This study introduces a novel weakly supervised SINR based approach for 3D MRI US deformable registration. By leveraging sparse surface supervision and spatial priors it achieves accurate robust and computationally efficient registration enhancing real time image guidance in HDR prostate brachytherapy and improving treatment precision.,Weakly Supervised Spatial Implicit Neural Representation Learning for 3D MRI Ultrasound Deformable Image Registration in HDR Prostate Brachytherapy,"['pm', 'prostate', 'mm', 'mri', 'registration', 'surface', 'accurate', 'dsc', 'hd95', 'hdr']",Purpose Accurate 3D MRI ultrasound US deformable registration is critical for real time guidance in high dose rate HDR prostate brachytherapy.
2503.14488v1,Engineering Scientific Assistants using Interactive Structured Induction of Programs,"We are interested in the construction of software that can act as scientific
assistants to domain specialists. It is expected that such assistants will be
needed to accelerate the identification of ways to address complex problems
requiring urgent solutions. In this paper, our focus is not on a specific
scientific problem, but on the software-engineering of such 'science
accelerators'. Recent developments in 'No Code' techniques would seem to
suggest that scientist can simply hypothesise solutions simply by conversing
with a large language model (LLM). However, for complex scientific problems,
this seems unlikely given the current state of LLM technology. What does appear
feasible is that a software engineer can use LLMs to rapidly construct programs
for use by a domain-specialist, including the specialist's requirements
expressed in natural language. We propose the design of an interactive form of
'structured' inductive programming in which a software-engineer and an LLM
collaboratively construct an 'assistant' for a scientific data analysis. The
paper describes a simple implementation called iStrucInd that adapts a '2-way
Intelligibility' protocol to implement the interaction between the software
engineer and the LLM. We test the tool on two different non-trivial scientific
data analysis tasks. Specifically, we compare the system constructed by
iStrucInd against systems constructed manually and by Low Code/No Code methods
along dimensions of: (a) program performance; (b) program quality; and (c)
programming effort. The results show iStrucInd allows a software engineer to
develop better programs faster suggesting interactive structured induction can
play a useful role in the rapid construction of scientific assistants.","['cs.AI', 'cs.SE']","['Shraddha Surana', 'Ashwin Srinivasan']",2025-03-18,2025-03-18,We are interested in the construction of software that can act as scientific assistants to domain specialists. It is expected that such assistants will be needed to accelerate the identification of ways to address complex problems requiring urgent solutions. In this paper our focus is not on a specific scientific problem but on the software engineering of such science accelerators . Recent developments in No Code techniques would seem to suggest that scientist can simply hypothesise solutions simply by conversing with a large language model LLM . However for complex scientific problems this seems unlikely given the current state of LLM technology. What does appear feasible is that a software engineer can use LLMs to rapidly construct programs for use by a domain specialist including the specialist s requirements expressed in natural language. We propose the design of an interactive form of structured inductive programming in which a software engineer and an LLM collaboratively construct an assistant for a scientific data analysis. The paper describes a simple implementation called iStrucInd that adapts a 2 way Intelligibility protocol to implement the interaction between the software engineer and the LLM. We test the tool on two different non trivial scientific data analysis tasks. Specifically we compare the system constructed by iStrucInd against systems constructed manually and by Low Code No Code methods along dimensions of a program performance b program quality and c programming effort. The results show iStrucInd allows a software engineer to develop better programs faster suggesting interactive structured induction can play a useful role in the rapid construction of scientific assistants.,Engineering Scientific Assistants using Interactive Structured Induction of Programs,"['scientific', 'software', 'engineer', 'llm', 'software engineer', 'assistants', 'code', 'istrucind', 'analysis', 'complex']",We are interested in the construction of software that can act as scientific assistants to domain specialists.
2503.15554v1,A Comprehensive Study of LLM Secure Code Generation,"LLMs are widely used in software development. However, the code generated by
LLMs often contains vulnerabilities. Several secure code generation methods
have been proposed to address this issue, but their current evaluation schemes
leave several concerns unaddressed. Specifically, most existing studies
evaluate security and functional correctness separately, using different
datasets. That is, they assess vulnerabilities using security-related code
datasets while validating functionality with general code datasets. In
addition, prior research primarily relies on a single static analyzer, CodeQL,
to detect vulnerabilities in generated code, which limits the scope of security
evaluation.
  In this work, we conduct a comprehensive study to systematically assess the
improvements introduced by four state-of-the-art secure code generation
techniques. Specifically, we apply both security inspection and functionality
validation to the same generated code and evaluate these two aspects together.
We also employ three popular static analyzers and two LLMs to identify
potential vulnerabilities in the generated code. Our study reveals that
existing techniques often compromise the functionality of generated code to
enhance security. Their overall performance remains limited when evaluating
security and functionality together. In fact, many techniques even degrade the
performance of the base LLM. Our further inspection reveals that these
techniques often either remove vulnerable lines of code entirely or generate
``garbage code'' that is unrelated to the intended task. Moreover, the commonly
used static analyzer CodeQL fails to detect several vulnerabilities, further
obscuring the actual security improvements achieved by existing techniques. Our
study serves as a guideline for a more rigorous and comprehensive evaluation of
secure code generation performance in future work.","['cs.CR', 'cs.LG', 'cs.SE']","['Shih-Chieh Dai', 'Jun Xu', 'Guanhong Tao']",2025-03-18,2025-03-18,LLMs are widely used in software development. However the code generated by LLMs often contains vulnerabilities. Several secure code generation methods have been proposed to address this issue but their current evaluation schemes leave several concerns unaddressed. Specifically most existing studies evaluate security and functional correctness separately using different datasets. That is they assess vulnerabilities using security related code datasets while validating functionality with general code datasets. In addition prior research primarily relies on a single static analyzer CodeQL to detect vulnerabilities in generated code which limits the scope of security evaluation. In this work we conduct a comprehensive study to systematically assess the improvements introduced by four state of the art secure code generation techniques. Specifically we apply both security inspection and functionality validation to the same generated code and evaluate these two aspects together. We also employ three popular static analyzers and two LLMs to identify potential vulnerabilities in the generated code. Our study reveals that existing techniques often compromise the functionality of generated code to enhance security. Their overall performance remains limited when evaluating security and functionality together. In fact many techniques even degrade the performance of the base LLM. Our further inspection reveals that these techniques often either remove vulnerable lines of code entirely or generate garbage code that is unrelated to the intended task. Moreover the commonly used static analyzer CodeQL fails to detect several vulnerabilities further obscuring the actual security improvements achieved by existing techniques. Our study serves as a guideline for a more rigorous and comprehensive evaluation of secure code generation performance in future work.,A Comprehensive Study of LLM Secure Code Generation,"['code', 'security', 'generated', 'techniques', 'vulnerabilities', 'functionality', 'generated code', 'code generation', 'datasets', 'evaluation']",LLMs are widely used in software development.
2503.16428v1,XAttention: Block Sparse Attention with Antidiagonal Scoring,"Long-Context Transformer Models (LCTMs) are vital for real-world applications
but suffer high computational costs due to attention's quadratic complexity.
Block-sparse attention mitigates this by focusing computation on critical
regions, yet existing methods struggle with balancing accuracy and efficiency
due to costly block importance measurements. In this paper, we introduce
XAttention, a plug-and-play framework that dramatically accelerates
long-context inference in Transformers models using sparse attention.
XAttention's key innovation is the insight that the sum of antidiagonal values
(i.e., from the lower-left to upper-right) in the attention matrix provides a
powerful proxy for block importance. This allows for precise identification and
pruning of non-essential blocks, resulting in high sparsity and dramatically
accelerated inference. Across comprehensive evaluations on demanding
long-context benchmarks-including RULER and LongBench for language, VideoMME
for video understanding, and VBench for video generation. XAttention achieves
accuracy comparable to full attention while delivering substantial
computational gains. We demonstrate up to 13.5x acceleration in attention
computation. These results underscore XAttention's ability to unlock the
practical potential of block sparse attention, paving the way for scalable and
efficient deployment of LCTMs in real-world applications. Code is available at
https://github.com/mit-han-lab/x-attention.","['cs.CL', 'cs.CV']","['Ruyi Xu', 'Guangxuan Xiao', 'Haofeng Huang', 'Junxian Guo', 'Song Han']",2025-03-20,2025-03-20,Long Context Transformer Models LCTMs are vital for real world applications but suffer high computational costs due to attention s quadratic complexity. Block sparse attention mitigates this by focusing computation on critical regions yet existing methods struggle with balancing accuracy and efficiency due to costly block importance measurements. In this paper we introduce XAttention a plug and play framework that dramatically accelerates long context inference in Transformers models using sparse attention. XAttention s key innovation is the insight that the sum of antidiagonal values i.e. from the lower left to upper right in the attention matrix provides a powerful proxy for block importance. This allows for precise identification and pruning of non essential blocks resulting in high sparsity and dramatically accelerated inference. Across comprehensive evaluations on demanding long context benchmarks including RULER and LongBench for language VideoMME for video understanding and VBench for video generation. XAttention achieves accuracy comparable to full attention while delivering substantial computational gains. We demonstrate up to 13.5x acceleration in attention computation. These results underscore XAttention s ability to unlock the practical potential of block sparse attention paving the way for scalable and efficient deployment of LCTMs in real world applications. Code is available at https github.com mit han lab x attention.,XAttention Block Sparse Attention with Antidiagonal Scoring,"['attention', 'block', 'xattention', 'context', 'long', 'long context', 'sparse', 'sparse attention', 'accuracy', 'applications']",Long Context Transformer Models LCTMs are vital for real world applications but suffer high computational costs due to attention s quadratic complexity.
2503.14755v1,Language Independent Named Entity Recognition via Orthogonal Transformation of Word Vectors,"Word embeddings have been a key building block for NLP in which models relied
heavily on word embeddings in many different tasks. In this paper, a model is
proposed based on using Bidirectional LSTM/CRF with word embeddings to perform
named entity recognition for any language. This is done by training a model on
a source language (English) and transforming word embeddings from the target
language into word embeddings of the source language by using an orthogonal
linear transformation matrix. Evaluation of the model shows that by training a
model on an English dataset the model was capable of detecting named entities
in an Arabic dataset without neither training or fine tuning the model on an
Arabic language dataset.","['cs.CL', 'cs.AI']","['Omar E. Rakha', 'Hazem M. Abbas']",2025-03-18,2025-03-18,Word embeddings have been a key building block for NLP in which models relied heavily on word embeddings in many different tasks. In this paper a model is proposed based on using Bidirectional LSTM CRF with word embeddings to perform named entity recognition for any language. This is done by training a model on a source language English and transforming word embeddings from the target language into word embeddings of the source language by using an orthogonal linear transformation matrix. Evaluation of the model shows that by training a model on an English dataset the model was capable of detecting named entities in an Arabic dataset without neither training or fine tuning the model on an Arabic language dataset.,Language Independent Named Entity Recognition via Orthogonal Transformation of Word Vectors,"['model', 'embeddings', 'language', 'word', 'word embeddings', 'dataset', 'training', 'arabic', 'english', 'named']",Word embeddings have been a key building block for NLP in which models relied heavily on word embeddings in many different tasks.
2503.15024v1,Forensics-Bench: A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models,"Recently, the rapid development of AIGC has significantly boosted the
diversities of fake media spread in the Internet, posing unprecedented threats
to social security, politics, law, and etc. To detect the ever-increasingly
diverse malicious fake media in the new era of AIGC, recent studies have
proposed to exploit Large Vision Language Models (LVLMs) to design robust
forgery detectors due to their impressive performance on a wide range of
multimodal tasks. However, it still lacks a comprehensive benchmark designed to
comprehensively assess LVLMs' discerning capabilities on forgery media. To fill
this gap, we present Forensics-Bench, a new forgery detection evaluation
benchmark suite to assess LVLMs across massive forgery detection tasks,
requiring comprehensive recognition, location and reasoning capabilities on
diverse forgeries. Forensics-Bench comprises 63,292 meticulously curated
multi-choice visual questions, covering 112 unique forgery detection types from
5 perspectives: forgery semantics, forgery modalities, forgery tasks, forgery
types and forgery models. We conduct thorough evaluations on 22 open-sourced
LVLMs and 3 proprietary models GPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet,
highlighting the significant challenges of comprehensive forgery detection
posed by Forensics-Bench. We anticipate that Forensics-Bench will motivate the
community to advance the frontier of LVLMs, striving for all-around forgery
detectors in the era of AIGC. The deliverables will be updated at
https://Forensics-Bench.github.io/.",['cs.CV'],"['Jin Wang', 'Chenghui Lv', 'Xian Li', 'Shichao Dong', 'Huadong Li', 'kelu Yao', 'Chao Li', 'Wenqi Shao', 'Ping Luo']",2025-03-19,2025-03-19,Recently the rapid development of AIGC has significantly boosted the diversities of fake media spread in the Internet posing unprecedented threats to social security politics law and etc. To detect the ever increasingly diverse malicious fake media in the new era of AIGC recent studies have proposed to exploit Large Vision Language Models LVLMs to design robust forgery detectors due to their impressive performance on a wide range of multimodal tasks. However it still lacks a comprehensive benchmark designed to comprehensively assess LVLMs discerning capabilities on forgery media. To fill this gap we present Forensics Bench a new forgery detection evaluation benchmark suite to assess LVLMs across massive forgery detection tasks requiring comprehensive recognition location and reasoning capabilities on diverse forgeries. Forensics Bench comprises 63 292 meticulously curated multi choice visual questions covering 112 unique forgery detection types from 5 perspectives forgery semantics forgery modalities forgery tasks forgery types and forgery models. We conduct thorough evaluations on 22 open sourced LVLMs and 3 proprietary models GPT 4o Gemini 1.5 Pro and Claude 3.5 Sonnet highlighting the significant challenges of comprehensive forgery detection posed by Forensics Bench. We anticipate that Forensics Bench will motivate the community to advance the frontier of LVLMs striving for all around forgery detectors in the era of AIGC. The deliverables will be updated at https Forensics Bench.github.io .,Forensics Bench A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models,"['forgery', 'bench', 'forensics', 'forensics bench', 'lvlms', 'detection', 'forgery detection', 'aigc', 'comprehensive', 'media']",Recently the rapid development of AIGC has significantly boosted the diversities of fake media spread in the Internet posing unprecedented threats to social security politics law and etc.
2503.16357v1,UniSync: A Unified Framework for Audio-Visual Synchronization,"Precise audio-visual synchronization in speech videos is crucial for content
quality and viewer comprehension. Existing methods have made significant
strides in addressing this challenge through rule-based approaches and
end-to-end learning techniques. However, these methods often rely on limited
audio-visual representations and suboptimal learning strategies, potentially
constraining their effectiveness in more complex scenarios. To address these
limitations, we present UniSync, a novel approach for evaluating audio-visual
synchronization using embedding similarities. UniSync offers broad
compatibility with various audio representations (e.g., Mel spectrograms,
HuBERT) and visual representations (e.g., RGB images, face parsing maps, facial
landmarks, 3DMM), effectively handling their significant dimensional
differences. We enhance the contrastive learning framework with a margin-based
loss component and cross-speaker unsynchronized pairs, improving discriminative
capabilities. UniSync outperforms existing methods on standard datasets and
demonstrates versatility across diverse audio-visual representations. Its
integration into talking face generation frameworks enhances synchronization
quality in both natural and AI-generated content.","['cs.CV', 'cs.SD', 'eess.AS']","['Tao Feng', 'Yifan Xie', 'Xun Guan', 'Jiyuan Song', 'Zhou Liu', 'Fei Ma', 'Fei Yu']",2025-03-20,2025-03-20,Precise audio visual synchronization in speech videos is crucial for content quality and viewer comprehension. Existing methods have made significant strides in addressing this challenge through rule based approaches and end to end learning techniques. However these methods often rely on limited audio visual representations and suboptimal learning strategies potentially constraining their effectiveness in more complex scenarios. To address these limitations we present UniSync a novel approach for evaluating audio visual synchronization using embedding similarities. UniSync offers broad compatibility with various audio representations e.g. Mel spectrograms HuBERT and visual representations e.g. RGB images face parsing maps facial landmarks 3DMM effectively handling their significant dimensional differences. We enhance the contrastive learning framework with a margin based loss component and cross speaker unsynchronized pairs improving discriminative capabilities. UniSync outperforms existing methods on standard datasets and demonstrates versatility across diverse audio visual representations. Its integration into talking face generation frameworks enhances synchronization quality in both natural and AI generated content.,UniSync A Unified Framework for Audio Visual Synchronization,"['audio', 'visual', 'audio visual', 'representations', 'learning', 'methods', 'synchronization', 'unisync', 'visual representations', 'based']",Precise audio visual synchronization in speech videos is crucial for content quality and viewer comprehension.
2503.15768v1,Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer,"Abstractive multi-document summarization (MDS) is the task of automatically
summarizing information in multiple documents, from news articles to
conversations with multiple speakers. The training approaches for current MDS
models can be grouped into four approaches: end-to-end with special
pre-training (""direct""), chunk-then-summarize, extract-then-summarize, and
inference with GPT-style models. In this work, we evaluate MDS models across
training approaches, domains, and dimensions (reference similarity, quality,
and factuality), to analyze how and why models trained on one domain can fail
to summarize documents from another (News, Science, and Conversation) in the
zero-shot domain transfer setting. We define domain-transfer ""failure"" as a
decrease in factuality, higher deviation from the target, and a general
decrease in summary quality. In addition to exploring domain transfer for MDS
models, we examine potential issues with applying popular summarization metrics
out-of-the-box.","['cs.CL', 'cs.AI']","['Alexandra DeLucia', 'Mark Dredze']",2025-03-20,2025-03-20,Abstractive multi document summarization MDS is the task of automatically summarizing information in multiple documents from news articles to conversations with multiple speakers. The training approaches for current MDS models can be grouped into four approaches end to end with special pre training direct chunk then summarize extract then summarize and inference with GPT style models. In this work we evaluate MDS models across training approaches domains and dimensions reference similarity quality and factuality to analyze how and why models trained on one domain can fail to summarize documents from another News Science and Conversation in the zero shot domain transfer setting. We define domain transfer failure as a decrease in factuality higher deviation from the target and a general decrease in summary quality. In addition to exploring domain transfer for MDS models we examine potential issues with applying popular summarization metrics out of the box.,Can one size fit all Measuring Failure in Multi Document Summarization Domain Transfer,"['models', 'domain', 'mds', 'approaches', 'domain transfer', 'mds models', 'summarize', 'training', 'transfer', 'decrease']",Abstractive multi document summarization MDS is the task of automatically summarizing information in multiple documents from news articles to conversations with multiple speakers.
2503.16868v1,Joint Extraction Matters: Prompt-Based Visual Question Answering for Multi-Field Document Information Extraction,"Visual question answering (VQA) has emerged as a flexible approach for
extracting specific pieces of information from document images. However,
existing work typically queries each field in isolation, overlooking potential
dependencies across multiple items. This paper investigates the merits of
extracting multiple fields jointly versus separately. Through experiments on
multiple large vision language models and datasets, we show that jointly
extracting fields often improves accuracy, especially when the fields share
strong numeric or contextual dependencies. We further analyze how performance
scales with the number of requested items and use a regression based metric to
quantify inter field relationships. Our results suggest that multi field
prompts can mitigate confusion arising from similar surface forms and related
numeric values, providing practical methods for designing robust VQA systems in
document information extraction tasks.","['cs.CL', 'cs.CV']","['Mengsay Loem', 'Taiju Hosaka']",2025-03-21,2025-03-21,Visual question answering VQA has emerged as a flexible approach for extracting specific pieces of information from document images. However existing work typically queries each field in isolation overlooking potential dependencies across multiple items. This paper investigates the merits of extracting multiple fields jointly versus separately. Through experiments on multiple large vision language models and datasets we show that jointly extracting fields often improves accuracy especially when the fields share strong numeric or contextual dependencies. We further analyze how performance scales with the number of requested items and use a regression based metric to quantify inter field relationships. Our results suggest that multi field prompts can mitigate confusion arising from similar surface forms and related numeric values providing practical methods for designing robust VQA systems in document information extraction tasks.,Joint Extraction Matters Prompt Based Visual Question Answering for Multi Field Document Information Extraction,"['extracting', 'field', 'fields', 'multiple', 'dependencies', 'document', 'information', 'items', 'jointly', 'numeric']",Visual question answering VQA has emerged as a flexible approach for extracting specific pieces of information from document images.
2503.16192v1,Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning,"This paper introduces novel Bellman mappings (B-Maps) for value iteration
(VI) in distributed reinforcement learning (DRL), where multiple agents operate
over a network without a centralized fusion node. Each agent constructs its own
nonparametric B-Map for VI while communicating only with direct neighbors to
achieve consensus. These B-Maps operate on Q-functions represented in a
reproducing kernel Hilbert space, enabling a nonparametric formulation that
allows for flexible, agent-specific basis function design. Unlike existing DRL
methods that restrict information exchange to Q-function estimates, the
proposed framework also enables agents to share basis information in the form
of covariance matrices, capturing additional structural details. A theoretical
analysis establishes linear convergence rates for both Q-function and
covariance-matrix estimates toward their consensus values. The optimal learning
rates for consensus-based updates are dictated by the ratio of the smallest
positive eigenvalue to the largest one of the network's Laplacian matrix.
Furthermore, each nodal Q-function estimate is shown to lie very close to the
fixed point of a centralized nonparametric B-Map, effectively allowing the
proposed DRL design to approximate the performance of a centralized fusion
center. Numerical experiments on two well-known control problems demonstrate
the superior performance of the proposed nonparametric B-Maps compared to prior
methods. Notably, the results reveal a counter-intuitive finding: although the
proposed approach involves greater information exchange -- specifically through
the sharing of covariance matrices -- it achieves the desired performance with
lower cumulative communication cost than existing DRL schemes, highlighting the
crucial role of basis information in accelerating the learning process.","['cs.LG', 'eess.SP']","['Yuki Akiyama', 'Konstantinos Slavakis']",2025-03-20,2025-03-20,This paper introduces novel Bellman mappings B Maps for value iteration VI in distributed reinforcement learning DRL where multiple agents operate over a network without a centralized fusion node. Each agent constructs its own nonparametric B Map for VI while communicating only with direct neighbors to achieve consensus. These B Maps operate on Q functions represented in a reproducing kernel Hilbert space enabling a nonparametric formulation that allows for flexible agent specific basis function design. Unlike existing DRL methods that restrict information exchange to Q function estimates the proposed framework also enables agents to share basis information in the form of covariance matrices capturing additional structural details. A theoretical analysis establishes linear convergence rates for both Q function and covariance matrix estimates toward their consensus values. The optimal learning rates for consensus based updates are dictated by the ratio of the smallest positive eigenvalue to the largest one of the network s Laplacian matrix. Furthermore each nodal Q function estimate is shown to lie very close to the fixed point of a centralized nonparametric B Map effectively allowing the proposed DRL design to approximate the performance of a centralized fusion center. Numerical experiments on two well known control problems demonstrate the superior performance of the proposed nonparametric B Maps compared to prior methods. Notably the results reveal a counter intuitive finding although the proposed approach involves greater information exchange specifically through the sharing of covariance matrices it achieves the desired performance with lower cumulative communication cost than existing DRL schemes highlighting the crucial role of basis information in accelerating the learning process.,Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning,"['drl', 'function', 'information', 'nonparametric', 'proposed', 'basis', 'centralized', 'consensus', 'covariance', 'learning']",This paper introduces novel Bellman mappings B Maps for value iteration VI in distributed reinforcement learning DRL where multiple agents operate over a network without a centralized fusion node.
2503.15817v1,Ranking Counterfactual Explanations,"AI-driven outcomes can be challenging for end-users to understand.
Explanations can address two key questions: ""Why this outcome?"" (factual) and
""Why not another?"" (counterfactual). While substantial efforts have been made
to formalize factual explanations, a precise and comprehensive study of
counterfactual explanations is still lacking. This paper proposes a formal
definition of counterfactual explanations, proving some properties they
satisfy, and examining the relationship with factual explanations. Given that
multiple counterfactual explanations generally exist for a specific case, we
also introduce a rigorous method to rank these counterfactual explanations,
going beyond a simple minimality condition, and to identify the optimal ones.
Our experiments with 12 real-world datasets highlight that, in most cases, a
single optimal counterfactual explanation emerges. We also demonstrate, via
three metrics, that the selected optimal explanation exhibits higher
representativeness and can explain a broader range of elements than a random
minimal counterfactual. This result highlights the effectiveness of our
approach in identifying more robust and comprehensive counterfactual
explanations.",['cs.AI'],"['Suryani Lim', 'Henri Prade', 'Gilles Richard']",2025-03-20,2025-03-20,AI driven outcomes can be challenging for end users to understand. Explanations can address two key questions Why this outcome factual and Why not another counterfactual . While substantial efforts have been made to formalize factual explanations a precise and comprehensive study of counterfactual explanations is still lacking. This paper proposes a formal definition of counterfactual explanations proving some properties they satisfy and examining the relationship with factual explanations. Given that multiple counterfactual explanations generally exist for a specific case we also introduce a rigorous method to rank these counterfactual explanations going beyond a simple minimality condition and to identify the optimal ones. Our experiments with 12 real world datasets highlight that in most cases a single optimal counterfactual explanation emerges. We also demonstrate via three metrics that the selected optimal explanation exhibits higher representativeness and can explain a broader range of elements than a random minimal counterfactual. This result highlights the effectiveness of our approach in identifying more robust and comprehensive counterfactual explanations.,Ranking Counterfactual Explanations,"['counterfactual', 'explanations', 'counterfactual explanations', 'factual', 'optimal', 'comprehensive', 'explanation', 'factual explanations', '12', 'counterfactual result']",AI driven outcomes can be challenging for end users to understand.
2503.16795v1,DCEdit: Dual-Level Controlled Image Editing via Precisely Localized Semantics,"This paper presents a novel approach to improving text-guided image editing
using diffusion-based models. Text-guided image editing task poses key
challenge of precisly locate and edit the target semantic, and previous methods
fall shorts in this aspect. Our method introduces a Precise Semantic
Localization strategy that leverages visual and textual self-attention to
enhance the cross-attention map, which can serve as a regional cues to improve
editing performance. Then we propose a Dual-Level Control mechanism for
incorporating regional cues at both feature and latent levels, offering
fine-grained control for more precise edits. To fully compare our methods with
other DiT-based approaches, we construct the RW-800 benchmark, featuring high
resolution images, long descriptive texts, real-world images, and a new text
editing task. Experimental results on the popular PIE-Bench and RW-800
benchmarks demonstrate the superior performance of our approach in preserving
background and providing accurate edits.",['cs.CV'],"['Yihan Hu', 'Jianing Peng', 'Yiheng Lin', 'Ting Liu', 'Xiaochao Qu', 'Luoqi Liu', 'Yao Zhao', 'Yunchao Wei']",2025-03-21,2025-03-21,This paper presents a novel approach to improving text guided image editing using diffusion based models. Text guided image editing task poses key challenge of precisly locate and edit the target semantic and previous methods fall shorts in this aspect. Our method introduces a Precise Semantic Localization strategy that leverages visual and textual self attention to enhance the cross attention map which can serve as a regional cues to improve editing performance. Then we propose a Dual Level Control mechanism for incorporating regional cues at both feature and latent levels offering fine grained control for more precise edits. To fully compare our methods with other DiT based approaches we construct the RW 800 benchmark featuring high resolution images long descriptive texts real world images and a new text editing task. Experimental results on the popular PIE Bench and RW 800 benchmarks demonstrate the superior performance of our approach in preserving background and providing accurate edits.,DCEdit Dual Level Controlled Image Editing via Precisely Localized Semantics,"['editing', 'text', '800', 'approach', 'attention', 'based', 'control', 'cues', 'editing task', 'edits']",This paper presents a novel approach to improving text guided image editing using diffusion based models.
2503.16728v1,Natural Language Generation,"This article provides a brief overview of the field of Natural Language
Generation. The term Natural Language Generation (NLG), in its broadest
definition, refers to the study of systems that verbalize some form of
information through natural language. That information could be stored in a
large database or knowledge graph (in data-to-text applications), but NLG
researchers may also study summarisation (text-to-text) or image captioning
(image-to-text), for example. As a subfield of Natural Language Processing, NLG
is closely related to other sub-disciplines such as Machine Translation (MT)
and Dialog Systems. Some NLG researchers exclude MT from their definition of
the field, since there is no content selection involved where the system has to
determine what to say. Conversely, dialog systems do not typically fall under
the header of Natural Language Generation since NLG is just one component of
dialog systems (the others being Natural Language Understanding and Dialog
Management). However, with the rise of Large Language Models (LLMs), different
subfields of Natural Language Processing have converged on similar
methodologies for the production of natural language and the evaluation of
automatically generated text.",['cs.CL'],"['Emiel van Miltenburg', 'Chenghua Lin']",2025-03-20,2025-03-20,This article provides a brief overview of the field of Natural Language Generation. The term Natural Language Generation NLG in its broadest definition refers to the study of systems that verbalize some form of information through natural language. That information could be stored in a large database or knowledge graph in data to text applications but NLG researchers may also study summarisation text to text or image captioning image to text for example. As a subfield of Natural Language Processing NLG is closely related to other sub disciplines such as Machine Translation MT and Dialog Systems. Some NLG researchers exclude MT from their definition of the field since there is no content selection involved where the system has to determine what to say. Conversely dialog systems do not typically fall under the header of Natural Language Generation since NLG is just one component of dialog systems the others being Natural Language Understanding and Dialog Management . However with the rise of Large Language Models LLMs different subfields of Natural Language Processing have converged on similar methodologies for the production of natural language and the evaluation of automatically generated text.,Natural Language Generation,"['language', 'natural', 'natural language', 'nlg', 'text', 'dialog', 'systems', 'dialog systems', 'generation', 'language generation']",This article provides a brief overview of the field of Natural Language Generation.
2503.17070v1,A Thorough Assessment of the Non-IID Data Impact in Federated Learning,"Federated learning (FL) allows collaborative machine learning (ML) model
training among decentralized clients' information, ensuring data privacy. The
decentralized nature of FL deals with non-independent and identically
distributed (non-IID) data. This open problem has notable consequences, such as
decreased model performance and more significant convergence times. Despite its
importance, experimental studies systematically addressing all types of data
heterogeneity (a.k.a. non-IIDness) remain scarce. We aim to fill this gap by
assessing and quantifying the non-IID effect through a thorough empirical
analysis. We use the Hellinger Distance (HD) to measure differences in
distribution among clients. Our study benchmarks four state-of-the-art
strategies for handling non-IID data, including label, feature, quantity, and
spatiotemporal skewness, under realistic and controlled conditions. This is the
first comprehensive analysis of the spatiotemporal skew effect in FL. Our
findings highlight the significant impact of label and spatiotemporal skew
non-IID types on FL model performance, with notable performance drops occurring
at specific HD thresholds. Additionally, the FL performance is heavily affected
mainly when the non-IIDness is extreme. Thus, we provide recommendations for FL
research to tackle data heterogeneity effectively. Our work represents the most
extensive examination of non-IIDness in FL, offering a robust foundation for
future research.","['cs.LG', 'cs.AI', 'stat.ML']","['Daniel M. Jimenez-Gutierrez', 'Mehrdad Hassanzadeh', 'Aris Anagnostopoulos', 'Ioannis Chatzigiannakis', 'Andrea Vitaletti']",2025-03-21,2025-03-21,Federated learning FL allows collaborative machine learning ML model training among decentralized clients information ensuring data privacy. The decentralized nature of FL deals with non independent and identically distributed non IID data. This open problem has notable consequences such as decreased model performance and more significant convergence times. Despite its importance experimental studies systematically addressing all types of data heterogeneity a.k.a. non IIDness remain scarce. We aim to fill this gap by assessing and quantifying the non IID effect through a thorough empirical analysis. We use the Hellinger Distance HD to measure differences in distribution among clients. Our study benchmarks four state of the art strategies for handling non IID data including label feature quantity and spatiotemporal skewness under realistic and controlled conditions. This is the first comprehensive analysis of the spatiotemporal skew effect in FL. Our findings highlight the significant impact of label and spatiotemporal skew non IID types on FL model performance with notable performance drops occurring at specific HD thresholds. Additionally the FL performance is heavily affected mainly when the non IIDness is extreme. Thus we provide recommendations for FL research to tackle data heterogeneity effectively. Our work represents the most extensive examination of non IIDness in FL offering a robust foundation for future research.,A Thorough Assessment of the Non IID Data Impact in Federated Learning,"['non', 'fl', 'data', 'iid', 'non iid', 'performance', 'iidness', 'model', 'non iidness', 'spatiotemporal']",Federated learning FL allows collaborative machine learning ML model training among decentralized clients information ensuring data privacy.
2503.14575v1,The Exoplanet Citizen Science Pipeline: Human Factors and Machine Learning,"We present the progress of work to streamline and simplify the process of
exoplanet observation by citizen scientists. International collaborations such
as ExoClock and Exoplanet Watch enable citizen scientists to use small
telescopes to carry out transit observations. These studies provide essential
supports for space missions such as JWST and ARIEL. Contributions include
maintenance or recovery of ephemerides, follow up confirmation and transit time
variations. Ongoing observation programs benefit from a large pool of
observers, with a wide variety of experience levels. Our projects work closely
with these communities to streamline their observation pipelines and enable
wider participation. Two complementary approaches are taken: Star Guide applies
human-centric design and community consultation to identify points of friction
within existing systems and provide complementary online tools and resources to
reduce barriers to entry to the observing community. Machine Learning is used
to accelerate data processing and automate steps which are currently manual,
providing a streamlined tool for citizen science and a scalable solution for
large-scale archival research.","['astro-ph.IM', 'astro-ph.EP', 'cs.LG']","['OisÃ­n Creaner', 'Anna Preis', 'Cormac Ryan', 'Nika Gorchakova']",2025-03-18,2025-03-18,We present the progress of work to streamline and simplify the process of exoplanet observation by citizen scientists. International collaborations such as ExoClock and Exoplanet Watch enable citizen scientists to use small telescopes to carry out transit observations. These studies provide essential supports for space missions such as JWST and ARIEL. Contributions include maintenance or recovery of ephemerides follow up confirmation and transit time variations. Ongoing observation programs benefit from a large pool of observers with a wide variety of experience levels. Our projects work closely with these communities to streamline their observation pipelines and enable wider participation. Two complementary approaches are taken Star Guide applies human centric design and community consultation to identify points of friction within existing systems and provide complementary online tools and resources to reduce barriers to entry to the observing community. Machine Learning is used to accelerate data processing and automate steps which are currently manual providing a streamlined tool for citizen science and a scalable solution for large scale archival research.,The Exoplanet Citizen Science Pipeline Human Factors and Machine Learning,"['citizen', 'observation', 'citizen scientists', 'community', 'complementary', 'enable', 'exoplanet', 'large', 'provide', 'scientists']",We present the progress of work to streamline and simplify the process of exoplanet observation by citizen scientists.
2503.14681v1,DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis,"Differentially private (DP) image synthesis aims to generate artificial
images that retain the properties of sensitive images while protecting the
privacy of individual images within the dataset. Despite recent advancements,
we find that inconsistent--and sometimes flawed--evaluation protocols have been
applied across studies. This not only impedes the understanding of current
methods but also hinders future advancements.
  To address the issue, this paper introduces DPImageBench for DP image
synthesis, with thoughtful design across several dimensions: (1) Methods. We
study eleven prominent methods and systematically characterize each based on
model architecture, pretraining strategy, and privacy mechanism. (2)
Evaluation. We include nine datasets and seven fidelity and utility metrics to
thoroughly assess them. Notably, we find that a common practice of selecting
downstream classifiers based on the highest accuracy on the sensitive test set
not only violates DP but also overestimates the utility scores. DPImageBench
corrects for these mistakes. (3) Platform. Despite the methods and evaluation
protocols, DPImageBench provides a standardized interface that accommodates
current and future implementations within a unified framework. With
DPImageBench, we have several noteworthy findings. For example, contrary to the
common wisdom that pretraining on public image datasets is usually beneficial,
we find that the distributional similarity between pretraining and sensitive
images significantly impacts the performance of the synthetic images and does
not always yield improvements. In addition, adding noise to low-dimensional
features, such as the high-level characteristics of sensitive images, is less
affected by the privacy budget compared to adding noise to high-dimensional
features, like weight gradients. The former methods perform better than the
latter under a low privacy budget.","['cs.CR', 'cs.AI']","['Chen Gong', 'Kecen Li', 'Zinan Lin', 'Tianhao Wang']",2025-03-18,2025-03-18,Differentially private DP image synthesis aims to generate artificial images that retain the properties of sensitive images while protecting the privacy of individual images within the dataset. Despite recent advancements we find that inconsistent and sometimes flawed evaluation protocols have been applied across studies. This not only impedes the understanding of current methods but also hinders future advancements. To address the issue this paper introduces DPImageBench for DP image synthesis with thoughtful design across several dimensions 1 Methods. We study eleven prominent methods and systematically characterize each based on model architecture pretraining strategy and privacy mechanism. 2 Evaluation. We include nine datasets and seven fidelity and utility metrics to thoroughly assess them. Notably we find that a common practice of selecting downstream classifiers based on the highest accuracy on the sensitive test set not only violates DP but also overestimates the utility scores. DPImageBench corrects for these mistakes. 3 Platform. Despite the methods and evaluation protocols DPImageBench provides a standardized interface that accommodates current and future implementations within a unified framework. With DPImageBench we have several noteworthy findings. For example contrary to the common wisdom that pretraining on public image datasets is usually beneficial we find that the distributional similarity between pretraining and sensitive images significantly impacts the performance of the synthetic images and does not always yield improvements. In addition adding noise to low dimensional features such as the high level characteristics of sensitive images is less affected by the privacy budget compared to adding noise to high dimensional features like weight gradients. The former methods perform better than the latter under a low privacy budget.,DPImageBench A Unified Benchmark for Differentially Private Image Synthesis,"['images', 'methods', 'dpimagebench', 'privacy', 'sensitive', 'dp', 'evaluation', 'image', 'pretraining', 'sensitive images']",Differentially private DP image synthesis aims to generate artificial images that retain the properties of sensitive images while protecting the privacy of individual images within the dataset.
2503.14476v1,DAPO: An Open-Source LLM Reinforcement Learning System at Scale,"Inference scaling empowers LLMs with unprecedented reasoning ability, with
reinforcement learning as the core technique to elicit complex reasoning.
However, key technical details of state-of-the-art reasoning LLMs are concealed
(such as in OpenAI o1 blog and DeepSeek R1 technical report), thus the
community still struggles to reproduce their RL training results. We propose
the $\textbf{D}$ecoupled Clip and $\textbf{D}$ynamic s$\textbf{A}$mpling
$\textbf{P}$olicy $\textbf{O}$ptimization ($\textbf{DAPO}$) algorithm, and
fully open-source a state-of-the-art large-scale RL system that achieves 50
points on AIME 2024 using Qwen2.5-32B base model. Unlike previous works that
withhold training details, we introduce four key techniques of our algorithm
that make large-scale LLM RL a success. In addition, we open-source our
training code, which is built on the verl framework, along with a carefully
curated and processed dataset. These components of our open-source system
enhance reproducibility and support future research in large-scale LLM RL.","['cs.LG', 'cs.CL']","['Qiying Yu', 'Zheng Zhang', 'Ruofei Zhu', 'Yufeng Yuan', 'Xiaochen Zuo', 'Yu Yue', 'Tiantian Fan', 'Gaohong Liu', 'Lingjun Liu', 'Xin Liu', 'Haibin Lin', 'Zhiqi Lin', 'Bole Ma', 'Guangming Sheng', 'Yuxuan Tong', 'Chi Zhang', 'Mofan Zhang', 'Wang Zhang', 'Hang Zhu', 'Jinhua Zhu', 'Jiaze Chen', 'Jiangjie Chen', 'Chengyi Wang', 'Hongli Yu', 'Weinan Dai', 'Yuxuan Song', 'Xiangpeng Wei', 'Hao Zhou', 'Jingjing Liu', 'Wei-Ying Ma', 'Ya-Qin Zhang', 'Lin Yan', 'Mu Qiao', 'Yonghui Wu', 'Mingxuan Wang']",2025-03-18,2025-03-18,Inference scaling empowers LLMs with unprecedented reasoning ability with reinforcement learning as the core technique to elicit complex reasoning. However key technical details of state of the art reasoning LLMs are concealed such as in OpenAI o1 blog and DeepSeek R1 technical report thus the community still struggles to reproduce their RL training results. We propose the textbf D ecoupled Clip and textbf D ynamic s textbf A mpling textbf P olicy textbf O ptimization textbf DAPO algorithm and fully open source a state of the art large scale RL system that achieves 50 points on AIME 2024 using Qwen2.5 32B base model. Unlike previous works that withhold training details we introduce four key techniques of our algorithm that make large scale LLM RL a success. In addition we open source our training code which is built on the verl framework along with a carefully curated and processed dataset. These components of our open source system enhance reproducibility and support future research in large scale LLM RL.,DAPO An Open Source LLM Reinforcement Learning System at Scale,"['textbf', 'rl', 'large', 'large scale', 'open', 'open source', 'reasoning', 'scale', 'source', 'training']",Inference scaling empowers LLMs with unprecedented reasoning ability with reinforcement learning as the core technique to elicit complex reasoning.
2503.16278v2,Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens,"Recent advancements in large language models and their multi-modal extensions
have demonstrated the effectiveness of unifying generation and understanding
through autoregressive next-token prediction. However, despite the critical
role of 3D structural generation and understanding (3D GU) in AI for science,
these tasks have largely evolved independently, with autoregressive methods
remaining underexplored. To bridge this gap, we introduce Uni-3DAR, a unified
framework that seamlessly integrates 3D GU tasks via autoregressive prediction.
At its core, Uni-3DAR employs a novel hierarchical tokenization that compresses
3D space using an octree, leveraging the inherent sparsity of 3D structures. It
then applies an additional tokenization for fine-grained structural details,
capturing key attributes such as atom types and precise spatial coordinates in
microscopic 3D structures. We further propose two optimizations to enhance
efficiency and effectiveness. The first is a two-level subtree compression
strategy, which reduces the octree token sequence by up to 8x. The second is a
masked next-token prediction mechanism tailored for dynamically varying token
positions, significantly boosting model performance. By combining these
strategies, Uni-3DAR successfully unifies diverse 3D GU tasks within a single
autoregressive framework. Extensive experiments across multiple microscopic 3D
GU tasks, including molecules, proteins, polymers, and crystals, validate its
effectiveness and versatility. Notably, Uni-3DAR surpasses previous
state-of-the-art diffusion models by a substantial margin, achieving up to
256\% relative improvement while delivering inference speeds up to 21.8x
faster. The code is publicly available at
https://github.com/dptech-corp/Uni-3DAR.","['cs.LG', 'cond-mat.mtrl-sci', 'q-bio.BM']","['Shuqi Lu', 'Haowei Lin', 'Lin Yao', 'Zhifeng Gao', 'Xiaohong Ji', 'Weinan E', 'Linfeng Zhang', 'Guolin Ke']",2025-03-20,2025-03-21,Recent advancements in large language models and their multi modal extensions have demonstrated the effectiveness of unifying generation and understanding through autoregressive next token prediction. However despite the critical role of 3D structural generation and understanding 3D GU in AI for science these tasks have largely evolved independently with autoregressive methods remaining underexplored. To bridge this gap we introduce Uni 3DAR a unified framework that seamlessly integrates 3D GU tasks via autoregressive prediction. At its core Uni 3DAR employs a novel hierarchical tokenization that compresses 3D space using an octree leveraging the inherent sparsity of 3D structures. It then applies an additional tokenization for fine grained structural details capturing key attributes such as atom types and precise spatial coordinates in microscopic 3D structures. We further propose two optimizations to enhance efficiency and effectiveness. The first is a two level subtree compression strategy which reduces the octree token sequence by up to 8x. The second is a masked next token prediction mechanism tailored for dynamically varying token positions significantly boosting model performance. By combining these strategies Uni 3DAR successfully unifies diverse 3D GU tasks within a single autoregressive framework. Extensive experiments across multiple microscopic 3D GU tasks including molecules proteins polymers and crystals validate its effectiveness and versatility. Notably Uni 3DAR surpasses previous state of the art diffusion models by a substantial margin achieving up to 256 relative improvement while delivering inference speeds up to 21.8x faster. The code is publicly available at https github.com dptech corp Uni 3DAR.,Uni 3DAR Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens,"['3d', '3dar', 'uni', 'uni 3dar', '3d gu', 'autoregressive', 'gu', 'tasks', 'token', 'effectiveness']",Recent advancements in large language models and their multi modal extensions have demonstrated the effectiveness of unifying generation and understanding through autoregressive next token prediction.
2503.16965v1,When Words Outperform Vision: VLMs Can Self-Improve Via Text-Only Training For Human-Centered Decision Making,"Embodied decision-making is fundamental for AI agents operating in real-world
environments. While Visual Language Models (VLMs) have advanced this
capability, they still struggle with complex decisions, particularly in
human-centered situations that require deep reasoning about human needs and
values. In this study, we systematically evaluate open-sourced VLMs on
multimodal human-centered decision-making tasks. We find that LLMs receiving
only textual descriptions unexpectedly outperform their VLM counterparts of
similar scale that process actual images, suggesting that visual alignment may
hinder VLM abilities. To address this challenge, we propose a novel text-only
training approach with synthesized textual data. This method strengthens VLMs'
language components and transfers the learned abilities to multimodal
inference, eliminating the need for expensive image-text paired data.
Furthermore, we show that VLMs can achieve substantial performance gains
through self-improvement, using training data generated by their LLM
counterparts rather than relying on larger teacher models like GPT-4. Our
findings establish a more efficient and scalable approach to enhancing VLMs'
human-centered decision-making capabilities, opening new avenues for optimizing
VLMs through self-improvement mechanisms.","['cs.CL', 'cs.CV']","['Zhe Hu', 'Jing Li', 'Yu Yin']",2025-03-21,2025-03-21,Embodied decision making is fundamental for AI agents operating in real world environments. While Visual Language Models VLMs have advanced this capability they still struggle with complex decisions particularly in human centered situations that require deep reasoning about human needs and values. In this study we systematically evaluate open sourced VLMs on multimodal human centered decision making tasks. We find that LLMs receiving only textual descriptions unexpectedly outperform their VLM counterparts of similar scale that process actual images suggesting that visual alignment may hinder VLM abilities. To address this challenge we propose a novel text only training approach with synthesized textual data. This method strengthens VLMs language components and transfers the learned abilities to multimodal inference eliminating the need for expensive image text paired data. Furthermore we show that VLMs can achieve substantial performance gains through self improvement using training data generated by their LLM counterparts rather than relying on larger teacher models like GPT 4. Our findings establish a more efficient and scalable approach to enhancing VLMs human centered decision making capabilities opening new avenues for optimizing VLMs through self improvement mechanisms.,When Words Outperform Vision VLMs Can Self Improve Via Text Only Training For Human Centered Decision Making,"['vlms', 'human', 'centered', 'data', 'decision', 'decision making', 'human centered', 'making', 'abilities', 'approach']",Embodied decision making is fundamental for AI agents operating in real world environments.
2503.15454v1,Evaluating Bias in Retrieval-Augmented Medical Question-Answering Systems,"Medical QA systems powered by Retrieval-Augmented Generation (RAG) models
support clinical decision-making but may introduce biases related to race,
gender, and social determinants of health. We systematically evaluate biases in
RAG-based LLM by examining demographic-sensitive queries and measuring
retrieval discrepancies. Using datasets like MMLU and MedMCQA, we analyze
retrieval overlap and correctness disparities. Our findings reveal substantial
demographic disparities within RAG pipelines, emphasizing the critical need for
retrieval methods that explicitly account for fairness to ensure equitable
clinical decision-making.",['cs.CL'],"['Yuelyu Ji', 'Hang Zhang', 'Yanshan Wang']",2025-03-19,2025-03-19,Medical QA systems powered by Retrieval Augmented Generation RAG models support clinical decision making but may introduce biases related to race gender and social determinants of health. We systematically evaluate biases in RAG based LLM by examining demographic sensitive queries and measuring retrieval discrepancies. Using datasets like MMLU and MedMCQA we analyze retrieval overlap and correctness disparities. Our findings reveal substantial demographic disparities within RAG pipelines emphasizing the critical need for retrieval methods that explicitly account for fairness to ensure equitable clinical decision making.,Evaluating Bias in Retrieval Augmented Medical Question Answering Systems,"['retrieval', 'rag', 'biases', 'clinical', 'clinical decision', 'decision', 'decision making', 'demographic', 'disparities', 'making']",Medical QA systems powered by Retrieval Augmented Generation RAG models support clinical decision making but may introduce biases related to race gender and social determinants of health.
2503.16561v1,FutureGen: LLM-RAG Approach to Generate the Future Work of Scientific Article,"The future work section of a scientific article outlines potential research
directions by identifying gaps and limitations of a current study. This section
serves as a valuable resource for early-career researchers seeking unexplored
areas and experienced researchers looking for new projects or collaborations.
In this study, we generate future work suggestions from key sections of a
scientific article alongside related papers and analyze how the trends have
evolved. We experimented with various Large Language Models (LLMs) and
integrated Retrieval-Augmented Generation (RAG) to enhance the generation
process. We incorporate a LLM feedback mechanism to improve the quality of the
generated content and propose an LLM-as-a-judge approach for evaluation. Our
results demonstrated that the RAG-based approach with LLM feedback outperforms
other methods evaluated through qualitative and quantitative metrics. Moreover,
we conduct a human evaluation to assess the LLM as an extractor and judge. The
code and dataset for this project are here, code: HuggingFace","['cs.CL', 'cs.LG']","['Ibrahim Al Azher', 'Miftahul Jannat Mokarrama', 'Zhishuai Guo', 'Sagnik Ray Choudhury', 'Hamed Alhoori']",2025-03-20,2025-03-20,The future work section of a scientific article outlines potential research directions by identifying gaps and limitations of a current study. This section serves as a valuable resource for early career researchers seeking unexplored areas and experienced researchers looking for new projects or collaborations. In this study we generate future work suggestions from key sections of a scientific article alongside related papers and analyze how the trends have evolved. We experimented with various Large Language Models LLMs and integrated Retrieval Augmented Generation RAG to enhance the generation process. We incorporate a LLM feedback mechanism to improve the quality of the generated content and propose an LLM as a judge approach for evaluation. Our results demonstrated that the RAG based approach with LLM feedback outperforms other methods evaluated through qualitative and quantitative metrics. Moreover we conduct a human evaluation to assess the LLM as an extractor and judge. The code and dataset for this project are here code HuggingFace,FutureGen LLM RAG Approach to Generate the Future Work of Scientific Article,"['llm', 'approach', 'article', 'code', 'evaluation', 'feedback', 'future', 'future work', 'generation', 'judge']",The future work section of a scientific article outlines potential research directions by identifying gaps and limitations of a current study.
2503.16194v1,Improving Autoregressive Image Generation through Coarse-to-Fine Token Prediction,"Autoregressive models have shown remarkable success in image generation by
adapting sequential prediction techniques from language modeling. However,
applying these approaches to images requires discretizing continuous pixel data
through vector quantization methods like VQ-VAE. To alleviate the quantization
errors that existed in VQ-VAE, recent works tend to use larger codebooks.
However, this will accordingly expand vocabulary size, complicating the
autoregressive modeling task. This paper aims to find a way to enjoy the
benefits of large codebooks without making autoregressive modeling more
difficult. Through empirical investigation, we discover that tokens with
similar codeword representations produce similar effects on the final generated
image, revealing significant redundancy in large codebooks. Based on this
insight, we propose to predict tokens from coarse to fine (CTF), realized by
assigning the same coarse label for similar tokens. Our framework consists of
two stages: (1) an autoregressive model that sequentially predicts coarse
labels for each token in the sequence, and (2) an auxiliary model that
simultaneously predicts fine-grained labels for all tokens conditioned on their
coarse labels. Experiments on ImageNet demonstrate our method's superior
performance, achieving an average improvement of 59 points in Inception Score
compared to baselines. Notably, despite adding an inference step, our approach
achieves faster sampling speeds.",['cs.CV'],"['Ziyao Guo', 'Kaipeng Zhang', 'Michael Qizhe Shieh']",2025-03-20,2025-03-20,Autoregressive models have shown remarkable success in image generation by adapting sequential prediction techniques from language modeling. However applying these approaches to images requires discretizing continuous pixel data through vector quantization methods like VQ VAE. To alleviate the quantization errors that existed in VQ VAE recent works tend to use larger codebooks. However this will accordingly expand vocabulary size complicating the autoregressive modeling task. This paper aims to find a way to enjoy the benefits of large codebooks without making autoregressive modeling more difficult. Through empirical investigation we discover that tokens with similar codeword representations produce similar effects on the final generated image revealing significant redundancy in large codebooks. Based on this insight we propose to predict tokens from coarse to fine CTF realized by assigning the same coarse label for similar tokens. Our framework consists of two stages 1 an autoregressive model that sequentially predicts coarse labels for each token in the sequence and 2 an auxiliary model that simultaneously predicts fine grained labels for all tokens conditioned on their coarse labels. Experiments on ImageNet demonstrate our method s superior performance achieving an average improvement of 59 points in Inception Score compared to baselines. Notably despite adding an inference step our approach achieves faster sampling speeds.,Improving Autoregressive Image Generation through Coarse to Fine Token Prediction,"['autoregressive', 'coarse', 'tokens', 'codebooks', 'labels', 'modeling', 'similar', 'autoregressive modeling', 'coarse labels', 'fine']",Autoregressive models have shown remarkable success in image generation by adapting sequential prediction techniques from language modeling.
2503.16825v1,SGFormer: Satellite-Ground Fusion for 3D Semantic Scene Completion,"Recently, camera-based solutions have been extensively explored for scene
semantic completion (SSC). Despite their success in visible areas, existing
methods struggle to capture complete scene semantics due to frequent visual
occlusions. To address this limitation, this paper presents the first
satellite-ground cooperative SSC framework, i.e., SGFormer, exploring the
potential of satellite-ground image pairs in the SSC task. Specifically, we
propose a dual-branch architecture that encodes orthogonal satellite and ground
views in parallel, unifying them into a common domain. Additionally, we design
a ground-view guidance strategy that corrects satellite image biases during
feature encoding, addressing misalignment between satellite and ground views.
Moreover, we develop an adaptive weighting strategy that balances contributions
from satellite and ground views. Experiments demonstrate that SGFormer
outperforms the state of the art on SemanticKITTI and SSCBench-KITTI-360
datasets. Our code is available on https://github.com/gxytcrc/SGFormer.","['cs.CV', 'cs.RO']","['Xiyue Guo', 'Jiarui Hu', 'Junjie Hu', 'Hujun Bao', 'Guofeng Zhang']",2025-03-21,2025-03-21,Recently camera based solutions have been extensively explored for scene semantic completion SSC . Despite their success in visible areas existing methods struggle to capture complete scene semantics due to frequent visual occlusions. To address this limitation this paper presents the first satellite ground cooperative SSC framework i.e. SGFormer exploring the potential of satellite ground image pairs in the SSC task. Specifically we propose a dual branch architecture that encodes orthogonal satellite and ground views in parallel unifying them into a common domain. Additionally we design a ground view guidance strategy that corrects satellite image biases during feature encoding addressing misalignment between satellite and ground views. Moreover we develop an adaptive weighting strategy that balances contributions from satellite and ground views. Experiments demonstrate that SGFormer outperforms the state of the art on SemanticKITTI and SSCBench KITTI 360 datasets. Our code is available on https github.com gxytcrc SGFormer.,SGFormer Satellite Ground Fusion for 3D Semantic Scene Completion,"['ground', 'satellite', 'satellite ground', 'ground views', 'sgformer', 'ssc', 'views', 'image', 'scene', 'strategy']",Recently camera based solutions have been extensively explored for scene semantic completion SSC .
2503.15235v1,Exploring Large Language Models for Word Games:Who is the Spy?,"Word games hold significant research value for natural language processing
(NLP), game theory, and related fields due to their rule-based and situational
nature. This study explores how large language models (LLMs) can be effectively
involved in word games and proposes a training-free framework. ""Shei Shi Wo Di""
or ""Who is the Spy"" in English, is a classic word game. Using this game as an
example, we introduce a Chain-of-Thought (CoT)-based scheduling framework to
enable LLMs to achieve excellent performance in tasks such as inferring role
words and disguising their identities. We evaluate the framework's performance
based on game success rates and the accuracy of the LLM agents' analytical
results. Experimental results affirm the framework's effectiveness,
demonstrating notable improvements in LLM performance across multiple datasets.
This work highlights the potential of LLMs in mastering situational reasoning
and social interactions within structured game environments. Our code is
publicly available at https://github.com/ct-wei/Who-is-The-Spy.","['cs.CL', 'cs.AI']","['Chentian Wei', 'Jiewei Chen', 'Jinzhu Xu']",2025-03-19,2025-03-19,Word games hold significant research value for natural language processing NLP game theory and related fields due to their rule based and situational nature. This study explores how large language models LLMs can be effectively involved in word games and proposes a training free framework. Shei Shi Wo Di or Who is the Spy in English is a classic word game. Using this game as an example we introduce a Chain of Thought CoT based scheduling framework to enable LLMs to achieve excellent performance in tasks such as inferring role words and disguising their identities. We evaluate the framework s performance based on game success rates and the accuracy of the LLM agents analytical results. Experimental results affirm the framework s effectiveness demonstrating notable improvements in LLM performance across multiple datasets. This work highlights the potential of LLMs in mastering situational reasoning and social interactions within structured game environments. Our code is publicly available at https github.com ct wei Who is The Spy.,Exploring Large Language Models for Word Games Who is the Spy,"['game', 'framework', 'based', 'llms', 'performance', 'word', 'games', 'language', 'llm', 'results']",Word games hold significant research value for natural language processing NLP game theory and related fields due to their rule based and situational nature.
2503.15668v1,Model Risk Management for Generative AI In Financial Institutions,"The success of OpenAI's ChatGPT in 2023 has spurred financial enterprises
into exploring Generative AI applications to reduce costs or drive revenue
within different lines of businesses in the Financial Industry. While these
applications offer strong potential for efficiencies, they introduce new model
risks, primarily hallucinations and toxicity. As highly regulated entities,
financial enterprises (primarily large US banks) are obligated to enhance their
model risk framework with additional testing and controls to ensure safe
deployment of such applications. This paper outlines the key aspects for model
risk management of generative AI model with a special emphasis on additional
practices required in model validation.","['q-fin.RM', 'cs.LG']","['Anwesha Bhattacharyya', 'Ye Yu', 'Hanyu Yang', 'Rahul Singh', 'Tarun Joshi', 'Jie Chen', 'Kiran Yalavarthy']",2025-03-19,2025-03-19,The success of OpenAI s ChatGPT in 2023 has spurred financial enterprises into exploring Generative AI applications to reduce costs or drive revenue within different lines of businesses in the Financial Industry. While these applications offer strong potential for efficiencies they introduce new model risks primarily hallucinations and toxicity. As highly regulated entities financial enterprises primarily large US banks are obligated to enhance their model risk framework with additional testing and controls to ensure safe deployment of such applications. This paper outlines the key aspects for model risk management of generative AI model with a special emphasis on additional practices required in model validation.,Model Risk Management for Generative AI In Financial Institutions,"['model', 'applications', 'financial', 'additional', 'ai', 'enterprises', 'financial enterprises', 'generative', 'generative ai', 'model risk']",The success of OpenAI s ChatGPT in 2023 has spurred financial enterprises into exploring Generative AI applications to reduce costs or drive revenue within different lines of businesses in the Financial Industry.
2503.14698v1,SplatVoxel: History-Aware Novel View Streaming without Temporal Training,"We study the problem of novel view streaming from sparse-view videos, which
aims to generate a continuous sequence of high-quality, temporally consistent
novel views as new input frames arrive. However, existing novel view synthesis
methods struggle with temporal coherence and visual fidelity, leading to
flickering and inconsistency. To address these challenges, we introduce
history-awareness, leveraging previous frames to reconstruct the scene and
improve quality and stability. We propose a hybrid splat-voxel feed-forward
scene reconstruction approach that combines Gaussian Splatting to propagate
information over time, with a hierarchical voxel grid for temporal fusion.
Gaussian primitives are efficiently warped over time using a motion graph that
extends 2D tracking models to 3D motion, while a sparse voxel transformer
integrates new temporal observations in an error-aware manner. Crucially, our
method does not require training on multi-view video datasets, which are
currently limited in size and diversity, and can be directly applied to
sparse-view video streams in a history-aware manner at inference time. Our
approach achieves state-of-the-art performance in both static and streaming
scene reconstruction, effectively reducing temporal artifacts and visual
artifacts while running at interactive rates (15 fps with 350ms delay) on a
single H100 GPU. Project Page: https://19reborn.github.io/SplatVoxel/",['cs.CV'],"['Yiming Wang', 'Lucy Chai', 'Xuan Luo', 'Michael Niemeyer', 'Manuel Lagunas', 'Stephen Lombardi', 'Siyu Tang', 'Tiancheng Sun']",2025-03-18,2025-03-18,We study the problem of novel view streaming from sparse view videos which aims to generate a continuous sequence of high quality temporally consistent novel views as new input frames arrive. However existing novel view synthesis methods struggle with temporal coherence and visual fidelity leading to flickering and inconsistency. To address these challenges we introduce history awareness leveraging previous frames to reconstruct the scene and improve quality and stability. We propose a hybrid splat voxel feed forward scene reconstruction approach that combines Gaussian Splatting to propagate information over time with a hierarchical voxel grid for temporal fusion. Gaussian primitives are efficiently warped over time using a motion graph that extends 2D tracking models to 3D motion while a sparse voxel transformer integrates new temporal observations in an error aware manner. Crucially our method does not require training on multi view video datasets which are currently limited in size and diversity and can be directly applied to sparse view video streams in a history aware manner at inference time. Our approach achieves state of the art performance in both static and streaming scene reconstruction effectively reducing temporal artifacts and visual artifacts while running at interactive rates 15 fps with 350ms delay on a single H100 GPU. Project Page https 19reborn.github.io SplatVoxel,SplatVoxel History Aware Novel View Streaming without Temporal Training,"['view', 'temporal', 'novel', 'scene', 'sparse', 'time', 'voxel', 'approach', 'artifacts', 'aware']",We study the problem of novel view streaming from sparse view videos which aims to generate a continuous sequence of high quality temporally consistent novel views as new input frames arrive.
2503.17193v1,MSCA-Net:Multi-Scale Context Aggregation Network for Infrared Small Target Detection,"Detecting infrared small targets in complex backgrounds remains a challenging
task because of the low contrast and high noise levels inherent in infrared
images. These factors often lead to the loss of crucial details during feature
extraction. Moreover, existing detection methods have limitations in adequately
integrating global and local information, which constrains the efficiency and
accuracy of infrared small target detection. To address these challenges, this
paper proposes a novel network architecture named MSCA-Net, which integrates
three key components: Multi-Scale Enhanced Detection Attention
mechanism(MSEDA), Positional Convolutional Block Attention Module (PCBAM), and
Channel Aggregation Block (CAB). Specifically, MSEDA employs a multi-scale
feature fusion attention mechanism to adaptively aggregate information across
different scales, enriching feature representation. PCBAM captures the
correlation between global and local features through a correlation
matrix-based strategy, enabling deep feature interaction. Moreover, CAB
redistributes input feature channels, facilitating the efficient transmission
of beneficial features and further enhancing the model detection capability in
complex backgrounds. The experimental results demonstrate that MSCA-Net
achieves outstanding small target detection performance in complex backgrounds.
Specifically, it attains mIoU scores of 78.43\%, 94.56\%, and 67.08\% on the
NUAA-SIRST, NUDT-SIRST, and IRTSD-1K datasets, respectively, underscoring its
effectiveness and strong potential for real-world applications.",['cs.CV'],"['Xiaojin Lu', 'Taoran yue', 'Jiaxi cai', 'Shibing Chu']",2025-03-21,2025-03-21,Detecting infrared small targets in complex backgrounds remains a challenging task because of the low contrast and high noise levels inherent in infrared images. These factors often lead to the loss of crucial details during feature extraction. Moreover existing detection methods have limitations in adequately integrating global and local information which constrains the efficiency and accuracy of infrared small target detection. To address these challenges this paper proposes a novel network architecture named MSCA Net which integrates three key components Multi Scale Enhanced Detection Attention mechanism MSEDA Positional Convolutional Block Attention Module PCBAM and Channel Aggregation Block CAB . Specifically MSEDA employs a multi scale feature fusion attention mechanism to adaptively aggregate information across different scales enriching feature representation. PCBAM captures the correlation between global and local features through a correlation matrix based strategy enabling deep feature interaction. Moreover CAB redistributes input feature channels facilitating the efficient transmission of beneficial features and further enhancing the model detection capability in complex backgrounds. The experimental results demonstrate that MSCA Net achieves outstanding small target detection performance in complex backgrounds. Specifically it attains mIoU scores of 78.43 94.56 and 67.08 on the NUAA SIRST NUDT SIRST and IRTSD 1K datasets respectively underscoring its effectiveness and strong potential for real world applications.,MSCA Net Multi Scale Context Aggregation Network for Infrared Small Target Detection,"['detection', 'feature', 'attention', 'backgrounds', 'complex', 'complex backgrounds', 'infrared', 'small', 'attention mechanism', 'block']",Detecting infrared small targets in complex backgrounds remains a challenging task because of the low contrast and high noise levels inherent in infrared images.
2503.16334v1,LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates,"Recent findings reveal that much of the knowledge in a Transformer-based
Large Language Model (LLM) is encoded in its feed-forward (FFN) layers, where
each FNN layer can be interpreted as the summation of sub-updates, each
corresponding to a weighted column vector from the FFN's value parameter matrix
that often encodes human-interpretable concepts. In light of this, we
hypothesize that model performance and behaviors can be further enhanced and
controlled by modulating the contributions of these sub-updates based on their
relevance to the input or target output style, and propose LLMBRACES, a novel
and efficient method that computes relevance scores associated with value
vectors in FFN layers and leverages these scores to dynamically adjust the
contribution of sub-updates. By optimizing sub-update contributions, LLMBRACES
refines the prediction process, leading to more accurate and reliable outputs,
much like a 'brace' providing support and stability. Moreover, LLMBRACES can be
extended to support conditional control over generation characteristics, such
as sentiment, thereby offering fine-grained steering of LLM outputs. Extensive
experiments on various LLMs-including Qwen2.5-1.5B, Llama2-7B, and
Llama3-8B-demonstrate that LLMBRACES outperforms baseline approaches in both
fine-tuning and zero-shot settings while requiring significantly fewer tunable
parameters, up to 75% fewer compared to LoRA. Furthermore, LLMBRACES excels in
sentiment-controlled generation and toxicity reduction, highlighting its
potential for flexible, controlled text generation across applications.",['cs.CL'],"['Ying Shen', 'Lifu Huang']",2025-03-20,2025-03-20,Recent findings reveal that much of the knowledge in a Transformer based Large Language Model LLM is encoded in its feed forward FFN layers where each FNN layer can be interpreted as the summation of sub updates each corresponding to a weighted column vector from the FFN s value parameter matrix that often encodes human interpretable concepts. In light of this we hypothesize that model performance and behaviors can be further enhanced and controlled by modulating the contributions of these sub updates based on their relevance to the input or target output style and propose LLMBRACES a novel and efficient method that computes relevance scores associated with value vectors in FFN layers and leverages these scores to dynamically adjust the contribution of sub updates. By optimizing sub update contributions LLMBRACES refines the prediction process leading to more accurate and reliable outputs much like a brace providing support and stability. Moreover LLMBRACES can be extended to support conditional control over generation characteristics such as sentiment thereby offering fine grained steering of LLM outputs. Extensive experiments on various LLMs including Qwen2.5 1.5B Llama2 7B and Llama3 8B demonstrate that LLMBRACES outperforms baseline approaches in both fine tuning and zero shot settings while requiring significantly fewer tunable parameters up to 75 fewer compared to LoRA. Furthermore LLMBRACES excels in sentiment controlled generation and toxicity reduction highlighting its potential for flexible controlled text generation across applications.,LLM Braces Straightening Out LLM Predictions with Relevant Sub Updates,"['llmbraces', 'sub', 'controlled', 'ffn', 'generation', 'sub updates', 'updates', 'based', 'contributions', 'fewer']",Recent findings reveal that much of the knowledge in a Transformer based Large Language Model LLM is encoded in its feed forward FFN layers where each FNN layer can be interpreted as the summation of sub updates each corresponding to a weighted column vector from the FFN s value parameter matrix that often encodes human interpretable concepts.
2503.17076v1,Halton Scheduler For Masked Generative Image Transformer,"Masked Generative Image Transformers (MaskGIT) have emerged as a scalable and
efficient image generation framework, able to deliver high-quality visuals with
low inference costs. However, MaskGIT's token unmasking scheduler, an essential
component of the framework, has not received the attention it deserves. We
analyze the sampling objective in MaskGIT, based on the mutual information
between tokens, and elucidate its shortcomings. We then propose a new sampling
strategy based on our Halton scheduler instead of the original Confidence
scheduler. More precisely, our method selects the token's position according to
a quasi-random, low-discrepancy Halton sequence. Intuitively, that method
spreads the tokens spatially, progressively covering the image uniformly at
each step. Our analysis shows that it allows reducing non-recoverable sampling
errors, leading to simpler hyper-parameters tuning and better quality images.
Our scheduler does not require retraining or noise injection and may serve as a
simple drop-in replacement for the original sampling strategy. Evaluation of
both class-to-image synthesis on ImageNet and text-to-image generation on the
COCO dataset demonstrates that the Halton scheduler outperforms the Confidence
scheduler quantitatively by reducing the FID and qualitatively by generating
more diverse and more detailed images. Our code is at
https://github.com/valeoai/Halton-MaskGIT.",['cs.CV'],"['Victor Besnier', 'Mickael Chen', 'David Hurych', 'Eduardo Valle', 'Matthieu Cord']",2025-03-21,2025-03-21,Masked Generative Image Transformers MaskGIT have emerged as a scalable and efficient image generation framework able to deliver high quality visuals with low inference costs. However MaskGIT s token unmasking scheduler an essential component of the framework has not received the attention it deserves. We analyze the sampling objective in MaskGIT based on the mutual information between tokens and elucidate its shortcomings. We then propose a new sampling strategy based on our Halton scheduler instead of the original Confidence scheduler. More precisely our method selects the token s position according to a quasi random low discrepancy Halton sequence. Intuitively that method spreads the tokens spatially progressively covering the image uniformly at each step. Our analysis shows that it allows reducing non recoverable sampling errors leading to simpler hyper parameters tuning and better quality images. Our scheduler does not require retraining or noise injection and may serve as a simple drop in replacement for the original sampling strategy. Evaluation of both class to image synthesis on ImageNet and text to image generation on the COCO dataset demonstrates that the Halton scheduler outperforms the Confidence scheduler quantitatively by reducing the FID and qualitatively by generating more diverse and more detailed images. Our code is at https github.com valeoai Halton MaskGIT.,Halton Scheduler For Masked Generative Image Transformer,"['scheduler', 'image', 'halton', 'maskgit', 'sampling', 'based', 'confidence', 'confidence scheduler', 'framework', 'generation']",Masked Generative Image Transformers MaskGIT have emerged as a scalable and efficient image generation framework able to deliver high quality visuals with low inference costs.
2503.16589v1,A Statistical Analysis for Per-Instance Evaluation of Stochastic Optimizers: How Many Repeats Are Enough?,"A key trait of stochastic optimizers is that multiple runs of the same
optimizer in attempting to solve the same problem can produce different
results. As a result, their performance is evaluated over several repeats, or
runs, on the problem. However, the accuracy of the estimated performance
metrics depends on the number of runs and should be studied using statistical
tools. We present a statistical analysis of the common metrics, and develop
guidelines for experiment design to measure the optimizer's performance using
these metrics to a high level of confidence and accuracy. To this end, we first
discuss the confidence interval of the metrics and how they are related to the
number of runs of an experiment. We then derive a lower bound on the number of
repeats in order to guarantee achieving a given accuracy in the metrics. Using
this bound, we propose an algorithm to adaptively adjust the number of repeats
needed to ensure the accuracy of the evaluated metric. Our simulation results
demonstrate the utility of our analysis and how it allows us to conduct
reliable benchmarking as well as hyperparameter tuning and prevent us from
drawing premature conclusions regarding the performance of stochastic
optimizers.","['cs.LG', 'cs.ET', 'math.ST', 'stat.TH']","['Moslem Noori', 'Elisabetta Valiante', 'Thomas Van Vaerenbergh', 'Masoud Mohseni', 'Ignacio Rozada']",2025-03-20,2025-03-20,A key trait of stochastic optimizers is that multiple runs of the same optimizer in attempting to solve the same problem can produce different results. As a result their performance is evaluated over several repeats or runs on the problem. However the accuracy of the estimated performance metrics depends on the number of runs and should be studied using statistical tools. We present a statistical analysis of the common metrics and develop guidelines for experiment design to measure the optimizer s performance using these metrics to a high level of confidence and accuracy. To this end we first discuss the confidence interval of the metrics and how they are related to the number of runs of an experiment. We then derive a lower bound on the number of repeats in order to guarantee achieving a given accuracy in the metrics. Using this bound we propose an algorithm to adaptively adjust the number of repeats needed to ensure the accuracy of the evaluated metric. Our simulation results demonstrate the utility of our analysis and how it allows us to conduct reliable benchmarking as well as hyperparameter tuning and prevent us from drawing premature conclusions regarding the performance of stochastic optimizers.,A Statistical Analysis for Per Instance Evaluation of Stochastic Optimizers How Many Repeats Are Enough,"['metrics', 'accuracy', 'number', 'performance', 'runs', 'repeats', 'using', 'analysis', 'bound', 'confidence']",A key trait of stochastic optimizers is that multiple runs of the same optimizer in attempting to solve the same problem can produce different results.
2503.14393v1,On the clustering behavior of sliding windows,"Things can go spectacularly wrong when clustering timeseries data that has
been preprocessed with a sliding window. We highlight three surprising failures
that emerge depending on how the window size compares with the timeseries
length. In addition to computational examples, we present theoretical
explanations for each of these failure modes.",['cs.LG'],"['Boris Alexeev', 'Wenyan Luo', 'Dustin G. Mixon', 'Yan X Zhang']",2025-03-18,2025-03-18,Things can go spectacularly wrong when clustering timeseries data that has been preprocessed with a sliding window. We highlight three surprising failures that emerge depending on how the window size compares with the timeseries length. In addition to computational examples we present theoretical explanations for each of these failure modes.,On the clustering behavior of sliding windows,"['timeseries', 'window', 'addition', 'addition computational', 'clustering', 'clustering timeseries', 'compares', 'compares timeseries', 'computational', 'computational examples']",Things can go spectacularly wrong when clustering timeseries data that has been preprocessed with a sliding window.
2503.16399v1,SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World,"Existing vision-based 3D occupancy prediction methods are inherently limited
in accuracy due to their exclusive reliance on street-view imagery, neglecting
the potential benefits of incorporating satellite views. We propose SA-Occ, the
first Satellite-Assisted 3D occupancy prediction model, which leverages GPS &
IMU to integrate historical yet readily available satellite imagery into
real-time applications, effectively mitigating limitations of ego-vehicle
perceptions, involving occlusions and degraded performance in distant regions.
To address the core challenges of cross-view perception, we propose: 1)
Dynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions
caused by the temporal asynchrony between satellite and street views; 2)
3D-Proj Guidance, a module that enhances 3D feature extraction from inherently
2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the
sampling density between street and satellite views. Evaluated on
Occ3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among
single-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring
only 6.93 ms of additional latency per frame. Our code and newly curated
dataset are available at https://github.com/chenchen235/SA-Occ.","['cs.CV', 'cs.AI']","['Chen Chen', 'Zhirui Wang', 'Taowei Sheng', 'Yi Jiang', 'Yundu Li', 'Peirui Cheng', 'Luning Zhang', 'Kaiqiang Chen', 'Yanfeng Hu', 'Xue Yang', 'Xian Sun']",2025-03-20,2025-03-20,Existing vision based 3D occupancy prediction methods are inherently limited in accuracy due to their exclusive reliance on street view imagery neglecting the potential benefits of incorporating satellite views. We propose SA Occ the first Satellite Assisted 3D occupancy prediction model which leverages GPS IMU to integrate historical yet readily available satellite imagery into real time applications effectively mitigating limitations of ego vehicle perceptions involving occlusions and degraded performance in distant regions. To address the core challenges of cross view perception we propose 1 Dynamic Decoupling Fusion which resolves inconsistencies in dynamic regions caused by the temporal asynchrony between satellite and street views 2 3D Proj Guidance a module that enhances 3D feature extraction from inherently 2D satellite imagery and 3 Uniform Sampling Alignment which aligns the sampling density between street and satellite views. Evaluated on Occ3D nuScenes SA Occ achieves state of the art performance especially among single frame methods with a 39.05 mIoU a 6.97 improvement while incurring only 6.93 ms of additional latency per frame. Our code and newly curated dataset are available at https github.com chenchen235 SA Occ.,SA Occ Satellite Assisted 3D Occupancy Prediction in Real World,"['satellite', '3d', 'imagery', 'occ', 'sa', 'sa occ', 'street', 'views', '3d occupancy', 'available']",Existing vision based 3D occupancy prediction methods are inherently limited in accuracy due to their exclusive reliance on street view imagery neglecting the potential benefits of incorporating satellite views.
2503.16611v1,A Recipe for Generating 3D Worlds From a Single Image,"We introduce a recipe for generating immersive 3D worlds from a single image
by framing the task as an in-context learning problem for 2D inpainting models.
This approach requires minimal training and uses existing generative models.
Our process involves two steps: generating coherent panoramas using a
pre-trained diffusion model and lifting these into 3D with a metric depth
estimator. We then fill unobserved regions by conditioning the inpainting model
on rendered point clouds, requiring minimal fine-tuning. Tested on both
synthetic and real images, our method produces high-quality 3D environments
suitable for VR display. By explicitly modeling the 3D structure of the
generated environment from the start, our approach consistently outperforms
state-of-the-art, video synthesis-based methods along multiple quantitative
image quality metrics. Project Page: https://katjaschwarz.github.io/worlds/","['cs.CV', 'cs.AI', 'cs.LG']","['Katja Schwarz', 'Denys Rozumnyi', 'Samuel Rota BulÃ²', 'Lorenzo Porzi', 'Peter Kontschieder']",2025-03-20,2025-03-20,We introduce a recipe for generating immersive 3D worlds from a single image by framing the task as an in context learning problem for 2D inpainting models. This approach requires minimal training and uses existing generative models. Our process involves two steps generating coherent panoramas using a pre trained diffusion model and lifting these into 3D with a metric depth estimator. We then fill unobserved regions by conditioning the inpainting model on rendered point clouds requiring minimal fine tuning. Tested on both synthetic and real images our method produces high quality 3D environments suitable for VR display. By explicitly modeling the 3D structure of the generated environment from the start our approach consistently outperforms state of the art video synthesis based methods along multiple quantitative image quality metrics. Project Page https katjaschwarz.github.io worlds,A Recipe for Generating 3D Worlds From a Single Image,"['3d', 'approach', 'generating', 'image', 'inpainting', 'minimal', 'model', 'models', 'quality', 'worlds']",We introduce a recipe for generating immersive 3D worlds from a single image by framing the task as an in context learning problem for 2D inpainting models.
2503.14604v1,Image Captioning Evaluation in the Age of Multimodal LLMs: Challenges and Future Perspectives,"The evaluation of machine-generated image captions is a complex and evolving
challenge. With the advent of Multimodal Large Language Models (MLLMs), image
captioning has become a core task, increasing the need for robust and reliable
evaluation metrics. This survey provides a comprehensive overview of
advancements in image captioning evaluation, analyzing the evolution,
strengths, and limitations of existing metrics. We assess these metrics across
multiple dimensions, including correlation with human judgment, ranking
accuracy, and sensitivity to hallucinations. Additionally, we explore the
challenges posed by the longer and more detailed captions generated by MLLMs
and examine the adaptability of current metrics to these stylistic variations.
Our analysis highlights some limitations of standard evaluation approaches and
suggests promising directions for future research in image captioning
assessment.","['cs.CV', 'cs.AI', 'cs.CL']","['Sara Sarto', 'Marcella Cornia', 'Rita Cucchiara']",2025-03-18,2025-03-18,The evaluation of machine generated image captions is a complex and evolving challenge. With the advent of Multimodal Large Language Models MLLMs image captioning has become a core task increasing the need for robust and reliable evaluation metrics. This survey provides a comprehensive overview of advancements in image captioning evaluation analyzing the evolution strengths and limitations of existing metrics. We assess these metrics across multiple dimensions including correlation with human judgment ranking accuracy and sensitivity to hallucinations. Additionally we explore the challenges posed by the longer and more detailed captions generated by MLLMs and examine the adaptability of current metrics to these stylistic variations. Our analysis highlights some limitations of standard evaluation approaches and suggests promising directions for future research in image captioning assessment.,Image Captioning Evaluation in the Age of Multimodal LLMs Challenges and Future Perspectives,"['evaluation', 'image', 'metrics', 'captioning', 'image captioning', 'captions', 'generated', 'limitations', 'mllms', 'accuracy']",The evaluation of machine generated image captions is a complex and evolving challenge.
2503.15621v1,LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning,"Recent progress in Multimodal Large Language Models (MLLMs) has highlighted
the critical roles of both the visual backbone and the underlying language
model. While prior work has primarily focused on scaling these components to
billions of parameters, the trade-offs between model size, architecture, and
performance remain underexplored. Additionally, inconsistencies in training
data and evaluation protocols have hindered direct comparisons, making it
difficult to derive optimal design choices. In this paper, we introduce
LLaVA-MORE, a new family of MLLMs that integrates recent language models with
diverse visual backbones. To ensure fair comparisons, we employ a unified
training protocol applied consistently across all architectures. Our analysis
systematically explores both small- and medium-scale LLMs -- including Phi-4,
LLaMA-3.1, and Gemma-2 -- to evaluate multimodal reasoning, generation, and
instruction following, while examining the relationship between model size and
performance. Beyond evaluating the LLM impact on final results, we conduct a
comprehensive study of various visual encoders, ranging from CLIP-based
architectures to alternatives such as DINOv2, SigLIP, and SigLIP2. Additional
experiments investigate the effects of increased image resolution and
variations in pre-training datasets. Overall, our results provide insights into
the design of more effective MLLMs, offering a reproducible evaluation
framework that facilitates direct comparisons and can guide future model
development. Our source code and trained models are publicly available at:
https://github.com/aimagelab/LLaVA-MORE.","['cs.CV', 'cs.AI', 'cs.CL', 'cs.MM']","['Federico Cocchi', 'Nicholas Moratelli', 'Davide Caffagni', 'Sara Sarto', 'Lorenzo Baraldi', 'Marcella Cornia', 'Rita Cucchiara']",2025-03-19,2025-03-19,Recent progress in Multimodal Large Language Models MLLMs has highlighted the critical roles of both the visual backbone and the underlying language model. While prior work has primarily focused on scaling these components to billions of parameters the trade offs between model size architecture and performance remain underexplored. Additionally inconsistencies in training data and evaluation protocols have hindered direct comparisons making it difficult to derive optimal design choices. In this paper we introduce LLaVA MORE a new family of MLLMs that integrates recent language models with diverse visual backbones. To ensure fair comparisons we employ a unified training protocol applied consistently across all architectures. Our analysis systematically explores both small and medium scale LLMs including Phi 4 LLaMA 3.1 and Gemma 2 to evaluate multimodal reasoning generation and instruction following while examining the relationship between model size and performance. Beyond evaluating the LLM impact on final results we conduct a comprehensive study of various visual encoders ranging from CLIP based architectures to alternatives such as DINOv2 SigLIP and SigLIP2. Additional experiments investigate the effects of increased image resolution and variations in pre training datasets. Overall our results provide insights into the design of more effective MLLMs offering a reproducible evaluation framework that facilitates direct comparisons and can guide future model development. Our source code and trained models are publicly available at https github.com aimagelab LLaVA MORE.,LLaVA MORE A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning,"['model', 'comparisons', 'language', 'mllms', 'models', 'training', 'visual', 'architectures', 'design', 'direct']",Recent progress in Multimodal Large Language Models MLLMs has highlighted the critical roles of both the visual backbone and the underlying language model.
2503.16013v1,GraspCoT: Integrating Physical Property Reasoning for 6-DoF Grasping under Flexible Language Instructions,"Flexible instruction-guided 6-DoF grasping is a significant yet challenging
task for real-world robotic systems. Existing methods utilize the contextual
understanding capabilities of the large language models (LLMs) to establish
mappings between expressions and targets, allowing robots to comprehend users'
intentions in the instructions. However, the LLM's knowledge about objects'
physical properties remains underexplored despite its tight relevance to
grasping. In this work, we propose GraspCoT, a 6-DoF grasp detection framework
that integrates a Chain-of-Thought (CoT) reasoning mechanism oriented to
physical properties, guided by auxiliary question-answering (QA) tasks.
Particularly, we design a set of QA templates to enable hierarchical reasoning
that includes three stages: target parsing, physical property analysis, and
grasp action selection. Moreover, GraspCoT presents a unified multimodal LLM
architecture, which encodes multi-view observations of 3D scenes into 3D-aware
visual tokens, and then jointly embeds these visual tokens with CoT-derived
textual tokens within LLMs to generate grasp pose predictions. Furthermore, we
present IntentGrasp, a large-scale benchmark that fills the gap in public
datasets for multi-object grasp detection under diverse and indirect verbal
commands. Extensive experiments on IntentGrasp demonstrate the superiority of
our method, with additional validation in real-world robotic applications
confirming its practicality. Codes and data will be released.","['cs.RO', 'cs.CV']","['Xiaomeng Chu', 'Jiajun Deng', 'Guoliang You', 'Wei Liu', 'Xingchen Li', 'Jianmin Ji', 'Yanyong Zhang']",2025-03-20,2025-03-20,Flexible instruction guided 6 DoF grasping is a significant yet challenging task for real world robotic systems. Existing methods utilize the contextual understanding capabilities of the large language models LLMs to establish mappings between expressions and targets allowing robots to comprehend users intentions in the instructions. However the LLM s knowledge about objects physical properties remains underexplored despite its tight relevance to grasping. In this work we propose GraspCoT a 6 DoF grasp detection framework that integrates a Chain of Thought CoT reasoning mechanism oriented to physical properties guided by auxiliary question answering QA tasks. Particularly we design a set of QA templates to enable hierarchical reasoning that includes three stages target parsing physical property analysis and grasp action selection. Moreover GraspCoT presents a unified multimodal LLM architecture which encodes multi view observations of 3D scenes into 3D aware visual tokens and then jointly embeds these visual tokens with CoT derived textual tokens within LLMs to generate grasp pose predictions. Furthermore we present IntentGrasp a large scale benchmark that fills the gap in public datasets for multi object grasp detection under diverse and indirect verbal commands. Extensive experiments on IntentGrasp demonstrate the superiority of our method with additional validation in real world robotic applications confirming its practicality. Codes and data will be released.,GraspCoT Integrating Physical Property Reasoning for 6 DoF Grasping under Flexible Language Instructions,"['grasp', 'physical', 'tokens', '3d', 'cot', 'detection', 'dof', 'grasp detection', 'graspcot', 'grasping']",Flexible instruction guided 6 DoF grasping is a significant yet challenging task for real world robotic systems.
2503.14873v1,Robust Support Vector Machines for Imbalanced and Noisy Data via Benders Decomposition,"This study introduces a novel formulation to enhance Support Vector Machines
(SVMs) in handling class imbalance and noise. Unlike the conventional Soft
Margin SVM, which penalizes the magnitude of constraint violations, the
proposed model quantifies the number of violations and aims to minimize their
frequency. To achieve this, a binary variable is incorporated into the
objective function of the primal SVM formulation, replacing the traditional
slack variable. Furthermore, each misclassified sample is assigned a priority
and an associated constraint. The resulting formulation is a mixed-integer
programming model, efficiently solved using Benders decomposition. The proposed
model's performance was benchmarked against existing models, including Soft
Margin SVM, weighted SVM, and NuSVC. Two primary hypotheses were examined: 1)
The proposed model improves the F1-score for the minority class in imbalanced
classification tasks. 2) The proposed model enhances classification accuracy in
noisy datasets. These hypotheses were evaluated using a Wilcoxon test across
multiple publicly available datasets from the OpenML repository. The results
supported both hypotheses (\( p < 0.05 \)). In addition, the proposed model
exhibited several interesting properties, such as improved robustness to noise,
a decision boundary shift favoring the minority class, a reduced number of
support vectors, and decreased prediction time. The open-source Python
implementation of the proposed SVM model is available.",['cs.LG'],"['Seyed Mojtaba Mohasel', 'Hamidreza Koosha']",2025-03-19,2025-03-19,This study introduces a novel formulation to enhance Support Vector Machines SVMs in handling class imbalance and noise. Unlike the conventional Soft Margin SVM which penalizes the magnitude of constraint violations the proposed model quantifies the number of violations and aims to minimize their frequency. To achieve this a binary variable is incorporated into the objective function of the primal SVM formulation replacing the traditional slack variable. Furthermore each misclassified sample is assigned a priority and an associated constraint. The resulting formulation is a mixed integer programming model efficiently solved using Benders decomposition. The proposed model s performance was benchmarked against existing models including Soft Margin SVM weighted SVM and NuSVC. Two primary hypotheses were examined 1 The proposed model improves the F1 score for the minority class in imbalanced classification tasks. 2 The proposed model enhances classification accuracy in noisy datasets. These hypotheses were evaluated using a Wilcoxon test across multiple publicly available datasets from the OpenML repository. The results supported both hypotheses p 0.05 . In addition the proposed model exhibited several interesting properties such as improved robustness to noise a decision boundary shift favoring the minority class a reduced number of support vectors and decreased prediction time. The open source Python implementation of the proposed SVM model is available.,Robust Support Vector Machines for Imbalanced and Noisy Data via Benders Decomposition,"['model', 'proposed', 'proposed model', 'svm', 'class', 'formulation', 'hypotheses', 'available', 'classification', 'constraint']",This study introduces a novel formulation to enhance Support Vector Machines SVMs in handling class imbalance and noise.
2503.15706v1,Using machine learning to map simulated noisy and laser-limited multidimensional spectra to molecular electronic couplings,"Two-dimensional electronic spectroscopy (2DES) has enabled significant
discoveries in both biological and synthetic energy-transducing systems.
Although deriving chemical information from 2DES is a complex task, machine
learning (ML) offers exciting opportunities to translate complicated
spectroscopic data into physical insight. Recent studies have found that neural
networks (NNs) can map simulated multidimensional spectra to molecular-scale
properties with high accuracy. However, simulations often do not capture
experimental factors that influence real spectra, including noise and
suboptimal pulse resonance conditions, bringing into question the experimental
utility of NNs trained on simulated data. Here, we show how factors associated
with experimental 2D spectral data influence the ability of NNs to map
simulated 2DES spectra onto underlying intermolecular electronic couplings. By
systematically introducing multisourced noise into a library of 356000
simulated 2D spectra, we show that noise does not hamper NN performance for
spectra exceeding threshold signal-to-noise ratios (SNR) (> 6.6 if background
noise dominates vs. > 2.5 for intensity-dependent noise). In stark contrast to
human-based analyses of 2DES data, we find that the NN accuracy improves
significantly (ca. 84% $\rightarrow$ 96%) when the data are constrained by the
bandwidth and center frequency of the pump pulses. This result is consistent
with the NN learning the optical trends described by Kasha's theory of
molecular excitons. Our findings convey positive prospects for adapting
simulation-trained NNs to extract molecular properties from inherently
imperfect experimental 2DES data. More broadly, we propose that machine-learned
perspectives of nonlinear spectroscopic data may produce unique and, perhaps,
counterintuitive guidelines for experimental design.","['physics.chem-ph', 'cs.LG', 'quant-ph']","['Jonathan D. Schultz', 'Kelsey A. Parker', 'Bashir Sbaiti', 'David N. Beratan']",2025-03-19,2025-03-19,Two dimensional electronic spectroscopy 2DES has enabled significant discoveries in both biological and synthetic energy transducing systems. Although deriving chemical information from 2DES is a complex task machine learning ML offers exciting opportunities to translate complicated spectroscopic data into physical insight. Recent studies have found that neural networks NNs can map simulated multidimensional spectra to molecular scale properties with high accuracy. However simulations often do not capture experimental factors that influence real spectra including noise and suboptimal pulse resonance conditions bringing into question the experimental utility of NNs trained on simulated data. Here we show how factors associated with experimental 2D spectral data influence the ability of NNs to map simulated 2DES spectra onto underlying intermolecular electronic couplings. By systematically introducing multisourced noise into a library of 356000 simulated 2D spectra we show that noise does not hamper NN performance for spectra exceeding threshold signal to noise ratios SNR 6.6 if background noise dominates vs. 2.5 for intensity dependent noise . In stark contrast to human based analyses of 2DES data we find that the NN accuracy improves significantly ca. 84 rightarrow 96 when the data are constrained by the bandwidth and center frequency of the pump pulses. This result is consistent with the NN learning the optical trends described by Kasha s theory of molecular excitons. Our findings convey positive prospects for adapting simulation trained NNs to extract molecular properties from inherently imperfect experimental 2DES data. More broadly we propose that machine learned perspectives of nonlinear spectroscopic data may produce unique and perhaps counterintuitive guidelines for experimental design.,Using machine learning to map simulated noisy and laser limited multidimensional spectra to molecular electronic couplings,"['data', 'noise', '2des', 'experimental', 'spectra', 'nns', 'simulated', 'molecular', 'nn', '2d']",Two dimensional electronic spectroscopy 2DES has enabled significant discoveries in both biological and synthetic energy transducing systems.
2503.15559v1,Advanced Relay-Based Collaborative Framework for Optimizing Synchronization in Split Federated Learning over Wireless Networks,"Split Federated Learning (SFL) offers a promising approach for distributed
model training in edge computing, combining the strengths of split learning in
reducing computational demands on edge devices and enhancing data privacy, with
the role of federated aggregation to ensure model convergence and
synchronization across users. However, synchronization issues caused by user
heterogeneity have hindered the development of the framework. To optimize
synchronization efficiency among users and improve overall system performance,
we propose a collaborative SFL framework (CSFL). Based on the model's
partitioning capabilities, we design a mechanism called the collaborative relay
optimization mechanism (CROM), where the assistance provided by high-efficiency
users is seen as a relay process, with the portion of the model they compute
acting as the relay point. Wireless communication between users facilitates
real-time collaboration, allowing high-efficiency users to assist bottleneck
users in handling part of the model's computation, thereby alleviating the
computational load on bottleneck users. Simulation results show that our
proposed CSFL framework reduces synchronization delays and improves overall
system throughput while maintaining similar performance and convergence rate to
the SFL framework. This demonstrates that the collaboration not only reduces
synchronization waiting time but also accelerates model convergence.",['cs.LG'],"['Haoran Gao', 'Samuel D. Okegbile', 'Jun Cai']",2025-03-18,2025-03-18,Split Federated Learning SFL offers a promising approach for distributed model training in edge computing combining the strengths of split learning in reducing computational demands on edge devices and enhancing data privacy with the role of federated aggregation to ensure model convergence and synchronization across users. However synchronization issues caused by user heterogeneity have hindered the development of the framework. To optimize synchronization efficiency among users and improve overall system performance we propose a collaborative SFL framework CSFL . Based on the model s partitioning capabilities we design a mechanism called the collaborative relay optimization mechanism CROM where the assistance provided by high efficiency users is seen as a relay process with the portion of the model they compute acting as the relay point. Wireless communication between users facilitates real time collaboration allowing high efficiency users to assist bottleneck users in handling part of the model s computation thereby alleviating the computational load on bottleneck users. Simulation results show that our proposed CSFL framework reduces synchronization delays and improves overall system throughput while maintaining similar performance and convergence rate to the SFL framework. This demonstrates that the collaboration not only reduces synchronization waiting time but also accelerates model convergence.,Advanced Relay Based Collaborative Framework for Optimizing Synchronization in Split Federated Learning over Wireless Networks,"['users', 'model', 'synchronization', 'framework', 'convergence', 'efficiency', 'efficiency users', 'relay', 'sfl', 'bottleneck']",Split Federated Learning SFL offers a promising approach for distributed model training in edge computing combining the strengths of split learning in reducing computational demands on edge devices and enhancing data privacy with the role of federated aggregation to ensure model convergence and synchronization across users.
2503.16664v1,TextBite: A Historical Czech Document Dataset for Logical Page Segmentation,"Logical page segmentation is an important step in document analysis, enabling
better semantic representations, information retrieval, and text understanding.
Previous approaches define logical segmentation either through text or
geometric objects, relying on OCR or precise geometry. To avoid the need for
OCR, we define the task purely as segmentation in the image domain.
Furthermore, to ensure the evaluation remains unaffected by geometrical
variations that do not impact text segmentation, we propose to use only
foreground text pixels in the evaluation metric and disregard all background
pixels. To support research in logical document segmentation, we introduce
TextBite, a dataset of historical Czech documents spanning the 18th to 20th
centuries, featuring diverse layouts from newspapers, dictionaries, and
handwritten records. The dataset comprises 8,449 page images with 78,863
annotated segments of logically and thematically coherent text. We propose a
set of baseline methods combining text region detection and relation
prediction. The dataset, baselines and evaluation framework can be accessed at
https://github.com/DCGM/textbite-dataset.",['cs.CV'],"['Martin KostelnÃ­k', 'Karel BeneÅ¡', 'Michal HradiÅ¡']",2025-03-20,2025-03-20,Logical page segmentation is an important step in document analysis enabling better semantic representations information retrieval and text understanding. Previous approaches define logical segmentation either through text or geometric objects relying on OCR or precise geometry. To avoid the need for OCR we define the task purely as segmentation in the image domain. Furthermore to ensure the evaluation remains unaffected by geometrical variations that do not impact text segmentation we propose to use only foreground text pixels in the evaluation metric and disregard all background pixels. To support research in logical document segmentation we introduce TextBite a dataset of historical Czech documents spanning the 18th to 20th centuries featuring diverse layouts from newspapers dictionaries and handwritten records. The dataset comprises 8 449 page images with 78 863 annotated segments of logically and thematically coherent text. We propose a set of baseline methods combining text region detection and relation prediction. The dataset baselines and evaluation framework can be accessed at https github.com DCGM textbite dataset.,TextBite A Historical Czech Document Dataset for Logical Page Segmentation,"['text', 'segmentation', 'dataset', 'evaluation', 'logical', 'define', 'document', 'ocr', 'page', 'pixels']",Logical page segmentation is an important step in document analysis enabling better semantic representations information retrieval and text understanding.
2503.15685v1,Robotic Paper Wrapping by Learning Force Control,"Robotic packaging using wrapping paper poses significant challenges due to
the material's complex deformation properties. The packaging process itself
involves multiple steps, primarily categorized as folding the paper or creating
creases. Small deviations in the robot's arm trajectory or force vector can
lead to tearing or wrinkling of the paper, exacerbated by the variability in
material properties.
  This study introduces a novel framework that combines imitation learning and
reinforcement learning to enable a robot to perform each step of the packaging
process efficiently. The framework allows the robot to follow approximate
trajectories of the tool-center point (TCP) based on human demonstrations while
optimizing force control parameters to prevent tearing or wrinkling, even with
variable wrapping paper materials.
  The proposed method was validated through ablation studies, which
demonstrated successful task completion with a significant reduction in tear
and wrinkle rates. Furthermore, the force control strategy proved to be
adaptable across different wrapping paper materials and robust against
variations in the size of the target object.","['cs.RO', 'cs.LG']","['Hiroki Hanai', 'Takuya Kiyokawa', 'Weiwei Wan', 'Kensuke Harada']",2025-03-19,2025-03-19,Robotic packaging using wrapping paper poses significant challenges due to the material s complex deformation properties. The packaging process itself involves multiple steps primarily categorized as folding the paper or creating creases. Small deviations in the robot s arm trajectory or force vector can lead to tearing or wrinkling of the paper exacerbated by the variability in material properties. This study introduces a novel framework that combines imitation learning and reinforcement learning to enable a robot to perform each step of the packaging process efficiently. The framework allows the robot to follow approximate trajectories of the tool center point TCP based on human demonstrations while optimizing force control parameters to prevent tearing or wrinkling even with variable wrapping paper materials. The proposed method was validated through ablation studies which demonstrated successful task completion with a significant reduction in tear and wrinkle rates. Furthermore the force control strategy proved to be adaptable across different wrapping paper materials and robust against variations in the size of the target object.,Robotic Paper Wrapping by Learning Force Control,"['paper', 'force', 'packaging', 'robot', 'wrapping', 'wrapping paper', 'control', 'force control', 'framework', 'learning']",Robotic packaging using wrapping paper poses significant challenges due to the material s complex deformation properties.
2503.17290v1,Calibration Strategies for Robust Causal Estimation: Theoretical and Empirical Insights on Propensity Score Based Estimators,"The partitioning of data for estimation and calibration critically impacts
the performance of propensity score based estimators like inverse probability
weighting (IPW) and double/debiased machine learning (DML) frameworks. We
extend recent advances in calibration techniques for propensity score
estimation, improving the robustness of propensity scores in challenging
settings such as limited overlap, small sample sizes, or unbalanced data. Our
contributions are twofold: First, we provide a theoretical analysis of the
properties of calibrated estimators in the context of DML. To this end, we
refine existing calibration frameworks for propensity score models, with a
particular emphasis on the role of sample-splitting schemes in ensuring valid
causal inference. Second, through extensive simulations, we show that
calibration reduces variance of inverse-based propensity score estimators while
also mitigating bias in IPW, even in small-sample regimes. Notably, calibration
improves stability for flexible learners (e.g., gradient boosting) while
preserving the doubly robust properties of DML. A key insight is that, even
when methods perform well without calibration, incorporating a calibration step
does not degrade performance, provided that an appropriate sample-splitting
approach is chosen.","['stat.ML', 'cs.LG', 'econ.EM', 'stat.ME']","['Jan Rabenseifner', 'Sven Klaassen', 'Jannis Kueck', 'Philipp Bach']",2025-03-21,2025-03-21,The partitioning of data for estimation and calibration critically impacts the performance of propensity score based estimators like inverse probability weighting IPW and double debiased machine learning DML frameworks. We extend recent advances in calibration techniques for propensity score estimation improving the robustness of propensity scores in challenging settings such as limited overlap small sample sizes or unbalanced data. Our contributions are twofold First we provide a theoretical analysis of the properties of calibrated estimators in the context of DML. To this end we refine existing calibration frameworks for propensity score models with a particular emphasis on the role of sample splitting schemes in ensuring valid causal inference. Second through extensive simulations we show that calibration reduces variance of inverse based propensity score estimators while also mitigating bias in IPW even in small sample regimes. Notably calibration improves stability for flexible learners e.g. gradient boosting while preserving the doubly robust properties of DML. A key insight is that even when methods perform well without calibration incorporating a calibration step does not degrade performance provided that an appropriate sample splitting approach is chosen.,Calibration Strategies for Robust Causal Estimation Theoretical and Empirical Insights on Propensity Score Based Estimators,"['calibration', 'propensity', 'propensity score', 'sample', 'score', 'dml', 'estimators', 'based', 'data', 'estimation']",The partitioning of data for estimation and calibration critically impacts the performance of propensity score based estimators like inverse probability weighting IPW and double debiased machine learning DML frameworks.
2503.17276v1,HyperNVD: Accelerating Neural Video Decomposition via Hypernetworks,"Decomposing a video into a layer-based representation is crucial for easy
video editing for the creative industries, as it enables independent editing of
specific layers. Existing video-layer decomposition models rely on implicit
neural representations (INRs) trained independently for each video, making the
process time-consuming when applied to new videos. Noticing this limitation, we
propose a meta-learning strategy to learn a generic video decomposition model
to speed up the training on new videos. Our model is based on a hypernetwork
architecture which, given a video-encoder embedding, generates the parameters
for a compact INR-based neural video decomposition model. Our strategy
mitigates the problem of single-video overfitting and, importantly, shortens
the convergence of video decomposition on new, unseen videos. Our code is
available at: https://hypernvd.github.io/",['cs.CV'],"['Maria Pilligua', 'Danna Xue', 'Javier Vazquez-Corral']",2025-03-21,2025-03-21,Decomposing a video into a layer based representation is crucial for easy video editing for the creative industries as it enables independent editing of specific layers. Existing video layer decomposition models rely on implicit neural representations INRs trained independently for each video making the process time consuming when applied to new videos. Noticing this limitation we propose a meta learning strategy to learn a generic video decomposition model to speed up the training on new videos. Our model is based on a hypernetwork architecture which given a video encoder embedding generates the parameters for a compact INR based neural video decomposition model. Our strategy mitigates the problem of single video overfitting and importantly shortens the convergence of video decomposition on new unseen videos. Our code is available at https hypernvd.github.io,HyperNVD Accelerating Neural Video Decomposition via Hypernetworks,"['video', 'decomposition', 'based', 'model', 'new', 'video decomposition', 'videos', 'decomposition model', 'editing', 'layer']",Decomposing a video into a layer based representation is crucial for easy video editing for the creative industries as it enables independent editing of specific layers.
2503.15465v1,FP4DiT: Towards Effective Floating Point Quantization for Diffusion Transformers,"Diffusion Models (DM) have revolutionized the text-to-image visual generation
process. However, the large computational cost and model footprint of DMs
hinders practical deployment, especially on edge devices. Post-training
quantization (PTQ) is a lightweight method to alleviate these burdens without
the need for training or fine-tuning. While recent DM PTQ methods achieve W4A8
on integer-based PTQ, two key limitations remain: First, while most existing DM
PTQ methods evaluate on classical DMs like Stable Diffusion XL, 1.5 or earlier,
which use convolutional U-Nets, newer Diffusion Transformer (DiT) models like
the PixArt series, Hunyuan and others adopt fundamentally different transformer
backbones to achieve superior image synthesis. Second, integer (INT)
quantization is prevailing in DM PTQ but doesn't align well with the network
weight and activation distribution, while Floating-Point Quantization (FPQ) is
still under-investigated, yet it holds the potential to better align the weight
and activation distributions in low-bit settings for DiT. In response, we
introduce FP4DiT, a PTQ method that leverages FPQ to achieve W4A6 quantization.
Specifically, we extend and generalize the Adaptive Rounding PTQ technique to
adequately calibrate weight quantization for FPQ and demonstrate that DiT
activations depend on input patch data, necessitating robust online activation
quantization techniques. Experimental results demonstrate that FP4DiT
outperforms integer-based PTQ at W4A6 and W4A8 precision and generates
convincing visual content on PixArt-$\alpha$, PixArt-$\Sigma$ and Hunyuan in
terms of several T2I metrics such as HPSv2 and CLIP.",['cs.CV'],"['Ruichen Chen', 'Keith G. Mills', 'Di Niu']",2025-03-19,2025-03-19,Diffusion Models DM have revolutionized the text to image visual generation process. However the large computational cost and model footprint of DMs hinders practical deployment especially on edge devices. Post training quantization PTQ is a lightweight method to alleviate these burdens without the need for training or fine tuning. While recent DM PTQ methods achieve W4A8 on integer based PTQ two key limitations remain First while most existing DM PTQ methods evaluate on classical DMs like Stable Diffusion XL 1.5 or earlier which use convolutional U Nets newer Diffusion Transformer DiT models like the PixArt series Hunyuan and others adopt fundamentally different transformer backbones to achieve superior image synthesis. Second integer INT quantization is prevailing in DM PTQ but doesn t align well with the network weight and activation distribution while Floating Point Quantization FPQ is still under investigated yet it holds the potential to better align the weight and activation distributions in low bit settings for DiT. In response we introduce FP4DiT a PTQ method that leverages FPQ to achieve W4A6 quantization. Specifically we extend and generalize the Adaptive Rounding PTQ technique to adequately calibrate weight quantization for FPQ and demonstrate that DiT activations depend on input patch data necessitating robust online activation quantization techniques. Experimental results demonstrate that FP4DiT outperforms integer based PTQ at W4A6 and W4A8 precision and generates convincing visual content on PixArt alpha PixArt Sigma and Hunyuan in terms of several T2I metrics such as HPSv2 and CLIP.,FP4DiT Towards Effective Floating Point Quantization for Diffusion Transformers,"['ptq', 'quantization', 'dm', 'achieve', 'activation', 'diffusion', 'dit', 'dm ptq', 'fpq', 'integer']",Diffusion Models DM have revolutionized the text to image visual generation process.
2503.17349v1,Beyond Semantics: Rediscovering Spatial Awareness in Vision-Language Models,"Vision-Language Models (VLMs) excel at identifying and describing objects but
struggle with spatial reasoning such as accurately understanding the relative
positions of objects. Inspired by the dual-pathway (ventral-dorsal) model of
human vision, we investigate why VLMs fail spatial tasks despite strong object
recognition capabilities. Our interpretability-driven analysis reveals a
critical underlying cause: vision embeddings in VLMs are treated primarily as
semantic ``bag-of-tokens,"" overshadowing subtle yet crucial positional cues due
to their disproportionately large embedding norms. We validate this insight
through extensive diagnostic experiments, demonstrating minimal performance
impact when token orders or fine-grained spatial details are removed. Guided by
these findings, we propose simple, interpretable interventions, including
normalizing vision embedding norms and extracting mid-layer spatially rich
features, to restore spatial awareness. Empirical results on both our synthetic
data and standard benchmarks demonstrate improved spatial reasoning
capabilities, highlighting the value of interpretability-informed design
choices. Our study not only uncovers fundamental limitations in current VLM
architectures but also provides actionable insights for enhancing structured
perception of visual scenes.",['cs.CV'],"['Jianing Qi', 'Jiawei Liu', 'Hao Tang', 'Zhigang Zhu']",2025-03-21,2025-03-21,Vision Language Models VLMs excel at identifying and describing objects but struggle with spatial reasoning such as accurately understanding the relative positions of objects. Inspired by the dual pathway ventral dorsal model of human vision we investigate why VLMs fail spatial tasks despite strong object recognition capabilities. Our interpretability driven analysis reveals a critical underlying cause vision embeddings in VLMs are treated primarily as semantic bag of tokens overshadowing subtle yet crucial positional cues due to their disproportionately large embedding norms. We validate this insight through extensive diagnostic experiments demonstrating minimal performance impact when token orders or fine grained spatial details are removed. Guided by these findings we propose simple interpretable interventions including normalizing vision embedding norms and extracting mid layer spatially rich features to restore spatial awareness. Empirical results on both our synthetic data and standard benchmarks demonstrate improved spatial reasoning capabilities highlighting the value of interpretability informed design choices. Our study not only uncovers fundamental limitations in current VLM architectures but also provides actionable insights for enhancing structured perception of visual scenes.,Beyond Semantics Rediscovering Spatial Awareness in Vision Language Models,"['spatial', 'vision', 'vlms', 'capabilities', 'embedding', 'embedding norms', 'interpretability', 'norms', 'objects', 'reasoning']",Vision Language Models VLMs excel at identifying and describing objects but struggle with spatial reasoning such as accurately understanding the relative positions of objects.
2503.16771v1,On Explaining (Large) Language Models For Code Using Global Code-Based Explanations,"In recent years, Language Models for Code (LLM4Code) have significantly
changed the landscape of software engineering (SE) on downstream tasks, such as
code generation, by making software development more efficient. Therefore, a
growing interest has emerged in further evaluating these Language Models to
homogenize the quality assessment of generated code. As the current evaluation
process can significantly overreact on accuracy-based metrics, practitioners
often seek methods to interpret LLM4Code outputs beyond canonical benchmarks.
While the majority of research reports on code generation effectiveness in
terms of expected ground truth, scant attention has been paid to LLMs'
explanations. In essence, the decision-making process to generate code is hard
to interpret. To bridge this evaluation gap, we introduce code rationales
(Code$Q$), a technique with rigorous mathematical underpinning, to identify
subsets of tokens that can explain individual code predictions. We conducted a
thorough Exploratory Analysis to demonstrate the method's applicability and a
User Study to understand the usability of code-based explanations. Our
evaluation demonstrates that Code$Q$ is a powerful interpretability method to
explain how (less) meaningful input concepts (i.e., natural language particle
`at') highly impact output generation. Moreover, participants of this study
highlighted Code$Q$'s ability to show a causal relationship between the input
and output of the model with readable and informative explanations on code
completion and test generation tasks. Additionally, Code$Q$ also helps to
uncover model rationale, facilitating comparison with a human rationale to
promote a fair level of trust and distrust in the model.","['cs.SE', 'cs.LG']","['David N. Palacio', 'Dipin Khati', 'Daniel Rodriguez-Cardenas', 'Alejandro Velasco', 'Denys Poshyvanyk']",2025-03-21,2025-03-21,In recent years Language Models for Code LLM4Code have significantly changed the landscape of software engineering SE on downstream tasks such as code generation by making software development more efficient. Therefore a growing interest has emerged in further evaluating these Language Models to homogenize the quality assessment of generated code. As the current evaluation process can significantly overreact on accuracy based metrics practitioners often seek methods to interpret LLM4Code outputs beyond canonical benchmarks. While the majority of research reports on code generation effectiveness in terms of expected ground truth scant attention has been paid to LLMs explanations. In essence the decision making process to generate code is hard to interpret. To bridge this evaluation gap we introduce code rationales Code Q a technique with rigorous mathematical underpinning to identify subsets of tokens that can explain individual code predictions. We conducted a thorough Exploratory Analysis to demonstrate the method s applicability and a User Study to understand the usability of code based explanations. Our evaluation demonstrates that Code Q is a powerful interpretability method to explain how less meaningful input concepts i.e. natural language particle at highly impact output generation. Moreover participants of this study highlighted Code Q s ability to show a causal relationship between the input and output of the model with readable and informative explanations on code completion and test generation tasks. Additionally Code Q also helps to uncover model rationale facilitating comparison with a human rationale to promote a fair level of trust and distrust in the model.,On Explaining Large Language Models For Code Using Global Code Based Explanations,"['code', 'generation', 'evaluation', 'explanations', 'language', 'model', 'based', 'code generation', 'explain', 'input']",In recent years Language Models for Code LLM4Code have significantly changed the landscape of software engineering SE on downstream tasks such as code generation by making software development more efficient.
2503.14917v1,MASS: Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models,"High-quality data plays a critical role in the pretraining and fine-tuning of
large language models (LLMs), even determining their performance ceiling to
some degree. Consequently, numerous data selection methods have been proposed
to identify subsets of data that can effectively and efficiently enhance model
performance. However, most of these methods focus on general data selection and
tend to overlook the specific nuances of domain-related data. In this paper, we
introduce MASS, a \textbf{MA}thematical data \textbf{S}election framework using
the \textbf{S}kill graph for pretraining LLMs in the mathematical reasoning
domain. By taking into account the unique characteristics of mathematics and
reasoning, we construct a skill graph that captures the mathematical skills and
their interrelations from a reference dataset. This skill graph guides us in
assigning quality scores to the target dataset, enabling us to select the
top-ranked subset which is further used to pretrain LLMs. Experimental results
demonstrate the efficiency and effectiveness of MASS across different model
sizes (1B and 7B) and pretraining datasets (web data and synthetic data).
Specifically, in terms of efficiency, models trained on subsets selected by
MASS can achieve similar performance to models trained on the original
datasets, with a significant reduction in the number of trained tokens -
ranging from 50\% to 70\% fewer tokens. In terms of effectiveness, when trained
on the same amount of tokens, models trained on the data selected by MASS
outperform those trained on the original datasets by 3.3\% to 5.9\%. These
results underscore the potential of MASS to improve both the efficiency and
effectiveness of pretraining LLMs.","['cs.CL', 'cs.AI']","['Jiazheng Li', 'Lu Yu', 'Qing Cui', 'Zhiqiang Zhang', 'Jun Zhou', 'Yanfang Ye', 'Chuxu Zhang']",2025-03-19,2025-03-19,High quality data plays a critical role in the pretraining and fine tuning of large language models LLMs even determining their performance ceiling to some degree. Consequently numerous data selection methods have been proposed to identify subsets of data that can effectively and efficiently enhance model performance. However most of these methods focus on general data selection and tend to overlook the specific nuances of domain related data. In this paper we introduce MASS a textbf MA thematical data textbf S election framework using the textbf S kill graph for pretraining LLMs in the mathematical reasoning domain. By taking into account the unique characteristics of mathematics and reasoning we construct a skill graph that captures the mathematical skills and their interrelations from a reference dataset. This skill graph guides us in assigning quality scores to the target dataset enabling us to select the top ranked subset which is further used to pretrain LLMs. Experimental results demonstrate the efficiency and effectiveness of MASS across different model sizes 1B and 7B and pretraining datasets web data and synthetic data . Specifically in terms of efficiency models trained on subsets selected by MASS can achieve similar performance to models trained on the original datasets with a significant reduction in the number of trained tokens ranging from 50 to 70 fewer tokens. In terms of effectiveness when trained on the same amount of tokens models trained on the data selected by MASS outperform those trained on the original datasets by 3.3 to 5.9 . These results underscore the potential of MASS to improve both the efficiency and effectiveness of pretraining LLMs.,MASS Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models,"['data', 'trained', 'mass', 'llms', 'models', 'pretraining', 'datasets', 'effectiveness', 'efficiency', 'graph']",High quality data plays a critical role in the pretraining and fine tuning of large language models LLMs even determining their performance ceiling to some degree.
2503.16402v1,The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination,"Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples
in the training set-has raised increasing concerns in Large Language Model
(LLM) evaluation, leading to falsely inflated performance estimates and
undermining evaluation reliability. To address this, researchers have proposed
various mitigation strategies to update existing benchmarks, including
modifying original questions or generating new ones based on them. However, a
rigorous examination of the effectiveness of these mitigation strategies
remains lacking. In this paper, we design a systematic and controlled pipeline
along with two novel metrics-fidelity and contamination resistance-to provide a
fine-grained and comprehensive assessment of existing BDC mitigation
strategies. Previous assessment methods, such as accuracy drop and accuracy
matching, focus solely on aggregate accuracy, often leading to incomplete or
misleading conclusions. Our metrics address this limitation by emphasizing
question-level evaluation result matching. Extensive experiments with 10 LLMs,
5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios
reveal that no existing strategy significantly improves resistance over the
vanilla case (i.e., no benchmark update) across all benchmarks, and none
effectively balances fidelity and contamination resistance. These findings
underscore the urgent need for designing more effective BDC mitigation
strategies. Our code repository is available at
https://github.com/ASTRAL-Group/BDC_mitigation_assessment.","['cs.AI', 'cs.CL', 'cs.LG']","['Yifan Sun', 'Han Wang', 'Dongbai Li', 'Gang Wang', 'Huan Zhang']",2025-03-20,2025-03-20,Benchmark Data Contamination BDC the inclusion of benchmark testing samples in the training set has raised increasing concerns in Large Language Model LLM evaluation leading to falsely inflated performance estimates and undermining evaluation reliability. To address this researchers have proposed various mitigation strategies to update existing benchmarks including modifying original questions or generating new ones based on them. However a rigorous examination of the effectiveness of these mitigation strategies remains lacking. In this paper we design a systematic and controlled pipeline along with two novel metrics fidelity and contamination resistance to provide a fine grained and comprehensive assessment of existing BDC mitigation strategies. Previous assessment methods such as accuracy drop and accuracy matching focus solely on aggregate accuracy often leading to incomplete or misleading conclusions. Our metrics address this limitation by emphasizing question level evaluation result matching. Extensive experiments with 10 LLMs 5 benchmarks 20 BDC mitigation strategies and 2 contamination scenarios reveal that no existing strategy significantly improves resistance over the vanilla case i.e. no benchmark update across all benchmarks and none effectively balances fidelity and contamination resistance. These findings underscore the urgent need for designing more effective BDC mitigation strategies. Our code repository is available at https github.com ASTRAL Group BDC_mitigation_assessment.,The Emperor s New Clothes in Benchmarking A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination,"['mitigation', 'mitigation strategies', 'strategies', 'bdc', 'contamination', 'accuracy', 'bdc mitigation', 'benchmark', 'benchmarks', 'evaluation']",Benchmark Data Contamination BDC the inclusion of benchmark testing samples in the training set has raised increasing concerns in Large Language Model LLM evaluation leading to falsely inflated performance estimates and undermining evaluation reliability.
2503.17211v1,A Language Anchor-Guided Method for Robust Noisy Domain Generalization,"Real-world machine learning applications often struggle with two major
challenges: distribution shift and label noise. Models tend to overfit by
focusing on redundant and uninformative features in the training data, which
makes it hard for them to generalize to the target domain. Noisy data worsens
this problem by causing further overfitting to the noise, meaning that existing
methods often fail to tell the difference between true, invariant features and
misleading, spurious ones. To tackle these issues, we introduce Anchor
Alignment and Adaptive Weighting (A3W). This new algorithm uses sample
reweighting guided by natural language processing (NLP) anchors to extract more
representative features. In simple terms, A3W leverages semantic
representations from natural language models as a source of domain-invariant
prior knowledge. Additionally, it employs a weighted loss function that adjusts
each sample's contribution based on its similarity to the corresponding NLP
anchor. This adjustment makes the model more robust to noisy labels. Extensive
experiments on standard benchmark datasets show that A3W consistently
outperforms state-of-the-art domain generalization methods, offering
significant improvements in both accuracy and robustness across different
datasets and noise levels.","['cs.CL', 'cs.CV', 'cs.LG']","['Zilin Dai', 'Lehong Wang', 'Fangzhou Lin', 'Yidong Wang', 'Zhigang Li', 'Kazunori D Yamada', 'Ziming Zhang', 'Wang Lu']",2025-03-21,2025-03-21,Real world machine learning applications often struggle with two major challenges distribution shift and label noise. Models tend to overfit by focusing on redundant and uninformative features in the training data which makes it hard for them to generalize to the target domain. Noisy data worsens this problem by causing further overfitting to the noise meaning that existing methods often fail to tell the difference between true invariant features and misleading spurious ones. To tackle these issues we introduce Anchor Alignment and Adaptive Weighting A3W . This new algorithm uses sample reweighting guided by natural language processing NLP anchors to extract more representative features. In simple terms A3W leverages semantic representations from natural language models as a source of domain invariant prior knowledge. Additionally it employs a weighted loss function that adjusts each sample s contribution based on its similarity to the corresponding NLP anchor. This adjustment makes the model more robust to noisy labels. Extensive experiments on standard benchmark datasets show that A3W consistently outperforms state of the art domain generalization methods offering significant improvements in both accuracy and robustness across different datasets and noise levels.,A Language Anchor Guided Method for Robust Noisy Domain Generalization,"['a3w', 'domain', 'features', 'noise', 'anchor', 'data', 'datasets', 'invariant', 'language', 'makes']",Real world machine learning applications often struggle with two major challenges distribution shift and label noise.
2503.15781v1,UAS Visual Navigation in Large and Unseen Environments via a Meta Agent,"The aim of this work is to develop an approach that enables Unmanned Aerial
System (UAS) to efficiently learn to navigate in large-scale urban environments
and transfer their acquired expertise to novel environments. To achieve this,
we propose a meta-curriculum training scheme. First, meta-training allows the
agent to learn a master policy to generalize across tasks. The resulting model
is then fine-tuned on the downstream tasks. We organize the training curriculum
in a hierarchical manner such that the agent is guided from coarse to fine
towards the target task. In addition, we introduce Incremental Self-Adaptive
Reinforcement learning (ISAR), an algorithm that combines the ideas of
incremental learning and meta-reinforcement learning (MRL). In contrast to
traditional reinforcement learning (RL), which focuses on acquiring a policy
for a specific task, MRL aims to learn a policy with fast transfer ability to
novel tasks. However, the MRL training process is time consuming, whereas our
proposed ISAR algorithm achieves faster convergence than the conventional MRL
algorithm. We evaluate the proposed methodologies in simulated environments and
demonstrate that using this training philosophy in conjunction with the ISAR
algorithm significantly improves the convergence speed for navigation in
large-scale cities and the adaptation proficiency in novel environments.","['cs.RO', 'cs.CV']","['Yuci Han', 'Charles Toth', 'Alper Yilmaz']",2025-03-20,2025-03-20,The aim of this work is to develop an approach that enables Unmanned Aerial System UAS to efficiently learn to navigate in large scale urban environments and transfer their acquired expertise to novel environments. To achieve this we propose a meta curriculum training scheme. First meta training allows the agent to learn a master policy to generalize across tasks. The resulting model is then fine tuned on the downstream tasks. We organize the training curriculum in a hierarchical manner such that the agent is guided from coarse to fine towards the target task. In addition we introduce Incremental Self Adaptive Reinforcement learning ISAR an algorithm that combines the ideas of incremental learning and meta reinforcement learning MRL . In contrast to traditional reinforcement learning RL which focuses on acquiring a policy for a specific task MRL aims to learn a policy with fast transfer ability to novel tasks. However the MRL training process is time consuming whereas our proposed ISAR algorithm achieves faster convergence than the conventional MRL algorithm. We evaluate the proposed methodologies in simulated environments and demonstrate that using this training philosophy in conjunction with the ISAR algorithm significantly improves the convergence speed for navigation in large scale cities and the adaptation proficiency in novel environments.,UAS Visual Navigation in Large and Unseen Environments via a Meta Agent,"['training', 'algorithm', 'environments', 'learning', 'mrl', 'isar', 'isar algorithm', 'learn', 'meta', 'novel']",The aim of this work is to develop an approach that enables Unmanned Aerial System UAS to efficiently learn to navigate in large scale urban environments and transfer their acquired expertise to novel environments.
2503.16797v1,A Learnability Analysis on Neuro-Symbolic Learning,"This paper analyzes the learnability of neuro-symbolic (NeSy) tasks within
hybrid systems. We show that the learnability of NeSy tasks can be
characterized by their derived constraint satisfaction problems (DCSPs).
Specifically, a task is learnable if the corresponding DCSP has a unique
solution; otherwise, it is unlearnable. For learnable tasks, we establish error
bounds by exploiting the clustering property of the hypothesis space.
Additionally, we analyze the asymptotic error for general NeSy tasks, showing
that the expected error scales with the disagreement among solutions. Our
results offer a principled approach to determining learnability and provide
insights into the design of new algorithms.","['cs.AI', 'cs.LG']","['Hao-Yuan He', 'Ming Li']",2025-03-21,2025-03-21,This paper analyzes the learnability of neuro symbolic NeSy tasks within hybrid systems. We show that the learnability of NeSy tasks can be characterized by their derived constraint satisfaction problems DCSPs . Specifically a task is learnable if the corresponding DCSP has a unique solution otherwise it is unlearnable. For learnable tasks we establish error bounds by exploiting the clustering property of the hypothesis space. Additionally we analyze the asymptotic error for general NeSy tasks showing that the expected error scales with the disagreement among solutions. Our results offer a principled approach to determining learnability and provide insights into the design of new algorithms.,A Learnability Analysis on Neuro Symbolic Learning,"['tasks', 'error', 'learnability', 'nesy', 'nesy tasks', 'learnable', 'additionally', 'additionally analyze', 'algorithms', 'analyze']",This paper analyzes the learnability of neuro symbolic NeSy tasks within hybrid systems.
2503.15615v1,PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL,"Equivariant Graph Neural Networks (EGNNs) have emerged as a promising
approach in Multi-Agent Reinforcement Learning (MARL), leveraging symmetry
guarantees to greatly improve sample efficiency and generalization. However,
real-world environments often exhibit inherent asymmetries arising from factors
such as external forces, measurement inaccuracies, or intrinsic system biases.
This paper introduces \textit{Partially Equivariant Graph NeUral Networks
(PEnGUiN)}, a novel architecture specifically designed to address these
challenges. We formally identify and categorize various types of partial
equivariance relevant to MARL, including subgroup equivariance, feature-wise
equivariance, regional equivariance, and approximate equivariance. We
theoretically demonstrate that PEnGUiN is capable of learning both fully
equivariant (EGNN) and non-equivariant (GNN) representations within a unified
framework. Through extensive experiments on a range of MARL problems
incorporating various asymmetries, we empirically validate the efficacy of
PEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both
EGNNs and standard GNNs in asymmetric environments, highlighting their
potential to improve the robustness and applicability of graph-based MARL
algorithms in real-world scenarios.","['cs.LG', 'cs.AI', 'cs.RO']","['Joshua McClellan', 'Greyson Brothers', 'Furong Huang', 'Pratap Tokekar']",2025-03-19,2025-03-19,Equivariant Graph Neural Networks EGNNs have emerged as a promising approach in Multi Agent Reinforcement Learning MARL leveraging symmetry guarantees to greatly improve sample efficiency and generalization. However real world environments often exhibit inherent asymmetries arising from factors such as external forces measurement inaccuracies or intrinsic system biases. This paper introduces textit Partially Equivariant Graph NeUral Networks PEnGUiN a novel architecture specifically designed to address these challenges. We formally identify and categorize various types of partial equivariance relevant to MARL including subgroup equivariance feature wise equivariance regional equivariance and approximate equivariance. We theoretically demonstrate that PEnGUiN is capable of learning both fully equivariant EGNN and non equivariant GNN representations within a unified framework. Through extensive experiments on a range of MARL problems incorporating various asymmetries we empirically validate the efficacy of PEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both EGNNs and standard GNNs in asymmetric environments highlighting their potential to improve the robustness and applicability of graph based MARL algorithms in real world scenarios.,PEnGUiN Partially Equivariant Graph NeUral Networks for Sample Efficient MARL,"['equivariance', 'equivariant', 'marl', 'penguin', 'graph', 'asymmetries', 'demonstrate', 'demonstrate penguin', 'egnns', 'environments']",Equivariant Graph Neural Networks EGNNs have emerged as a promising approach in Multi Agent Reinforcement Learning MARL leveraging symmetry guarantees to greatly improve sample efficiency and generalization.
2503.15211v1,GO-N3RDet: Geometry Optimized NeRF-enhanced 3D Object Detector,"We propose GO-N3RDet, a scene-geometry optimized multi-view 3D object
detector enhanced by neural radiance fields. The key to accurate 3D object
detection is in effective voxel representation. However, due to occlusion and
lack of 3D information, constructing 3D features from multi-view 2D images is
challenging. Addressing that, we introduce a unique 3D positional information
embedded voxel optimization mechanism to fuse multi-view features. To
prioritize neural field reconstruction in object regions, we also devise a
double importance sampling scheme for the NeRF branch of our detector. We
additionally propose an opacity optimization module for precise voxel opacity
prediction by enforcing multi-view consistency constraints. Moreover, to
further improve voxel density consistency across multiple perspectives, we
incorporate ray distance as a weighting factor to minimize cumulative ray
errors. Our unique modules synergetically form an end-to-end neural model that
establishes new state-of-the-art in NeRF-based multi-view 3D detection,
verified with extensive experiments on ScanNet and ARKITScenes. Code will be
available at https://github.com/ZechuanLi/GO-N3RDet.",['cs.CV'],"['Zechuan Li', 'Hongshan Yu', 'Yihao Ding', 'Jinhao Qiao', 'Basim Azam', 'Naveed Akhtar']",2025-03-19,2025-03-19,We propose GO N3RDet a scene geometry optimized multi view 3D object detector enhanced by neural radiance fields. The key to accurate 3D object detection is in effective voxel representation. However due to occlusion and lack of 3D information constructing 3D features from multi view 2D images is challenging. Addressing that we introduce a unique 3D positional information embedded voxel optimization mechanism to fuse multi view features. To prioritize neural field reconstruction in object regions we also devise a double importance sampling scheme for the NeRF branch of our detector. We additionally propose an opacity optimization module for precise voxel opacity prediction by enforcing multi view consistency constraints. Moreover to further improve voxel density consistency across multiple perspectives we incorporate ray distance as a weighting factor to minimize cumulative ray errors. Our unique modules synergetically form an end to end neural model that establishes new state of the art in NeRF based multi view 3D detection verified with extensive experiments on ScanNet and ARKITScenes. Code will be available at https github.com ZechuanLi GO N3RDet.,GO N3RDet Geometry Optimized NeRF enhanced 3D Object Detector,"['3d', 'multi', 'multi view', 'view', 'voxel', 'neural', 'object', '3d object', 'consistency', 'detection']",We propose GO N3RDet a scene geometry optimized multi view 3D object detector enhanced by neural radiance fields.
2503.15300v2,SUM Parts: Benchmarking Part-Level Semantic Segmentation of Urban Meshes,"Semantic segmentation in urban scene analysis has mainly focused on images or
point clouds, while textured meshes - offering richer spatial representation -
remain underexplored. This paper introduces SUM Parts, the first large-scale
dataset for urban textured meshes with part-level semantic labels, covering
about 2.5 km2 with 21 classes. The dataset was created using our own annotation
tool, which supports both face- and texture-based annotations with efficient
interactive selection. We also provide a comprehensive evaluation of 3D
semantic segmentation and interactive annotation methods on this dataset. Our
project page is available at https://tudelft3d.github.io/SUMParts/.",['cs.CV'],"['Weixiao Gao', 'Liangliang Nan', 'Hugo Ledoux']",2025-03-19,2025-03-21,Semantic segmentation in urban scene analysis has mainly focused on images or point clouds while textured meshes offering richer spatial representation remain underexplored. This paper introduces SUM Parts the first large scale dataset for urban textured meshes with part level semantic labels covering about 2.5 km2 with 21 classes. The dataset was created using our own annotation tool which supports both face and texture based annotations with efficient interactive selection. We also provide a comprehensive evaluation of 3D semantic segmentation and interactive annotation methods on this dataset. Our project page is available at https tudelft3d.github.io SUMParts .,SUM Parts Benchmarking Part Level Semantic Segmentation of Urban Meshes,"['dataset', 'semantic', 'annotation', 'interactive', 'meshes', 'segmentation', 'semantic segmentation', 'textured', 'textured meshes', 'urban']",Semantic segmentation in urban scene analysis has mainly focused on images or point clouds while textured meshes offering richer spatial representation remain underexplored.
2503.14799v1,Pruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure,"With the growing need for real-time processing on IoT devices, optimizing
machine learning (ML) models' size, latency, and computational efficiency is
essential. This paper investigates a pruning method for anomaly detection in
resource-constrained environments, specifically targeting Electric Vehicle
Charging Infrastructure (EVCI). Using the CICEVSE2024 dataset, we trained and
optimized three models-Multi-Layer Perceptron (MLP), Long Short-Term Memory
(LSTM), and XGBoost-through hyperparameter tuning with Optuna, further refining
them using SHapley Additive exPlanations (SHAP)-based feature selection (FS)
and unstructured pruning techniques. The optimized models achieved significant
reductions in model size and inference times, with only a marginal impact on
their performance. Notably, our findings indicate that, in the context of EVCI,
pruning and FS can enhance computational efficiency while retaining critical
anomaly detection capabilities.","['cs.LG', 'eess.SP']","['Fatemeh Dehrouyeh', 'Ibrahim Shaer', 'Soodeh Nikan', 'Firouz Badrkhani Ajaei', 'Abdallah Shami']",2025-03-19,2025-03-19,With the growing need for real time processing on IoT devices optimizing machine learning ML models size latency and computational efficiency is essential. This paper investigates a pruning method for anomaly detection in resource constrained environments specifically targeting Electric Vehicle Charging Infrastructure EVCI . Using the CICEVSE2024 dataset we trained and optimized three models Multi Layer Perceptron MLP Long Short Term Memory LSTM and XGBoost through hyperparameter tuning with Optuna further refining them using SHapley Additive exPlanations SHAP based feature selection FS and unstructured pruning techniques. The optimized models achieved significant reductions in model size and inference times with only a marginal impact on their performance. Notably our findings indicate that in the context of EVCI pruning and FS can enhance computational efficiency while retaining critical anomaly detection capabilities.,Pruning Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure,"['models', 'pruning', 'anomaly', 'anomaly detection', 'computational', 'computational efficiency', 'detection', 'efficiency', 'evci', 'fs']",With the growing need for real time processing on IoT devices optimizing machine learning ML models size latency and computational efficiency is essential.
2503.17155v1,D2C: Unlocking the Potential of Continuous Autoregressive Image Generation with Discrete Tokens,"In the domain of image generation, latent-based generative models occupy a
dominant status; however, these models rely heavily on image tokenizer. To meet
modeling requirements, autoregressive models possessing the characteristics of
scalability and flexibility embrace a discrete-valued tokenizer, but face the
challenge of poor image generation quality. In contrast, diffusion models take
advantage of the continuous-valued tokenizer to achieve better generation
quality but are subject to low efficiency and complexity. The existing hybrid
models are mainly to compensate for information loss and simplify the diffusion
learning process. The potential of merging discrete-valued and
continuous-valued tokens in the field of image generation has not yet been
explored. In this paper, we propose D2C, a novel two-stage method to enhance
model generation capacity. In the first stage, the discrete-valued tokens
representing coarse-grained image features are sampled by employing a small
discrete-valued generator. Then in the second stage, the continuous-valued
tokens representing fine-grained image features are learned conditioned on the
discrete token sequence. In addition, we design two kinds of fusion modules for
seamless interaction. On the ImageNet-256 benchmark, extensive experiment
results validate that our model achieves superior performance compared with
several continuous-valued and discrete-valued generative models on the
class-conditional image generation tasks.",['cs.CV'],"['Panpan Wang', 'Liqiang Niu', 'Fandong Meng', 'Jinan Xu', 'Yufeng Chen', 'Jie Zhou']",2025-03-21,2025-03-21,In the domain of image generation latent based generative models occupy a dominant status however these models rely heavily on image tokenizer. To meet modeling requirements autoregressive models possessing the characteristics of scalability and flexibility embrace a discrete valued tokenizer but face the challenge of poor image generation quality. In contrast diffusion models take advantage of the continuous valued tokenizer to achieve better generation quality but are subject to low efficiency and complexity. The existing hybrid models are mainly to compensate for information loss and simplify the diffusion learning process. The potential of merging discrete valued and continuous valued tokens in the field of image generation has not yet been explored. In this paper we propose D2C a novel two stage method to enhance model generation capacity. In the first stage the discrete valued tokens representing coarse grained image features are sampled by employing a small discrete valued generator. Then in the second stage the continuous valued tokens representing fine grained image features are learned conditioned on the discrete token sequence. In addition we design two kinds of fusion modules for seamless interaction. On the ImageNet 256 benchmark extensive experiment results validate that our model achieves superior performance compared with several continuous valued and discrete valued generative models on the class conditional image generation tasks.,D2C Unlocking the Potential of Continuous Autoregressive Image Generation with Discrete Tokens,"['valued', 'image', 'discrete', 'generation', 'models', 'discrete valued', 'continuous', 'continuous valued', 'image generation', 'stage']",In the domain of image generation latent based generative models occupy a dominant status however these models rely heavily on image tokenizer.
2503.15779v1,MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion,"Human mobility modeling is critical for urban planning and transportation
management, yet existing datasets often lack the resolution and semantic
richness required for comprehensive analysis. To address this, we proposed a
cross-domain data fusion framework that integrates multi-modal data of distinct
nature and spatio-temporal resolution, including geographical, mobility,
socio-demographic, and traffic information, to construct a privacy-preserving
and semantically enriched human travel trajectory dataset. This framework is
demonstrated through two case studies in Los Angeles (LA) and Egypt, where a
domain adaptation algorithm ensures its transferability across diverse urban
contexts. Quantitative evaluation shows that the generated synthetic dataset
accurately reproduces mobility patterns observed in empirical data. Moreover,
large-scale traffic simulations for LA County based on the generated synthetic
demand align well with observed traffic. On California's I-405 corridor, the
simulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume
and 4.36% for speed compared to Caltrans PeMS observations.","['cs.LG', 'cs.AI']","['Haoxuan Ma', 'Xishun Liao', 'Yifan Liu', 'Qinhua Jiang', 'Chris Stanford', 'Shangqing Cao', 'Jiaqi Ma']",2025-03-20,2025-03-20,Human mobility modeling is critical for urban planning and transportation management yet existing datasets often lack the resolution and semantic richness required for comprehensive analysis. To address this we proposed a cross domain data fusion framework that integrates multi modal data of distinct nature and spatio temporal resolution including geographical mobility socio demographic and traffic information to construct a privacy preserving and semantically enriched human travel trajectory dataset. This framework is demonstrated through two case studies in Los Angeles LA and Egypt where a domain adaptation algorithm ensures its transferability across diverse urban contexts. Quantitative evaluation shows that the generated synthetic dataset accurately reproduces mobility patterns observed in empirical data. Moreover large scale traffic simulations for LA County based on the generated synthetic demand align well with observed traffic. On California s I 405 corridor the simulation yields a Mean Absolute Percentage Error of 5.85 for traffic volume and 4.36 for speed compared to Caltrans PeMS observations.,MobiFuse Learning Universal Human Mobility Patterns through Cross domain Data Fusion,"['traffic', 'data', 'mobility', 'dataset', 'domain', 'framework', 'generated', 'generated synthetic', 'human', 'la']",Human mobility modeling is critical for urban planning and transportation management yet existing datasets often lack the resolution and semantic richness required for comprehensive analysis.
2503.17050v1,"Scoring, Remember, and Reference: Catching Camouflaged Objects in Videos","Video Camouflaged Object Detection (VCOD) aims to segment objects whose
appearances closely resemble their surroundings, posing a challenging and
emerging task. Existing vision models often struggle in such scenarios due to
the indistinguishable appearance of camouflaged objects and the insufficient
exploitation of dynamic information in videos. To address these challenges, we
propose an end-to-end VCOD framework inspired by human memory-recognition,
which leverages historical video information by integrating memory reference
frames for camouflaged sequence processing. Specifically, we design a
dual-purpose decoder that simultaneously generates predicted masks and scores,
enabling reference frame selection based on scores while introducing auxiliary
supervision to enhance feature extraction.Furthermore, this study introduces a
novel reference-guided multilevel asymmetric attention mechanism, effectively
integrating long-term reference information with short-term motion cues for
comprehensive feature extraction. By combining these modules, we develop the
Scoring, Remember, and Reference (SRR) framework, which efficiently extracts
information to locate targets and employs memory guidance to improve subsequent
processing. With its optimized module design and effective utilization of video
data, our model achieves significant performance improvements, surpassing
existing approaches by 10% on benchmark datasets while requiring fewer
parameters (54M) and only a single pass through the video. The code will be
made publicly available.",['cs.CV'],"['Yuang Feng', 'Shuyong Gao', 'Fuzhen Yan', 'Yicheng Song', 'Lingyi Hong', 'Junjie Hu', 'Wenqiang Zhang']",2025-03-21,2025-03-21,Video Camouflaged Object Detection VCOD aims to segment objects whose appearances closely resemble their surroundings posing a challenging and emerging task. Existing vision models often struggle in such scenarios due to the indistinguishable appearance of camouflaged objects and the insufficient exploitation of dynamic information in videos. To address these challenges we propose an end to end VCOD framework inspired by human memory recognition which leverages historical video information by integrating memory reference frames for camouflaged sequence processing. Specifically we design a dual purpose decoder that simultaneously generates predicted masks and scores enabling reference frame selection based on scores while introducing auxiliary supervision to enhance feature extraction.Furthermore this study introduces a novel reference guided multilevel asymmetric attention mechanism effectively integrating long term reference information with short term motion cues for comprehensive feature extraction. By combining these modules we develop the Scoring Remember and Reference SRR framework which efficiently extracts information to locate targets and employs memory guidance to improve subsequent processing. With its optimized module design and effective utilization of video data our model achieves significant performance improvements surpassing existing approaches by 10 on benchmark datasets while requiring fewer parameters 54M and only a single pass through the video. The code will be made publicly available.,Scoring Remember and Reference Catching Camouflaged Objects in Videos,"['reference', 'information', 'video', 'camouflaged', 'memory', 'design', 'end', 'existing', 'extraction', 'feature']",Video Camouflaged Object Detection VCOD aims to segment objects whose appearances closely resemble their surroundings posing a challenging and emerging task.
2503.15892v1,UMIT: Unifying Medical Imaging Tasks via Vision-Language Models,"With the rapid advancement of deep learning, particularly in the field of
medical image analysis, an increasing number of Vision-Language Models (VLMs)
are being widely applied to solve complex health and biomedical challenges.
However, existing research has primarily focused on specific tasks or single
modalities, which limits their applicability and generalization across diverse
medical scenarios. To address this challenge, we propose UMIT, a unified
multi-modal, multi-task VLM designed specifically for medical imaging tasks.
UMIT is able to solve various tasks, including visual question answering,
disease detection, and medical report generation. In addition, it is applicable
to multiple imaging modalities (e.g., X-ray, CT and PET), covering a wide range
of applications from basic diagnostics to complex lesion analysis. Moreover,
UMIT supports both English and Chinese, expanding its applicability globally
and ensuring accessibility to healthcare services in different linguistic
contexts. To enhance the model's adaptability and task-handling capability, we
design a unique two-stage training strategy and fine-tune UMIT with designed
instruction templates. Through extensive empirical evaluation, UMIT outperforms
previous methods in five tasks across multiple datasets. The performance of
UMIT indicates that it can significantly enhance diagnostic accuracy and
workflow efficiency, thus providing effective solutions for medical imaging
applications.",['cs.CV'],"['Haiyang Yu', 'Siyang Yi', 'Ke Niu', 'Minghan Zhuo', 'Bin Li']",2025-03-20,2025-03-20,With the rapid advancement of deep learning particularly in the field of medical image analysis an increasing number of Vision Language Models VLMs are being widely applied to solve complex health and biomedical challenges. However existing research has primarily focused on specific tasks or single modalities which limits their applicability and generalization across diverse medical scenarios. To address this challenge we propose UMIT a unified multi modal multi task VLM designed specifically for medical imaging tasks. UMIT is able to solve various tasks including visual question answering disease detection and medical report generation. In addition it is applicable to multiple imaging modalities e.g. X ray CT and PET covering a wide range of applications from basic diagnostics to complex lesion analysis. Moreover UMIT supports both English and Chinese expanding its applicability globally and ensuring accessibility to healthcare services in different linguistic contexts. To enhance the model s adaptability and task handling capability we design a unique two stage training strategy and fine tune UMIT with designed instruction templates. Through extensive empirical evaluation UMIT outperforms previous methods in five tasks across multiple datasets. The performance of UMIT indicates that it can significantly enhance diagnostic accuracy and workflow efficiency thus providing effective solutions for medical imaging applications.,UMIT Unifying Medical Imaging Tasks via Vision Language Models,"['umit', 'medical', 'tasks', 'imaging', 'analysis', 'applicability', 'applications', 'complex', 'designed', 'enhance']",With the rapid advancement of deep learning particularly in the field of medical image analysis an increasing number of Vision Language Models VLMs are being widely applied to solve complex health and biomedical challenges.
2503.15655v1,R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs,"Automatically adapting novels into screenplays is important for the TV, film,
or opera industries to promote products with low costs. The strong performances
of large language models (LLMs) in long-text generation call us to propose a
LLM based framework Reader-Rewriter (R$^2$) for this task. However, there are
two fundamental challenges here. First, the LLM hallucinations may cause
inconsistent plot extraction and screenplay generation. Second, the
causality-embedded plot lines should be effectively extracted for coherent
rewriting. Therefore, two corresponding tactics are proposed: 1) A
hallucination-aware refinement method (HAR) to iteratively discover and
eliminate the affections of hallucinations; and 2) a causal plot-graph
construction method (CPC) based on a greedy cycle-breaking algorithm to
efficiently construct plot lines with event causalities. Recruiting those
efficient techniques, R$^2$ utilizes two modules to mimic the human screenplay
rewriting process: The Reader module adopts a sliding window and CPC to build
the causal plot graphs, while the Rewriter module generates first the scene
outlines based on the graphs and then the screenplays. HAR is integrated into
both modules for accurate inferences of LLMs. Experimental results demonstrate
the superiority of R$^2$, which substantially outperforms three existing
approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison
at the overall win rate for GPT-4o.",['cs.AI'],"['Zefeng Lin', 'Yi Xiao', 'Zhiqiang Mo', 'Qifan Zhang', 'Jie Wang', 'Jiayang Chen', 'Jiajing Zhang', 'Hui Zhang', 'Zhengyi Liu', 'Xianyong Fang', 'Xiaohua Xu']",2025-03-19,2025-03-19,Automatically adapting novels into screenplays is important for the TV film or opera industries to promote products with low costs. The strong performances of large language models LLMs in long text generation call us to propose a LLM based framework Reader Rewriter R 2 for this task. However there are two fundamental challenges here. First the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second the causality embedded plot lines should be effectively extracted for coherent rewriting. Therefore two corresponding tactics are proposed 1 A hallucination aware refinement method HAR to iteratively discover and eliminate the affections of hallucinations and 2 a causal plot graph construction method CPC based on a greedy cycle breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques R 2 utilizes two modules to mimic the human screenplay rewriting process The Reader module adopts a sliding window and CPC to build the causal plot graphs while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R 2 which substantially outperforms three existing approaches 51.3 22.6 and 57.1 absolute increases in pairwise comparison at the overall win rate for GPT 4o.,R 2 A LLM Based Novel to Screenplay Generation Framework with Causal Plot Graphs,"['plot', 'based', 'causal', 'causal plot', 'cpc', 'generation', 'graphs', 'hallucinations', 'har', 'lines']",Automatically adapting novels into screenplays is important for the TV film or opera industries to promote products with low costs.
2503.15571v1,LLM-Aided Customizable Profiling of Code Data Based On Programming Language Concepts,"Data profiling is critical in machine learning for generating descriptive
statistics, supporting both deeper understanding and downstream tasks like data
valuation and curation. This work addresses profiling specifically in the
context of code datasets for Large Language Models (code-LLMs), where data
quality directly influences tasks such as code generation and summarization.
Characterizing code datasets in terms of programming language concepts enables
better insights and targeted data curation. Our proposed methodology decomposes
code data profiling into two phases: (1) an offline phase where LLMs are
leveraged to derive and learn rules for extracting syntactic and semantic
concepts across various programming languages, including previously unseen or
low-resource languages, and (2) an online deterministic phase applying these
derived rules for efficient real-time analysis. This hybrid approach is
customizable, extensible to new syntactic and semantic constructs, and scalable
to multiple languages. Experimentally, our LLM-aided method achieves a mean
accuracy of 90.33% for syntactic extraction rules and semantic classification
accuracies averaging 80% and 77% across languages and semantic concepts,
respectively.","['cs.SE', 'cs.ET', 'cs.IR', 'cs.LG', 'cs.PL']","['Pankaj Thorat', 'Adnan Qidwai', 'Adrija Dhar', 'Aishwariya Chakraborty', 'Anand Eswaran', 'Hima Patel', 'Praveen Jayachandran']",2025-03-19,2025-03-19,Data profiling is critical in machine learning for generating descriptive statistics supporting both deeper understanding and downstream tasks like data valuation and curation. This work addresses profiling specifically in the context of code datasets for Large Language Models code LLMs where data quality directly influences tasks such as code generation and summarization. Characterizing code datasets in terms of programming language concepts enables better insights and targeted data curation. Our proposed methodology decomposes code data profiling into two phases 1 an offline phase where LLMs are leveraged to derive and learn rules for extracting syntactic and semantic concepts across various programming languages including previously unseen or low resource languages and 2 an online deterministic phase applying these derived rules for efficient real time analysis. This hybrid approach is customizable extensible to new syntactic and semantic constructs and scalable to multiple languages. Experimentally our LLM aided method achieves a mean accuracy of 90.33 for syntactic extraction rules and semantic classification accuracies averaging 80 and 77 across languages and semantic concepts respectively.,LLM Aided Customizable Profiling of Code Data Based On Programming Language Concepts,"['code', 'data', 'languages', 'semantic', 'concepts', 'profiling', 'rules', 'syntactic', 'code datasets', 'curation']",Data profiling is critical in machine learning for generating descriptive statistics supporting both deeper understanding and downstream tasks like data valuation and curation.
2503.16413v1,M3: 3D-Spatial MultiModal Memory,"We present 3D Spatial MultiModal Memory (M3), a multimodal memory system
designed to retain information about medium-sized static scenes through video
sources for visual perception. By integrating 3D Gaussian Splatting techniques
with foundation models, M3 builds a multimodal memory capable of rendering
feature representations across granularities, encompassing a wide range of
knowledge. In our exploration, we identify two key challenges in previous works
on feature splatting: (1) computational constraints in storing high-dimensional
features for each Gaussian primitive, and (2) misalignment or information loss
between distilled features and foundation model features. To address these
challenges, we propose M3 with key components of principal scene components and
Gaussian memory attention, enabling efficient training and inference. To
validate M3, we conduct comprehensive quantitative evaluations of feature
similarity and downstream tasks, as well as qualitative visualizations to
highlight the pixel trace of Gaussian memory attention. Our approach
encompasses a diverse range of foundation models, including vision-language
models (VLMs), perception models, and large multimodal and language models
(LMMs/LLMs). Furthermore, to demonstrate real-world applicability, we deploy
M3's feature field in indoor scenes on a quadruped robot. Notably, we claim
that M3 is the first work to address the core compression challenges in 3D
feature distillation.","['cs.CV', 'cs.RO']","['Xueyan Zou', 'Yuchen Song', 'Ri-Zhao Qiu', 'Xuanbin Peng', 'Jianglong Ye', 'Sifei Liu', 'Xiaolong Wang']",2025-03-20,2025-03-20,We present 3D Spatial MultiModal Memory M3 a multimodal memory system designed to retain information about medium sized static scenes through video sources for visual perception. By integrating 3D Gaussian Splatting techniques with foundation models M3 builds a multimodal memory capable of rendering feature representations across granularities encompassing a wide range of knowledge. In our exploration we identify two key challenges in previous works on feature splatting 1 computational constraints in storing high dimensional features for each Gaussian primitive and 2 misalignment or information loss between distilled features and foundation model features. To address these challenges we propose M3 with key components of principal scene components and Gaussian memory attention enabling efficient training and inference. To validate M3 we conduct comprehensive quantitative evaluations of feature similarity and downstream tasks as well as qualitative visualizations to highlight the pixel trace of Gaussian memory attention. Our approach encompasses a diverse range of foundation models including vision language models VLMs perception models and large multimodal and language models LMMs LLMs . Furthermore to demonstrate real world applicability we deploy M3 s feature field in indoor scenes on a quadruped robot. Notably we claim that M3 is the first work to address the core compression challenges in 3D feature distillation.,M3 3D Spatial MultiModal Memory,"['m3', 'feature', 'memory', 'models', 'gaussian', 'multimodal', '3d', 'challenges', 'features', 'foundation']",We present 3D Spatial MultiModal Memory M3 a multimodal memory system designed to retain information about medium sized static scenes through video sources for visual perception.
2503.16418v1,InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity,"Achieving flexible and high-fidelity identity-preserved image generation
remains formidable, particularly with advanced Diffusion Transformers (DiTs)
like FLUX. We introduce InfiniteYou (InfU), one of the earliest robust
frameworks leveraging DiTs for this task. InfU addresses significant issues of
existing methods, such as insufficient identity similarity, poor text-image
alignment, and low generation quality and aesthetics. Central to InfU is
InfuseNet, a component that injects identity features into the DiT base model
via residual connections, enhancing identity similarity while maintaining
generation capabilities. A multi-stage training strategy, including pretraining
and supervised fine-tuning (SFT) with synthetic single-person-multiple-sample
(SPMS) data, further improves text-image alignment, ameliorates image quality,
and alleviates face copy-pasting. Extensive experiments demonstrate that InfU
achieves state-of-the-art performance, surpassing existing baselines. In
addition, the plug-and-play design of InfU ensures compatibility with various
existing methods, offering a valuable contribution to the broader community.","['cs.CV', 'cs.LG']","['Liming Jiang', 'Qing Yan', 'Yumin Jia', 'Zichuan Liu', 'Hao Kang', 'Xin Lu']",2025-03-20,2025-03-20,Achieving flexible and high fidelity identity preserved image generation remains formidable particularly with advanced Diffusion Transformers DiTs like FLUX. We introduce InfiniteYou InfU one of the earliest robust frameworks leveraging DiTs for this task. InfU addresses significant issues of existing methods such as insufficient identity similarity poor text image alignment and low generation quality and aesthetics. Central to InfU is InfuseNet a component that injects identity features into the DiT base model via residual connections enhancing identity similarity while maintaining generation capabilities. A multi stage training strategy including pretraining and supervised fine tuning SFT with synthetic single person multiple sample SPMS data further improves text image alignment ameliorates image quality and alleviates face copy pasting. Extensive experiments demonstrate that InfU achieves state of the art performance surpassing existing baselines. In addition the plug and play design of InfU ensures compatibility with various existing methods offering a valuable contribution to the broader community.,InfiniteYou Flexible Photo Recrafting While Preserving Your Identity,"['infu', 'identity', 'image', 'existing', 'generation', 'alignment', 'dits', 'existing methods', 'identity similarity', 'image alignment']",Achieving flexible and high fidelity identity preserved image generation remains formidable particularly with advanced Diffusion Transformers DiTs like FLUX.
2503.15355v1,Robustness of Nonlinear Representation Learning,"We study the problem of unsupervised representation learning in slightly
misspecified settings, and thus formalize the study of robustness of nonlinear
representation learning. We focus on the case where the mixing is close to a
local isometry in a suitable distance and show based on existing rigidity
results that the mixing can be identified up to linear transformations and
small errors. In a second step, we investigate Independent Component Analysis
(ICA) with observations generated according to $x=f(s)=As+h(s)$ where $A$ is an
invertible mixing matrix and $h$ a small perturbation. We show that we can
approximately recover the matrix $A$ and the independent components. Together,
these two results show approximate identifiability of nonlinear ICA with almost
isometric mixing functions. Those results are a step towards identifiability
results for unsupervised representation learning for real-world data that do
not follow restrictive model classes.","['stat.ML', 'cs.LG']","['Simon Buchholz', 'Bernhard SchÃ¶lkopf']",2025-03-19,2025-03-19,We study the problem of unsupervised representation learning in slightly misspecified settings and thus formalize the study of robustness of nonlinear representation learning. We focus on the case where the mixing is close to a local isometry in a suitable distance and show based on existing rigidity results that the mixing can be identified up to linear transformations and small errors. In a second step we investigate Independent Component Analysis ICA with observations generated according to x f s As h s where A is an invertible mixing matrix and h a small perturbation. We show that we can approximately recover the matrix A and the independent components. Together these two results show approximate identifiability of nonlinear ICA with almost isometric mixing functions. Those results are a step towards identifiability results for unsupervised representation learning for real world data that do not follow restrictive model classes.,Robustness of Nonlinear Representation Learning,"['mixing', 'results', 'learning', 'representation', 'representation learning', 'ica', 'identifiability', 'independent', 'matrix', 'nonlinear']",We study the problem of unsupervised representation learning in slightly misspecified settings and thus formalize the study of robustness of nonlinear representation learning.
2503.17251v1,Breaking the Symmetries of Indistinguishable Objects,"Indistinguishable objects often occur when modelling problems in constraint
programming, as well as in other related paradigms. They occur when objects can
be viewed as being drawn from a set of unlabelled objects, and the only
operation allowed on them is equality testing. For example, the golfers in the
social golfer problem are indistinguishable. If we do label the golfers, then
any relabelling of the golfers in one solution gives another valid solution.
Therefore, we can regard the symmetric group of size $n$ as acting on a set of
$n$ indistinguishable objects. In this paper, we show how we can break the
symmetries resulting from indistinguishable objects. We show how symmetries on
indistinguishable objects can be defined properly in complex types, for example
in a matrix indexed by indistinguishable objects. We then show how the
resulting symmetries can be broken correctly. In Essence, a high-level
modelling language, indistinguishable objects are encapsulated in ""unnamed
types"". We provide an implementation of complete symmetry breaking for unnamed
types in Essence.",['cs.AI'],"['Ozgur Akgun', 'Mun See Chang', 'Ian P. Gent', 'Christopher Jefferson']",2025-03-21,2025-03-21,Indistinguishable objects often occur when modelling problems in constraint programming as well as in other related paradigms. They occur when objects can be viewed as being drawn from a set of unlabelled objects and the only operation allowed on them is equality testing. For example the golfers in the social golfer problem are indistinguishable. If we do label the golfers then any relabelling of the golfers in one solution gives another valid solution. Therefore we can regard the symmetric group of size n as acting on a set of n indistinguishable objects. In this paper we show how we can break the symmetries resulting from indistinguishable objects. We show how symmetries on indistinguishable objects can be defined properly in complex types for example in a matrix indexed by indistinguishable objects. We then show how the resulting symmetries can be broken correctly. In Essence a high level modelling language indistinguishable objects are encapsulated in unnamed types . We provide an implementation of complete symmetry breaking for unnamed types in Essence.,Breaking the Symmetries of Indistinguishable Objects,"['objects', 'indistinguishable', 'indistinguishable objects', 'golfers', 'symmetries', 'types', 'essence', 'example', 'modelling', 'occur']",Indistinguishable objects often occur when modelling problems in constraint programming as well as in other related paradigms.
2503.15661v1,UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction,"Autonomous agents that navigate Graphical User Interfaces (GUIs) to automate
tasks like document editing and file management can greatly enhance computer
workflows. While existing research focuses on online settings, desktop
environments, critical for many professional and everyday tasks, remain
underexplored due to data collection challenges and licensing issues. We
introduce UI-Vision, the first comprehensive, license-permissive benchmark for
offline, fine-grained evaluation of computer use agents in real-world desktop
environments. Unlike online benchmarks, UI-Vision provides: (i) dense,
high-quality annotations of human demonstrations, including bounding boxes, UI
labels, and action trajectories (clicks, drags, and keyboard inputs) across 83
software applications, and (ii) three fine-to-coarse grained tasks-Element
Grounding, Layout Grounding, and Action Prediction-with well-defined metrics to
rigorously evaluate agents' performance in desktop environments. Our evaluation
reveals critical limitations in state-of-the-art models like UI-TARS-72B,
including issues with understanding professional software, spatial reasoning,
and complex actions like drag-and-drop. These findings highlight the challenges
in developing fully autonomous computer use agents. By releasing UI-Vision as
open-source, we aim to advance the development of more capable agents for
real-world desktop tasks.","['cs.CV', 'cs.AI', 'cs.CL']","['Shravan Nayak', 'Xiangru Jian', 'Kevin Qinghong Lin', 'Juan A. Rodriguez', 'Montek Kalsi', 'Rabiul Awal', 'Nicolas Chapados', 'M. Tamer Ãzsu', 'Aishwarya Agrawal', 'David Vazquez', 'Christopher Pal', 'Perouz Taslakian', 'Spandana Gella', 'Sai Rajeswar']",2025-03-19,2025-03-19,Autonomous agents that navigate Graphical User Interfaces GUIs to automate tasks like document editing and file management can greatly enhance computer workflows. While existing research focuses on online settings desktop environments critical for many professional and everyday tasks remain underexplored due to data collection challenges and licensing issues. We introduce UI Vision the first comprehensive license permissive benchmark for offline fine grained evaluation of computer use agents in real world desktop environments. Unlike online benchmarks UI Vision provides i dense high quality annotations of human demonstrations including bounding boxes UI labels and action trajectories clicks drags and keyboard inputs across 83 software applications and ii three fine to coarse grained tasks Element Grounding Layout Grounding and Action Prediction with well defined metrics to rigorously evaluate agents performance in desktop environments. Our evaluation reveals critical limitations in state of the art models like UI TARS 72B including issues with understanding professional software spatial reasoning and complex actions like drag and drop. These findings highlight the challenges in developing fully autonomous computer use agents. By releasing UI Vision as open source we aim to advance the development of more capable agents for real world desktop tasks.,UI Vision A Desktop centric GUI Benchmark for Visual Perception and Interaction,"['agents', 'ui', 'desktop', 'tasks', 'computer', 'desktop environments', 'environments', 'like', 'ui vision', 'vision']",Autonomous agents that navigate Graphical User Interfaces GUIs to automate tasks like document editing and file management can greatly enhance computer workflows.
2503.16389v1,Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation,"Retinal Optical Coherence Tomography (OCT) segmentation is essential for
diagnosing pathology. Traditional methods focus on either spatial or spectral
domains, overlooking their combined dependencies. We propose a triple-encoder
network that integrates CNNs for spatial features, Fast Fourier Convolution
(FFC) for spectral features, and attention mechanisms to capture global
relationships across both domains. Attention fusion modules integrate
convolution and cross-attention to further enhance features. Our method
achieves an average Dice score improvement from 0.855 to 0.864, outperforming
prior work.","['eess.IV', 'cs.AI', 'cs.CV']","['Kristin Qi', 'Xinhan Di']",2025-03-20,2025-03-20,Retinal Optical Coherence Tomography OCT segmentation is essential for diagnosing pathology. Traditional methods focus on either spatial or spectral domains overlooking their combined dependencies. We propose a triple encoder network that integrates CNNs for spatial features Fast Fourier Convolution FFC for spectral features and attention mechanisms to capture global relationships across both domains. Attention fusion modules integrate convolution and cross attention to further enhance features. Our method achieves an average Dice score improvement from 0.855 to 0.864 outperforming prior work.,Attentional Triple Encoder Network in Spatiospectral Domains for Medical Image Segmentation,"['attention', 'features', 'convolution', 'domains', 'spatial', 'spectral', '855', '855 864', '864', '864 outperforming']",Retinal Optical Coherence Tomography OCT segmentation is essential for diagnosing pathology.
2503.15265v1,DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning,"Triangle meshes play a crucial role in 3D applications for efficient
manipulation and rendering. While auto-regressive methods generate structured
meshes by predicting discrete vertex tokens, they are often constrained by
limited face counts and mesh incompleteness. To address these challenges, we
propose DeepMesh, a framework that optimizes mesh generation through two key
innovations: (1) an efficient pre-training strategy incorporating a novel
tokenization algorithm, along with improvements in data curation and
processing, and (2) the introduction of Reinforcement Learning (RL) into 3D
mesh generation to achieve human preference alignment via Direct Preference
Optimization (DPO). We design a scoring standard that combines human evaluation
with 3D metrics to collect preference pairs for DPO, ensuring both visual
appeal and geometric accuracy. Conditioned on point clouds and images, DeepMesh
generates meshes with intricate details and precise topology, outperforming
state-of-the-art methods in both precision and quality. Project page:
https://zhaorw02.github.io/DeepMesh/",['cs.CV'],"['Ruowen Zhao', 'Junliang Ye', 'Zhengyi Wang', 'Guangce Liu', 'Yiwen Chen', 'Yikai Wang', 'Jun Zhu']",2025-03-19,2025-03-19,Triangle meshes play a crucial role in 3D applications for efficient manipulation and rendering. While auto regressive methods generate structured meshes by predicting discrete vertex tokens they are often constrained by limited face counts and mesh incompleteness. To address these challenges we propose DeepMesh a framework that optimizes mesh generation through two key innovations 1 an efficient pre training strategy incorporating a novel tokenization algorithm along with improvements in data curation and processing and 2 the introduction of Reinforcement Learning RL into 3D mesh generation to achieve human preference alignment via Direct Preference Optimization DPO . We design a scoring standard that combines human evaluation with 3D metrics to collect preference pairs for DPO ensuring both visual appeal and geometric accuracy. Conditioned on point clouds and images DeepMesh generates meshes with intricate details and precise topology outperforming state of the art methods in both precision and quality. Project page https zhaorw02.github.io DeepMesh,DeepMesh Auto Regressive Artist mesh Creation with Reinforcement Learning,"['3d', 'deepmesh', 'mesh', 'meshes', 'preference', 'dpo', 'efficient', 'generation', 'human', 'mesh generation']",Triangle meshes play a crucial role in 3D applications for efficient manipulation and rendering.
2503.17171v1,Generative adversarial framework to calibrate excursion set models for the 3D morphology of all-solid-state battery cathodes,"This paper presents a computational method for generating virtual 3D
morphologies of functional materials using low-parametric stochastic geometry
models, i.e., digital twins, calibrated with 2D microscopy images. These
digital twins allow systematic parameter variations to simulate various
morphologies, that can be deployed for virtual materials testing by means of
spatially resolved numerical simulations of macroscopic properties. Generative
adversarial networks (GANs) have gained popularity for calibrating models to
generate realistic 3D morphologies. However, GANs often comprise of numerous
uninterpretable parameters make systematic variation of morphologies for
virtual materials testing challenging. In contrast, low-parametric stochastic
geometry models (e.g., based on Gaussian random fields) enable targeted
variation but may struggle to mimic complex morphologies. Combining GANs with
advanced stochastic geometry models (e.g., excursion sets of more general
random fields) addresses these limitations, allowing model calibration solely
from 2D image data. This approach is demonstrated by generating a digital twin
of all-solid-state battery (ASSB) cathodes. Since the digital twins are
parametric, they support systematic exploration of structural scenarios and
their macroscopic properties. The proposed method facilitates simulation
studies for optimizing 3D morphologies, benefiting not only ASSB cathodes but
also other materials with similar structures.","['stat.ML', 'cs.LG']","['Orkun Furat', 'Sabrina Weber', 'Johannes Schubert', 'RenÃ© Rekers', 'Maximilian Luczak', 'Erik Glatt', 'Andreas Wiegmann', 'JÃ¼rgen Janek', 'Anja Bielefeld', 'Volker Schmidt']",2025-03-21,2025-03-21,This paper presents a computational method for generating virtual 3D morphologies of functional materials using low parametric stochastic geometry models i.e. digital twins calibrated with 2D microscopy images. These digital twins allow systematic parameter variations to simulate various morphologies that can be deployed for virtual materials testing by means of spatially resolved numerical simulations of macroscopic properties. Generative adversarial networks GANs have gained popularity for calibrating models to generate realistic 3D morphologies. However GANs often comprise of numerous uninterpretable parameters make systematic variation of morphologies for virtual materials testing challenging. In contrast low parametric stochastic geometry models e.g. based on Gaussian random fields enable targeted variation but may struggle to mimic complex morphologies. Combining GANs with advanced stochastic geometry models e.g. excursion sets of more general random fields addresses these limitations allowing model calibration solely from 2D image data. This approach is demonstrated by generating a digital twin of all solid state battery ASSB cathodes. Since the digital twins are parametric they support systematic exploration of structural scenarios and their macroscopic properties. The proposed method facilitates simulation studies for optimizing 3D morphologies benefiting not only ASSB cathodes but also other materials with similar structures.,Generative adversarial framework to calibrate excursion set models for the 3D morphology of all solid state battery cathodes,"['morphologies', 'digital', 'materials', 'models', '3d', '3d morphologies', 'digital twins', 'gans', 'geometry', 'geometry models']",This paper presents a computational method for generating virtual 3D morphologies of functional materials using low parametric stochastic geometry models i.e.
2503.16614v1,Classification of User Reports for Detection of Faulty Computer Components using NLP Models: A Case Study,"Computer manufacturers typically offer platforms for users to report faults.
However, there remains a significant gap in these platforms' ability to
effectively utilize textual reports, which impedes users from describing their
issues in their own words. In this context, Natural Language Processing (NLP)
offers a promising solution, by enabling the analysis of user-generated text.
This paper presents an innovative approach that employs NLP models to classify
user reports for detecting faulty computer components, such as CPU, memory,
motherboard, video card, and more. In this work, we build a dataset of 341 user
reports obtained from many sources. Additionally, through extensive
experimental evaluation, our approach achieved an accuracy of 79% with our
dataset.","['cs.CL', 'cs.AI', 'cs.LG']","['Maria de Lourdes M. Silva', 'AndrÃ© L. C. MendonÃ§a', 'Eduardo R. D. Neto', 'Iago C. Chaves', 'Felipe T. Brito', 'Victor A. E. Farias', 'Javam C. Machado']",2025-03-20,2025-03-20,Computer manufacturers typically offer platforms for users to report faults. However there remains a significant gap in these platforms ability to effectively utilize textual reports which impedes users from describing their issues in their own words. In this context Natural Language Processing NLP offers a promising solution by enabling the analysis of user generated text. This paper presents an innovative approach that employs NLP models to classify user reports for detecting faulty computer components such as CPU memory motherboard video card and more. In this work we build a dataset of 341 user reports obtained from many sources. Additionally through extensive experimental evaluation our approach achieved an accuracy of 79 with our dataset.,Classification of User Reports for Detection of Faulty Computer Components using NLP Models A Case Study,"['reports', 'user', 'approach', 'computer', 'dataset', 'nlp', 'platforms', 'user reports', 'users', '341']",Computer manufacturers typically offer platforms for users to report faults.
2503.17168v1,Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving,"Light Detection and Ranging (LiDAR) is an essential sensor technology for
autonomous driving as it can capture high-resolution 3D data. As 3D object
detection systems (OD) can interpret such point cloud data, they play a key
role in the driving decisions of autonomous vehicles. Consequently, such 3D OD
must be robust against all types of perturbations and must therefore be
extensively tested. One approach is the use of adversarial examples, which are
small, sometimes sophisticated perturbations in the input data that change,
i.e., falsify, the prediction of the OD. These perturbations are carefully
designed based on the weaknesses of the OD. The robustness of the OD cannot be
quantified with adversarial examples in general, because if the OD is
vulnerable to a given attack, it is unclear whether this is due to the
robustness of the OD or whether the attack algorithm produces particularly
strong adversarial examples. The contribution of this work is Hi-ALPS --
Hierarchical Adversarial-example-based LiDAR Perturbation Level System, where
higher robustness of the OD is required to withstand the perturbations as the
perturbation levels increase. In doing so, the Hi-ALPS levels successively
implement a heuristic followed by established adversarial example approaches.
In a series of comprehensive experiments using Hi-ALPS, we quantify the
robustness of six state-of-the-art 3D OD under different types of
perturbations. The results of the experiments show that none of the OD is
robust against all Hi-ALPS levels; an important factor for the ranking is that
human observers can still correctly recognize the perturbed objects, as the
respective perturbations are small. To increase the robustness of the OD, we
discuss the applicability of state-of-the-art countermeasures. In addition, we
derive further suggestions for countermeasures based on our experimental
results.","['cs.CV', 'cs.LG']","['Alexandra Arzberger', 'Ramin Tavakoli Kolagari']",2025-03-21,2025-03-21,Light Detection and Ranging LiDAR is an essential sensor technology for autonomous driving as it can capture high resolution 3D data. As 3D object detection systems OD can interpret such point cloud data they play a key role in the driving decisions of autonomous vehicles. Consequently such 3D OD must be robust against all types of perturbations and must therefore be extensively tested. One approach is the use of adversarial examples which are small sometimes sophisticated perturbations in the input data that change i.e. falsify the prediction of the OD. These perturbations are carefully designed based on the weaknesses of the OD. The robustness of the OD cannot be quantified with adversarial examples in general because if the OD is vulnerable to a given attack it is unclear whether this is due to the robustness of the OD or whether the attack algorithm produces particularly strong adversarial examples. The contribution of this work is Hi ALPS Hierarchical Adversarial example based LiDAR Perturbation Level System where higher robustness of the OD is required to withstand the perturbations as the perturbation levels increase. In doing so the Hi ALPS levels successively implement a heuristic followed by established adversarial example approaches. In a series of comprehensive experiments using Hi ALPS we quantify the robustness of six state of the art 3D OD under different types of perturbations. The results of the experiments show that none of the OD is robust against all Hi ALPS levels an important factor for the ranking is that human observers can still correctly recognize the perturbed objects as the respective perturbations are small. To increase the robustness of the OD we discuss the applicability of state of the art countermeasures. In addition we derive further suggestions for countermeasures based on our experimental results.,Hi ALPS An Experimental Robustness Quantification of Six LiDAR based Object Detection Systems for Autonomous Driving,"['od', 'perturbations', 'adversarial', 'robustness', '3d', 'alps', 'hi', 'hi alps', 'robustness od', 'adversarial examples']",Light Detection and Ranging LiDAR is an essential sensor technology for autonomous driving as it can capture high resolution 3D data.
2503.16361v1,Enhancing variational quantum algorithms by balancing training on classical and quantum hardware,"Quantum computers offer a promising route to tackling problems that are
classically intractable such as in prime-factorization, solving large-scale
linear algebra and simulating complex quantum systems, but require
fault-tolerant quantum hardware. On the other hand, variational quantum
algorithms (VQAs) have the potential to provide a near-term route to quantum
utility or advantage, and is usually constructed by using parametrized quantum
circuits (PQCs) in combination with a classical optimizer for training.
Although VQAs have been proposed for a multitude of tasks such as ground-state
estimation, combinatorial optimization and unitary compilation, there remain
major challenges in its trainability and resource costs on quantum hardware.
Here we address these challenges by adopting Hardware Efficient and dynamical
LIe algebra Supported Ansatz (HELIA), and propose two training schemes that
combine an existing g-sim method (that uses the underlying group structure of
the operators) and the Parameter-Shift Rule (PSR). Our improvement comes from
distributing the resources required for gradient estimation and training to
both classical and quantum hardware. We numerically test our proposal for
ground-state estimation using Variational Quantum Eigensolver (VQE) and
classification of quantum phases using quantum neural networks. Our methods
show better accuracy and success of trials, and also need fewer calls to the
quantum hardware on an average than using only PSR (upto 60% reduction), that
runs exclusively on quantum hardware. We also numerically demonstrate the
capability of HELIA in mitigating barren plateaus, paving the way for training
large-scale quantum models.","['quant-ph', 'cs.LG', 'stat.ML']","['Rahul Bhowmick', 'Harsh Wadhwa', 'Avinash Singh', 'Tania Sidana', 'Quoc Hoan Tran', 'Krishna Kumar Sabapathy']",2025-03-20,2025-03-20,Quantum computers offer a promising route to tackling problems that are classically intractable such as in prime factorization solving large scale linear algebra and simulating complex quantum systems but require fault tolerant quantum hardware. On the other hand variational quantum algorithms VQAs have the potential to provide a near term route to quantum utility or advantage and is usually constructed by using parametrized quantum circuits PQCs in combination with a classical optimizer for training. Although VQAs have been proposed for a multitude of tasks such as ground state estimation combinatorial optimization and unitary compilation there remain major challenges in its trainability and resource costs on quantum hardware. Here we address these challenges by adopting Hardware Efficient and dynamical LIe algebra Supported Ansatz HELIA and propose two training schemes that combine an existing g sim method that uses the underlying group structure of the operators and the Parameter Shift Rule PSR . Our improvement comes from distributing the resources required for gradient estimation and training to both classical and quantum hardware. We numerically test our proposal for ground state estimation using Variational Quantum Eigensolver VQE and classification of quantum phases using quantum neural networks. Our methods show better accuracy and success of trials and also need fewer calls to the quantum hardware on an average than using only PSR upto 60 reduction that runs exclusively on quantum hardware. We also numerically demonstrate the capability of HELIA in mitigating barren plateaus paving the way for training large scale quantum models.,Enhancing variational quantum algorithms by balancing training on classical and quantum hardware,"['quantum', 'hardware', 'quantum hardware', 'training', 'using', 'estimation', 'algebra', 'challenges', 'classical', 'ground']",Quantum computers offer a promising route to tackling problems that are classically intractable such as in prime factorization solving large scale linear algebra and simulating complex quantum systems but require fault tolerant quantum hardware.
2503.15769v1,Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations,"Blockchain is increasingly offered as blockchain-as-a-service (BaaS) by cloud
service providers. However, configuring BaaS appropriately for optimal
performance and reliability resorts to try-and-error. A key challenge is that
BaaS is often perceived as a ``black-box,'' leading to uncertainties in
performance and resource provisioning. Previous studies attempted to address
this challenge; however, the impacts of both vertical and horizontal scaling
remain elusive. To this end, we present machine learning-based models to
predict network reliability and throughput based on scaling configurations. In
our evaluation, the models exhibit prediction errors of ~1.9%, which is highly
accurate and can be applied in the real-world.","['cs.DC', 'cs.LG', 'cs.SY', 'eess.SY']","['Seungwoo Jung', 'Yeonho Yoo', 'Gyeongsik Yang', 'Chuck Yoo']",2025-03-20,2025-03-20,Blockchain is increasingly offered as blockchain as a service BaaS by cloud service providers. However configuring BaaS appropriately for optimal performance and reliability resorts to try and error. A key challenge is that BaaS is often perceived as a black box leading to uncertainties in performance and resource provisioning. Previous studies attempted to address this challenge however the impacts of both vertical and horizontal scaling remain elusive. To this end we present machine learning based models to predict network reliability and throughput based on scaling configurations. In our evaluation the models exhibit prediction errors of 1.9 which is highly accurate and can be applied in the real world.,Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations,"['baas', 'based', 'blockchain', 'challenge', 'models', 'performance', 'reliability', 'scaling', 'service', 'accurate']",Blockchain is increasingly offered as blockchain as a service BaaS by cloud service providers.
2503.14345v2,MoonCast: High-Quality Zero-Shot Podcast Generation,"Recent advances in text-to-speech synthesis have achieved notable success in
generating high-quality short utterances for individual speakers. However,
these systems still face challenges when extending their capabilities to long,
multi-speaker, and spontaneous dialogues, typical of real-world scenarios such
as podcasts. These limitations arise from two primary challenges: 1) long
speech: podcasts typically span several minutes, exceeding the upper limit of
most existing work; 2) spontaneity: podcasts are marked by their spontaneous,
oral nature, which sharply contrasts with formal, written contexts; existing
works often fall short in capturing this spontaneity. In this paper, we propose
MoonCast, a solution for high-quality zero-shot podcast generation, aiming to
synthesize natural podcast-style speech from text-only sources (e.g., stories,
technical reports, news in TXT, PDF, or Web URL formats) using the voices of
unseen speakers. To generate long audio, we adopt a long-context language
model-based audio modeling approach utilizing large-scale long-context speech
data. To enhance spontaneity, we utilize a podcast generation module to
generate scripts with spontaneous details, which have been empirically shown to
be as crucial as the text-to-speech modeling itself. Experiments demonstrate
that MoonCast outperforms baselines, with particularly notable improvements in
spontaneity and coherence.","['eess.AS', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.SD']","['Zeqian Ju', 'Dongchao Yang', 'Jianwei Yu', 'Kai Shen', 'Yichong Leng', 'Zhengtao Wang', 'Xu Tan', 'Xinyu Zhou', 'Tao Qin', 'Xiangyang Li']",2025-03-18,2025-03-19,Recent advances in text to speech synthesis have achieved notable success in generating high quality short utterances for individual speakers. However these systems still face challenges when extending their capabilities to long multi speaker and spontaneous dialogues typical of real world scenarios such as podcasts. These limitations arise from two primary challenges 1 long speech podcasts typically span several minutes exceeding the upper limit of most existing work 2 spontaneity podcasts are marked by their spontaneous oral nature which sharply contrasts with formal written contexts existing works often fall short in capturing this spontaneity. In this paper we propose MoonCast a solution for high quality zero shot podcast generation aiming to synthesize natural podcast style speech from text only sources e.g. stories technical reports news in TXT PDF or Web URL formats using the voices of unseen speakers. To generate long audio we adopt a long context language model based audio modeling approach utilizing large scale long context speech data. To enhance spontaneity we utilize a podcast generation module to generate scripts with spontaneous details which have been empirically shown to be as crucial as the text to speech modeling itself. Experiments demonstrate that MoonCast outperforms baselines with particularly notable improvements in spontaneity and coherence.,MoonCast High Quality Zero Shot Podcast Generation,"['long', 'speech', 'spontaneity', 'podcast', 'podcasts', 'spontaneous', 'text', 'audio', 'challenges', 'context']",Recent advances in text to speech synthesis have achieved notable success in generating high quality short utterances for individual speakers.
2503.15166v1,Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU,"Machine unlearning methods have become increasingly important for selective
concept removal in large pre-trained models. While recent work has explored
unlearning in Euclidean contrastive vision-language models, the effectiveness
of concept removal in hyperbolic spaces remains unexplored. This paper
investigates machine unlearning in hyperbolic contrastive learning by adapting
Alignment Calibration to MERU, a model that embeds images and text in
hyperbolic space to better capture semantic hierarchies. Through systematic
experiments and ablation studies, we demonstrate that hyperbolic geometry
offers distinct advantages for concept removal, achieving near perfect
forgetting with reasonable performance on retained concepts, particularly when
scaling to multiple concept removal. Our approach introduces
hyperbolic-specific components including entailment calibration and norm
regularization that leverage the unique properties of hyperbolic space.
Comparative analysis with Euclidean models reveals fundamental differences in
unlearning dynamics, with hyperbolic unlearning reorganizing the semantic
hierarchy while Euclidean approaches merely disconnect cross-modal
associations. These findings not only advance machine unlearning techniques but
also provide insights into the geometric properties that influence concept
representation and removal in multimodal models. Source code available at
https://github.com/alex-pv01/HAC","['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM']","['Ãlex Pujol Vidal', 'Sergio Escalera', 'Kamal Nasrollahi', 'Thomas B. Moeslund']",2025-03-19,2025-03-19,Machine unlearning methods have become increasingly important for selective concept removal in large pre trained models. While recent work has explored unlearning in Euclidean contrastive vision language models the effectiveness of concept removal in hyperbolic spaces remains unexplored. This paper investigates machine unlearning in hyperbolic contrastive learning by adapting Alignment Calibration to MERU a model that embeds images and text in hyperbolic space to better capture semantic hierarchies. Through systematic experiments and ablation studies we demonstrate that hyperbolic geometry offers distinct advantages for concept removal achieving near perfect forgetting with reasonable performance on retained concepts particularly when scaling to multiple concept removal. Our approach introduces hyperbolic specific components including entailment calibration and norm regularization that leverage the unique properties of hyperbolic space. Comparative analysis with Euclidean models reveals fundamental differences in unlearning dynamics with hyperbolic unlearning reorganizing the semantic hierarchy while Euclidean approaches merely disconnect cross modal associations. These findings not only advance machine unlearning techniques but also provide insights into the geometric properties that influence concept representation and removal in multimodal models. Source code available at https github.com alex pv01 HAC,Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning Adapting Alignment Calibration to MERU,"['hyperbolic', 'unlearning', 'concept', 'removal', 'concept removal', 'models', 'euclidean', 'machine', 'machine unlearning', 'calibration']",Machine unlearning methods have become increasingly important for selective concept removal in large pre trained models.
2503.15056v1,Single-Step Bidirectional Unpaired Image Translation Using Implicit Bridge Consistency Distillation,"Unpaired image-to-image translation has seen significant progress since the
introduction of CycleGAN. However, methods based on diffusion models or
Schr\""odinger bridges have yet to be widely adopted in real-world applications
due to their iterative sampling nature. To address this challenge, we propose a
novel framework, Implicit Bridge Consistency Distillation (IBCD), which enables
single-step bidirectional unpaired translation without using adversarial loss.
IBCD extends consistency distillation by using a diffusion implicit bridge
model that connects PF-ODE trajectories between distributions. Additionally, we
introduce two key improvements: 1) distribution matching for consistency
distillation and 2) adaptive weighting method based on distillation difficulty.
Experimental results demonstrate that IBCD achieves state-of-the-art
performance on benchmark datasets in a single generation step. Project page
available at https://hyn2028.github.io/project_page/IBCD/index.html",['cs.CV'],"['Suhyeon Lee', 'Kwanyoung Kim', 'Jong Chul Ye']",2025-03-19,2025-03-19,Unpaired image to image translation has seen significant progress since the introduction of CycleGAN. However methods based on diffusion models or Schr odinger bridges have yet to be widely adopted in real world applications due to their iterative sampling nature. To address this challenge we propose a novel framework Implicit Bridge Consistency Distillation IBCD which enables single step bidirectional unpaired translation without using adversarial loss. IBCD extends consistency distillation by using a diffusion implicit bridge model that connects PF ODE trajectories between distributions. Additionally we introduce two key improvements 1 distribution matching for consistency distillation and 2 adaptive weighting method based on distillation difficulty. Experimental results demonstrate that IBCD achieves state of the art performance on benchmark datasets in a single generation step. Project page available at https hyn2028.github.io project_page IBCD index.html,Single Step Bidirectional Unpaired Image Translation Using Implicit Bridge Consistency Distillation,"['distillation', 'ibcd', 'consistency', 'consistency distillation', 'based', 'bridge', 'diffusion', 'image', 'implicit', 'implicit bridge']",Unpaired image to image translation has seen significant progress since the introduction of CycleGAN.
2503.16335v1,Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model,"An AI-powered quality engineering platform uses artificial intelligence to
boost software quality assessments through automated defect prediction and
optimized performance alongside improved feature extraction. Existing models
result in difficulties addressing noisy data types together with imbalances,
pattern recognition complexities, ineffective feature extraction, and
generalization weaknesses. To overcome those existing challenges in this
research, we develop a new model Adaptive Differential Evolution based Quantum
Variational Autoencoder-Transformer Model (ADE-QVAET), that combines a Quantum
Variational Autoencoder-Transformer (QVAET) to obtain high-dimensional latent
features and maintain sequential dependencies together with contextual
relationships, resulting in superior defect prediction accuracy. Adaptive
Differential Evolution (ADE) Optimization utilizes an adaptive parameter tuning
method that enhances model convergence and predictive performance. ADE-QVAET
integrates advanced AI techniques to create a robust solution for scalable and
accurate software defect prediction that represents a top-level AI-driven
technology for quality engineering applications. The proposed ADE-QVAET model
attains high accuracy, precision, recall, and f1-score during the training
percentage (TP) 90 of 98.08%, 92.45%, 94.67%, and 98.12%.","['cs.AI', 'cs.ET']","['Seshu Babu Barma', 'Mohanakrishnan Hariharan', 'Satish Arvapalli']",2025-03-20,2025-03-20,An AI powered quality engineering platform uses artificial intelligence to boost software quality assessments through automated defect prediction and optimized performance alongside improved feature extraction. Existing models result in difficulties addressing noisy data types together with imbalances pattern recognition complexities ineffective feature extraction and generalization weaknesses. To overcome those existing challenges in this research we develop a new model Adaptive Differential Evolution based Quantum Variational Autoencoder Transformer Model ADE QVAET that combines a Quantum Variational Autoencoder Transformer QVAET to obtain high dimensional latent features and maintain sequential dependencies together with contextual relationships resulting in superior defect prediction accuracy. Adaptive Differential Evolution ADE Optimization utilizes an adaptive parameter tuning method that enhances model convergence and predictive performance. ADE QVAET integrates advanced AI techniques to create a robust solution for scalable and accurate software defect prediction that represents a top level AI driven technology for quality engineering applications. The proposed ADE QVAET model attains high accuracy precision recall and f1 score during the training percentage TP 90 of 98.08 92.45 94.67 and 98.12 .,Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder Transformer Model,"['ade', 'model', 'qvaet', 'adaptive', 'ade qvaet', 'ai', 'defect', 'defect prediction', 'prediction', 'quality']",An AI powered quality engineering platform uses artificial intelligence to boost software quality assessments through automated defect prediction and optimized performance alongside improved feature extraction.
2503.16165v1,Iterative Optimal Attention and Local Model for Single Image Rain Streak Removal,"High-fidelity imaging is crucial for the successful safety supervision and
intelligent deployment of vision-based measurement systems (VBMS). It ensures
high-quality imaging in VBMS, which is fundamental for reliable visual
measurement and analysis. However, imaging quality can be significantly
impaired by adverse weather conditions, particularly rain, leading to blurred
images and reduced contrast. Such impairments increase the risk of inaccurate
evaluations and misinterpretations in VBMS. To address these limitations, we
propose an Expectation Maximization Reconstruction Transformer (EMResformer)
for single image rain streak removal. The EMResformer retains the key
self-attention values for feature aggregation, enhancing local features to
produce superior image reconstruction. Specifically, we propose an Expectation
Maximization Block seamlessly integrated into the single image rain streak
removal network, enhancing its ability to eliminate superfluous information and
restore a cleaner background image. Additionally, to further enhance local
information for improved detail rendition, we introduce a Local Model Residual
Block, which integrates two local model blocks along with a sequence of
convolutions and activation functions. This integration synergistically
facilitates the extraction of more pertinent features for enhanced single image
rain streak removal. Extensive experiments validate that our proposed
EMResformer surpasses current state-of-the-art single image rain streak removal
methods on both synthetic and real-world datasets, achieving an improved
balance between model complexity and single image deraining performance.
Furthermore, we evaluate the effectiveness of our method in VBMS scenarios,
demonstrating that high-quality imaging significantly improves the accuracy and
reliability of VBMS tasks.","['cs.CV', 'cs.IR']","['Xiangyu Li', 'Wanshu Fan', 'Yue Shen', 'Cong Wang', 'Wei Wang', 'Xin Yang', 'Qiang Zhang', 'Dongsheng Zhou']",2025-03-20,2025-03-20,High fidelity imaging is crucial for the successful safety supervision and intelligent deployment of vision based measurement systems VBMS . It ensures high quality imaging in VBMS which is fundamental for reliable visual measurement and analysis. However imaging quality can be significantly impaired by adverse weather conditions particularly rain leading to blurred images and reduced contrast. Such impairments increase the risk of inaccurate evaluations and misinterpretations in VBMS. To address these limitations we propose an Expectation Maximization Reconstruction Transformer EMResformer for single image rain streak removal. The EMResformer retains the key self attention values for feature aggregation enhancing local features to produce superior image reconstruction. Specifically we propose an Expectation Maximization Block seamlessly integrated into the single image rain streak removal network enhancing its ability to eliminate superfluous information and restore a cleaner background image. Additionally to further enhance local information for improved detail rendition we introduce a Local Model Residual Block which integrates two local model blocks along with a sequence of convolutions and activation functions. This integration synergistically facilitates the extraction of more pertinent features for enhanced single image rain streak removal. Extensive experiments validate that our proposed EMResformer surpasses current state of the art single image rain streak removal methods on both synthetic and real world datasets achieving an improved balance between model complexity and single image deraining performance. Furthermore we evaluate the effectiveness of our method in VBMS scenarios demonstrating that high quality imaging significantly improves the accuracy and reliability of VBMS tasks.,Iterative Optimal Attention and Local Model for Single Image Rain Streak Removal,"['image', 'rain', 'single', 'single image', 'vbms', 'image rain', 'imaging', 'local', 'rain streak', 'removal']",High fidelity imaging is crucial for the successful safety supervision and intelligent deployment of vision based measurement systems VBMS .
2503.15984v1,DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration,"Contemporary image restoration and super-resolution techniques effectively
harness deep neural networks, markedly outperforming traditional methods.
However, astrophotography presents unique challenges for deep learning due to
limited training data. This work explores hybrid strategies, such as the Deep
Image Prior (DIP) model, which facilitates blind training but is susceptible to
overfitting, artifact generation, and instability when handling noisy images.
We propose enhancements to the DIP model's baseline performance through several
advanced techniques. First, we refine the model to process multiple frames
concurrently, employing the Back Projection method and the TVNet model. Next,
we adopt a Markov approach incorporating Monte Carlo estimation, Langevin
dynamics, and a variational input technique to achieve unbiased estimates with
minimal variance and counteract overfitting effectively. Collectively, these
modifications reduce the likelihood of noise learning and mitigate loss
function fluctuations during training, enhancing result stability. We validated
our algorithm across multiple image sets of astronomical and celestial objects,
achieving performance that not only mitigates limitations of Lucky Imaging, a
classical computer vision technique that remains a standard in astronomical
image reconstruction but surpasses the original DIP model, state of the art
transformer- and diffusion-based models, underscoring the significance of our
improvements.","['cs.CV', 'astro-ph.IM', 'cs.AI', 'eess.IV']","['Suraj Singh', 'Anastasia Batsheva', 'Oleg Y. Rogov', 'Ahmed Bouridane']",2025-03-20,2025-03-20,Contemporary image restoration and super resolution techniques effectively harness deep neural networks markedly outperforming traditional methods. However astrophotography presents unique challenges for deep learning due to limited training data. This work explores hybrid strategies such as the Deep Image Prior DIP model which facilitates blind training but is susceptible to overfitting artifact generation and instability when handling noisy images. We propose enhancements to the DIP model s baseline performance through several advanced techniques. First we refine the model to process multiple frames concurrently employing the Back Projection method and the TVNet model. Next we adopt a Markov approach incorporating Monte Carlo estimation Langevin dynamics and a variational input technique to achieve unbiased estimates with minimal variance and counteract overfitting effectively. Collectively these modifications reduce the likelihood of noise learning and mitigate loss function fluctuations during training enhancing result stability. We validated our algorithm across multiple image sets of astronomical and celestial objects achieving performance that not only mitigates limitations of Lucky Imaging a classical computer vision technique that remains a standard in astronomical image reconstruction but surpasses the original DIP model state of the art transformer and diffusion based models underscoring the significance of our improvements.,DIPLI Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration,"['model', 'image', 'deep', 'dip', 'dip model', 'training', 'astronomical', 'effectively', 'learning', 'multiple']",Contemporary image restoration and super resolution techniques effectively harness deep neural networks markedly outperforming traditional methods.
2503.15831v1,EDEN: Enhanced Diffusion for High-quality Large-motion Video Frame Interpolation,"Handling complex or nonlinear motion patterns has long posed challenges for
video frame interpolation. Although recent advances in diffusion-based methods
offer improvements over traditional optical flow-based approaches, they still
struggle to generate sharp, temporally consistent frames in scenarios with
large motion. To address this limitation, we introduce EDEN, an Enhanced
Diffusion for high-quality large-motion vidEo frame iNterpolation. Our approach
first utilizes a transformer-based tokenizer to produce refined latent
representations of the intermediate frames for diffusion models. We then
enhance the diffusion transformer with temporal attention across the process
and incorporate a start-end frame difference embedding to guide the generation
of dynamic motion. Extensive experiments demonstrate that EDEN achieves
state-of-the-art results across popular benchmarks, including nearly a 10%
LPIPS reduction on DAVIS and SNU-FILM, and an 8% improvement on DAIN-HD.",['cs.CV'],"['Zihao Zhang', 'Haoran Chen', 'Haoyu Zhao', 'Guansong Lu', 'Yanwei Fu', 'Hang Xu', 'Zuxuan Wu']",2025-03-20,2025-03-20,Handling complex or nonlinear motion patterns has long posed challenges for video frame interpolation. Although recent advances in diffusion based methods offer improvements over traditional optical flow based approaches they still struggle to generate sharp temporally consistent frames in scenarios with large motion. To address this limitation we introduce EDEN an Enhanced Diffusion for high quality large motion vidEo frame iNterpolation. Our approach first utilizes a transformer based tokenizer to produce refined latent representations of the intermediate frames for diffusion models. We then enhance the diffusion transformer with temporal attention across the process and incorporate a start end frame difference embedding to guide the generation of dynamic motion. Extensive experiments demonstrate that EDEN achieves state of the art results across popular benchmarks including nearly a 10 LPIPS reduction on DAVIS and SNU FILM and an 8 improvement on DAIN HD.,EDEN Enhanced Diffusion for High quality Large motion Video Frame Interpolation,"['diffusion', 'motion', 'based', 'frame', 'eden', 'frame interpolation', 'frames', 'interpolation', 'large', 'large motion']",Handling complex or nonlinear motion patterns has long posed challenges for video frame interpolation.
2503.16777v1,Physics-Informed Deep B-Spline Networks for Dynamical Systems,"Physics-informed machine learning provides an approach to combining data and
governing physics laws for solving complex partial differential equations
(PDEs). However, efficiently solving PDEs with varying parameters and changing
initial conditions and boundary conditions (ICBCs) with theoretical guarantees
remains an open challenge. We propose a hybrid framework that uses a neural
network to learn B-spline control points to approximate solutions to PDEs with
varying system and ICBC parameters. The proposed network can be trained
efficiently as one can directly specify ICBCs without imposing losses,
calculate physics-informed loss functions through analytical formulas, and
requires only learning the weights of B-spline functions as opposed to both
weights and basis as in traditional neural operator learning methods. We
provide theoretical guarantees that the proposed B-spline networks serve as
universal approximators for the set of solutions of PDEs with varying ICBCs
under mild conditions and establish bounds on the generalization errors in
physics-informed learning. We also demonstrate in experiments that the proposed
B-spline network can solve problems with discontinuous ICBCs and outperforms
existing methods, and is able to learn solutions of 3D dynamics with diverse
initial conditions.","['cs.LG', 'cs.SY', 'eess.SY']","['Zhuoyuan Wang', 'Raffaele Romagnoli', 'Jasmine Ratchford', 'Yorie Nakahira']",2025-03-21,2025-03-21,Physics informed machine learning provides an approach to combining data and governing physics laws for solving complex partial differential equations PDEs . However efficiently solving PDEs with varying parameters and changing initial conditions and boundary conditions ICBCs with theoretical guarantees remains an open challenge. We propose a hybrid framework that uses a neural network to learn B spline control points to approximate solutions to PDEs with varying system and ICBC parameters. The proposed network can be trained efficiently as one can directly specify ICBCs without imposing losses calculate physics informed loss functions through analytical formulas and requires only learning the weights of B spline functions as opposed to both weights and basis as in traditional neural operator learning methods. We provide theoretical guarantees that the proposed B spline networks serve as universal approximators for the set of solutions of PDEs with varying ICBCs under mild conditions and establish bounds on the generalization errors in physics informed learning. We also demonstrate in experiments that the proposed B spline network can solve problems with discontinuous ICBCs and outperforms existing methods and is able to learn solutions of 3D dynamics with diverse initial conditions.,Physics Informed Deep B Spline Networks for Dynamical Systems,"['conditions', 'icbcs', 'learning', 'pdes', 'physics', 'spline', 'informed', 'network', 'pdes varying', 'physics informed']",Physics informed machine learning provides an approach to combining data and governing physics laws for solving complex partial differential equations PDEs .
2503.14976v2,Application of linear regression method to the deep reinforcement learning in continuous action cases,"The linear regression (LR) method offers the advantage that optimal
parameters can be calculated relatively easily, although its representation
capability is limited than that of the deep learning technique. To improve deep
reinforcement learning, the Least Squares Deep Q Network (LS-DQN) method was
proposed by Levine et al., which combines Deep Q Network (DQN) with LR method.
However, the LS-DQN method assumes that the actions are discrete. In this
study, we propose the Double Least Squares Deep Deterministic Policy Gradient
(DLS-DDPG) method to address this limitation. This method combines the LR
method with the Deep Deterministic Policy Gradient (DDPG) technique, one of the
representative deep reinforcement learning algorithms for continuous action
cases. Numerical experiments conducted in MuJoCo environments showed that the
LR update improved performance at least in some tasks, although there are
difficulties such as the inability to make the regularization terms small.","['cs.LG', 'cs.AI']",['Hisato Komatsu'],2025-03-19,2025-03-21,The linear regression LR method offers the advantage that optimal parameters can be calculated relatively easily although its representation capability is limited than that of the deep learning technique. To improve deep reinforcement learning the Least Squares Deep Q Network LS DQN method was proposed by Levine et al. which combines Deep Q Network DQN with LR method. However the LS DQN method assumes that the actions are discrete. In this study we propose the Double Least Squares Deep Deterministic Policy Gradient DLS DDPG method to address this limitation. This method combines the LR method with the Deep Deterministic Policy Gradient DDPG technique one of the representative deep reinforcement learning algorithms for continuous action cases. Numerical experiments conducted in MuJoCo environments showed that the LR update improved performance at least in some tasks although there are difficulties such as the inability to make the regularization terms small.,Application of linear regression method to the deep reinforcement learning in continuous action cases,"['deep', 'method', 'lr', 'dqn', 'learning', 'lr method', 'combines', 'ddpg', 'deep deterministic', 'deep network']",The linear regression LR method offers the advantage that optimal parameters can be calculated relatively easily although its representation capability is limited than that of the deep learning technique.
2503.16024v1,The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement,"Large language models (LLMs) have recently transformed from text-based
assistants to autonomous agents capable of planning, reasoning, and iteratively
improving their actions. While numerical reward signals and verifiers can
effectively rank candidate actions, they often provide limited contextual
guidance. In contrast, natural language feedback better aligns with the
generative capabilities of LLMs, providing richer and more actionable
suggestions. However, parsing and implementing this feedback effectively can be
challenging for LLM-based agents. In this work, we introduce Critique-Guided
Improvement (CGI), a novel two-player framework, comprising an actor model that
explores an environment and a critic model that generates detailed nature
language feedback. By training the critic to produce fine-grained assessments
and actionable revisions, and the actor to utilize these critiques, our
approach promotes more robust exploration of alternative strategies while
avoiding local optima. Experiments in three interactive environments show that
CGI outperforms existing baselines by a substantial margin. Notably, even a
small critic model surpasses GPT-4 in feedback quality. The resulting actor
achieves state-of-the-art performance, demonstrating the power of explicit
iterative guidance to enhance decision-making in LLM-based agents.","['cs.CL', 'cs.AI']","['Ruihan Yang', 'Fanghua Ye', 'Jian Li', 'Siyu Yuan', 'Yikai Zhang', 'Zhaopeng Tu', 'Xiaolong Li', 'Deqing Yang']",2025-03-20,2025-03-20,Large language models LLMs have recently transformed from text based assistants to autonomous agents capable of planning reasoning and iteratively improving their actions. While numerical reward signals and verifiers can effectively rank candidate actions they often provide limited contextual guidance. In contrast natural language feedback better aligns with the generative capabilities of LLMs providing richer and more actionable suggestions. However parsing and implementing this feedback effectively can be challenging for LLM based agents. In this work we introduce Critique Guided Improvement CGI a novel two player framework comprising an actor model that explores an environment and a critic model that generates detailed nature language feedback. By training the critic to produce fine grained assessments and actionable revisions and the actor to utilize these critiques our approach promotes more robust exploration of alternative strategies while avoiding local optima. Experiments in three interactive environments show that CGI outperforms existing baselines by a substantial margin. Notably even a small critic model surpasses GPT 4 in feedback quality. The resulting actor achieves state of the art performance demonstrating the power of explicit iterative guidance to enhance decision making in LLM based agents.,The Lighthouse of Language Enhancing LLM Agents via Critique Guided Improvement,"['feedback', 'actor', 'agents', 'based', 'critic', 'language', 'model', 'actionable', 'actions', 'based agents']",Large language models LLMs have recently transformed from text based assistants to autonomous agents capable of planning reasoning and iteratively improving their actions.
2503.15568v1,Mixed precision accumulation for neural network inference guided by componentwise forward error analysis,"This work proposes a mathematically founded mixed precision accumulation
strategy for the inference of neural networks. Our strategy is based on a new
componentwise forward error analysis that explains the propagation of errors in
the forward pass of neural networks. Specifically, our analysis shows that the
error in each component of the output of a layer is proportional to the
condition number of the inner product between the weights and the input,
multiplied by the condition number of the activation function. These condition
numbers can vary widely from one component to the other, thus creating a
significant opportunity to introduce mixed precision: each component should be
accumulated in a precision inversely proportional to the product of these
condition numbers. We propose a practical algorithm that exploits this
observation: it first computes all components in low precision, uses this
output to estimate the condition numbers, and recomputes in higher precision
only the components associated with large condition numbers. We test our
algorithm on various networks and datasets and confirm experimentally that it
can significantly improve the cost--accuracy tradeoff compared with uniform
precision accumulation baselines.","['cs.LG', 'cs.NA', 'math.NA']","['El-Mehdi El Arar', 'Silviu-Ioan Filip', 'Theo Mary', 'Elisa Riccietti']",2025-03-19,2025-03-19,This work proposes a mathematically founded mixed precision accumulation strategy for the inference of neural networks. Our strategy is based on a new componentwise forward error analysis that explains the propagation of errors in the forward pass of neural networks. Specifically our analysis shows that the error in each component of the output of a layer is proportional to the condition number of the inner product between the weights and the input multiplied by the condition number of the activation function. These condition numbers can vary widely from one component to the other thus creating a significant opportunity to introduce mixed precision each component should be accumulated in a precision inversely proportional to the product of these condition numbers. We propose a practical algorithm that exploits this observation it first computes all components in low precision uses this output to estimate the condition numbers and recomputes in higher precision only the components associated with large condition numbers. We test our algorithm on various networks and datasets and confirm experimentally that it can significantly improve the cost accuracy tradeoff compared with uniform precision accumulation baselines.,Mixed precision accumulation for neural network inference guided by componentwise forward error analysis,"['condition', 'precision', 'condition numbers', 'numbers', 'component', 'networks', 'accumulation', 'algorithm', 'analysis', 'components']",This work proposes a mathematically founded mixed precision accumulation strategy for the inference of neural networks.
2503.17101v1,Large Language Model Compression via the Nested Activation-Aware Decomposition,"In this paper, we tackle the critical challenge of compressing large language
models (LLMs) to facilitate their practical deployment and broader adoption. We
introduce a novel post-training compression paradigm that focuses on low-rank
decomposition of LLM weights. Our analysis identifies two main challenges in
this task: the variability in LLM activation distributions and handling unseen
activations from different datasets and models.
  To address these challenges, we propose a nested activation-aware framework
(NSVD) for LLMs, a training-free approach designed to enhance the accuracy of
low-rank decompositions by managing activation outliers through transforming
the weight matrix based on activation distribution and the original weight
matrix. This method allows for the absorption of outliers into the transformed
weight matrix, improving decomposition accuracy. Our comprehensive evaluation
across eight datasets and six models from three distinct LLM families
demonstrates the superiority of NSVD over current state-of-the-art methods,
especially at medium to large compression ratios or in multilingual and
multitask settings.",['cs.LG'],"['Jun Lu', 'Tianyi Xu', 'Bill Ding', 'David Li', 'Yu Kang']",2025-03-21,2025-03-21,In this paper we tackle the critical challenge of compressing large language models LLMs to facilitate their practical deployment and broader adoption. We introduce a novel post training compression paradigm that focuses on low rank decomposition of LLM weights. Our analysis identifies two main challenges in this task the variability in LLM activation distributions and handling unseen activations from different datasets and models. To address these challenges we propose a nested activation aware framework NSVD for LLMs a training free approach designed to enhance the accuracy of low rank decompositions by managing activation outliers through transforming the weight matrix based on activation distribution and the original weight matrix. This method allows for the absorption of outliers into the transformed weight matrix improving decomposition accuracy. Our comprehensive evaluation across eight datasets and six models from three distinct LLM families demonstrates the superiority of NSVD over current state of the art methods especially at medium to large compression ratios or in multilingual and multitask settings.,Large Language Model Compression via the Nested Activation Aware Decomposition,"['activation', 'llm', 'matrix', 'models', 'weight', 'weight matrix', 'accuracy', 'challenges', 'compression', 'datasets']",In this paper we tackle the critical challenge of compressing large language models LLMs to facilitate their practical deployment and broader adoption.
2503.17175v1,Which2comm: An Efficient Collaborative Perception Framework for 3D Object Detection,"Collaborative perception allows real-time inter-agent information exchange
and thus offers invaluable opportunities to enhance the perception capabilities
of individual agents. However, limited communication bandwidth in practical
scenarios restricts the inter-agent data transmission volume, consequently
resulting in performance declines in collaborative perception systems. This
implies a trade-off between perception performance and communication cost. To
address this issue, we propose Which2comm, a novel multi-agent 3D object
detection framework leveraging object-level sparse features. By integrating
semantic information of objects into 3D object detection boxes, we introduce
semantic detection boxes (SemDBs). Innovatively transmitting these
information-rich object-level sparse features among agents not only
significantly reduces the demanding communication volume, but also improves 3D
object detection performance. Specifically, a fully sparse network is
constructed to extract SemDBs from individual agents; a temporal fusion
approach with a relative temporal encoding mechanism is utilized to obtain the
comprehensive spatiotemporal features. Extensive experiments on the V2XSet and
OPV2V datasets demonstrate that Which2comm consistently outperforms other
state-of-the-art methods on both perception performance and communication cost,
exhibiting better robustness to real-world latency. These results present that
for multi-agent collaborative 3D object detection, transmitting only
object-level sparse features is sufficient to achieve high-precision and robust
performance.",['cs.CV'],"['Duanrui Yu', 'Jing You', 'Xin Pei', 'Anqi Qu', 'Dingyu Wang', 'Shaocheng Jia']",2025-03-21,2025-03-21,Collaborative perception allows real time inter agent information exchange and thus offers invaluable opportunities to enhance the perception capabilities of individual agents. However limited communication bandwidth in practical scenarios restricts the inter agent data transmission volume consequently resulting in performance declines in collaborative perception systems. This implies a trade off between perception performance and communication cost. To address this issue we propose Which2comm a novel multi agent 3D object detection framework leveraging object level sparse features. By integrating semantic information of objects into 3D object detection boxes we introduce semantic detection boxes SemDBs . Innovatively transmitting these information rich object level sparse features among agents not only significantly reduces the demanding communication volume but also improves 3D object detection performance. Specifically a fully sparse network is constructed to extract SemDBs from individual agents a temporal fusion approach with a relative temporal encoding mechanism is utilized to obtain the comprehensive spatiotemporal features. Extensive experiments on the V2XSet and OPV2V datasets demonstrate that Which2comm consistently outperforms other state of the art methods on both perception performance and communication cost exhibiting better robustness to real world latency. These results present that for multi agent collaborative 3D object detection transmitting only object level sparse features is sufficient to achieve high precision and robust performance.,Which2comm An Efficient Collaborative Perception Framework for 3D Object Detection,"['object', 'detection', 'perception', 'performance', '3d', '3d object', 'agent', 'communication', 'features', 'object detection']",Collaborative perception allows real time inter agent information exchange and thus offers invaluable opportunities to enhance the perception capabilities of individual agents.
2503.14905v1,Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation,"With the rapid advancement of Artificial Intelligence Generated Content
(AIGC) technologies, synthetic images have become increasingly prevalent in
everyday life, posing new challenges for authenticity assessment and detection.
Despite the effectiveness of existing methods in evaluating image authenticity
and locating forgeries, these approaches often lack human interpretability and
do not fully address the growing complexity of synthetic data. To tackle these
challenges, we introduce FakeVLM, a specialized large multimodal model designed
for both general synthetic image and DeepFake detection tasks. FakeVLM not only
excels in distinguishing real from fake images but also provides clear, natural
language explanations for image artifacts, enhancing interpretability.
Additionally, we present FakeClue, a comprehensive dataset containing over
100,000 images across seven categories, annotated with fine-grained artifact
clues in natural language. FakeVLM demonstrates performance comparable to
expert models while eliminating the need for additional classifiers, making it
a robust solution for synthetic data detection. Extensive evaluations across
multiple datasets confirm the superiority of FakeVLM in both authenticity
classification and artifact explanation tasks, setting a new benchmark for
synthetic image detection. The dataset and code will be released in:
https://github.com/opendatalab/FakeVLM.",['cs.CV'],"['Siwei Wen', 'Junyan Ye', 'Peilin Feng', 'Hengrui Kang', 'Zichen Wen', 'Yize Chen', 'Jiang Wu', 'Wenjun Wu', 'Conghui He', 'Weijia Li']",2025-03-19,2025-03-19,With the rapid advancement of Artificial Intelligence Generated Content AIGC technologies synthetic images have become increasingly prevalent in everyday life posing new challenges for authenticity assessment and detection. Despite the effectiveness of existing methods in evaluating image authenticity and locating forgeries these approaches often lack human interpretability and do not fully address the growing complexity of synthetic data. To tackle these challenges we introduce FakeVLM a specialized large multimodal model designed for both general synthetic image and DeepFake detection tasks. FakeVLM not only excels in distinguishing real from fake images but also provides clear natural language explanations for image artifacts enhancing interpretability. Additionally we present FakeClue a comprehensive dataset containing over 100 000 images across seven categories annotated with fine grained artifact clues in natural language. FakeVLM demonstrates performance comparable to expert models while eliminating the need for additional classifiers making it a robust solution for synthetic data detection. Extensive evaluations across multiple datasets confirm the superiority of FakeVLM in both authenticity classification and artifact explanation tasks setting a new benchmark for synthetic image detection. The dataset and code will be released in https github.com opendatalab FakeVLM.,Spot the Fake Large Multimodal Model Based Synthetic Image Detection with Artifact Explanation,"['fakevlm', 'synthetic', 'detection', 'image', 'authenticity', 'images', 'artifact', 'challenges', 'data', 'dataset']",With the rapid advancement of Artificial Intelligence Generated Content AIGC technologies synthetic images have become increasingly prevalent in everyday life posing new challenges for authenticity assessment and detection.
