id,title,abstract,categories,authors,published_date,updated_date,clean_abstract,clean_title,keywords,target
2503.16222v1,Efficient Bayesian Computation Using Plug-and-Play Priors for Poisson Inverse Problems,"This paper introduces a novel plug-and-play (PnP) Langevin sampling
methodology for Bayesian inference in low-photon Poisson imaging problems, a
challenging class of problems with significant applications in astronomy,
medicine, and biology. PnP Langevin sampling algorithms offer a powerful
framework for Bayesian image restoration, enabling accurate point estimation as
well as advanced inference tasks, including uncertainty quantification and
visualization analyses, and empirical Bayesian inference for automatic model
parameter tuning. However, existing PnP Langevin algorithms are not well-suited
for low-photon Poisson imaging due to high solution uncertainty and poor
regularity properties, such as exploding gradients and non-negativity
constraints. To address these challenges, we propose two strategies for
extending Langevin PnP sampling to Poisson imaging models: (i) an accelerated
PnP Langevin method that incorporates boundary reflections and a Poisson
likelihood approximation and (ii) a mirror sampling algorithm that leverages a
Riemannian geometry to handle the constraints and the poor regularity of the
likelihood without approximations. The effectiveness of these approaches is
demonstrated through extensive numerical experiments and comparisons with
state-of-the-art methods.","['stat.CO', 'cs.CV', 'cs.NA', 'math.NA', 'stat.ML', '53B21, 60H35, 62F15, 65C40, 65C60, 65J22, 68U10']","['Teresa Klatzer', 'Savvas Melidonis', 'Marcelo Pereyra', 'Konstantinos C. Zygalakis']",2025-03-20,2025-03-20,This paper introduces a novel plug and play PnP Langevin sampling methodology for Bayesian inference in low photon Poisson imaging problems a challenging class of problems with significant applications in astronomy medicine and biology. PnP Langevin sampling algorithms offer a powerful framework for Bayesian image restoration enabling accurate point estimation as well as advanced inference tasks including uncertainty quantification and visualization analyses and empirical Bayesian inference for automatic model parameter tuning. However existing PnP Langevin algorithms are not well suited for low photon Poisson imaging due to high solution uncertainty and poor regularity properties such as exploding gradients and non negativity constraints. To address these challenges we propose two strategies for extending Langevin PnP sampling to Poisson imaging models i an accelerated PnP Langevin method that incorporates boundary reflections and a Poisson likelihood approximation and ii a mirror sampling algorithm that leverages a Riemannian geometry to handle the constraints and the poor regularity of the likelihood without approximations. The effectiveness of these approaches is demonstrated through extensive numerical experiments and comparisons with state of the art methods.,Efficient Bayesian Computation Using Plug and Play Priors for Poisson Inverse Problems,"['langevin', 'pnp', 'pnp langevin', 'poisson', 'sampling', 'bayesian', 'imaging', 'inference', 'poisson imaging', 'algorithms']",This paper introduces a novel plug and play PnP Langevin sampling methodology for Bayesian inference in low photon Poisson imaging problems a challenging class of problems with significant applications in astronomy medicine and biology.
2503.17095v1,FFaceNeRF: Few-shot Face Editing in Neural Radiance Fields,"Recent 3D face editing methods using masks have produced high-quality edited
images by leveraging Neural Radiance Fields (NeRF). Despite their impressive
performance, existing methods often provide limited user control due to the use
of pre-trained segmentation masks. To utilize masks with a desired layout, an
extensive training dataset is required, which is challenging to gather. We
present FFaceNeRF, a NeRF-based face editing technique that can overcome the
challenge of limited user control due to the use of fixed mask layouts. Our
method employs a geometry adapter with feature injection, allowing for
effective manipulation of geometry attributes. Additionally, we adopt latent
mixing for tri-plane augmentation, which enables training with a few samples.
This facilitates rapid model adaptation to desired mask layouts, crucial for
applications in fields like personalized medical imaging or creative face
editing. Our comparative evaluations demonstrate that FFaceNeRF surpasses
existing mask based face editing methods in terms of flexibility, control, and
generated image quality, paving the way for future advancements in customized
and high-fidelity 3D face editing. The code is available on the
{\href{https://kwanyun.github.io/FFaceNeRF_page/}{project-page}}.","['cs.GR', 'cs.AI', 'cs.CV', '68T45, 68U05', 'I.3.3; I.3.8']","['Kwan Yun', 'Chaelin Kim', 'Hangyeul Shin', 'Junyong Noh']",2025-03-21,2025-03-21,Recent 3D face editing methods using masks have produced high quality edited images by leveraging Neural Radiance Fields NeRF . Despite their impressive performance existing methods often provide limited user control due to the use of pre trained segmentation masks. To utilize masks with a desired layout an extensive training dataset is required which is challenging to gather. We present FFaceNeRF a NeRF based face editing technique that can overcome the challenge of limited user control due to the use of fixed mask layouts. Our method employs a geometry adapter with feature injection allowing for effective manipulation of geometry attributes. Additionally we adopt latent mixing for tri plane augmentation which enables training with a few samples. This facilitates rapid model adaptation to desired mask layouts crucial for applications in fields like personalized medical imaging or creative face editing. Our comparative evaluations demonstrate that FFaceNeRF surpasses existing mask based face editing methods in terms of flexibility control and generated image quality paving the way for future advancements in customized and high fidelity 3D face editing. The code is available on the href https kwanyun.github.io FFaceNeRF_page project page .,FFaceNeRF Few shot Face Editing in Neural Radiance Fields,"['editing', 'face', 'face editing', 'control', 'mask', 'masks', 'methods', '3d', '3d face', 'based']",Recent 3D face editing methods using masks have produced high quality edited images by leveraging Neural Radiance Fields NeRF .
2503.16376v1,LaPIG: Cross-Modal Generation of Paired Thermal and Visible Facial Images,"The success of modern machine learning, particularly in facial translation
networks, is highly dependent on the availability of high-quality, paired,
large-scale datasets. However, acquiring sufficient data is often challenging
and costly. Inspired by the recent success of diffusion models in high-quality
image synthesis and advancements in Large Language Models (LLMs), we propose a
novel framework called LLM-assisted Paired Image Generation (LaPIG). This
framework enables the construction of comprehensive, high-quality paired
visible and thermal images using captions generated by LLMs. Our method
encompasses three parts: visible image synthesis with ArcFace embedding,
thermal image translation using Latent Diffusion Models (LDMs), and caption
generation with LLMs. Our approach not only generates multi-view paired visible
and thermal images to increase data diversity but also produces high-quality
paired data while maintaining their identity information. We evaluate our
method on public datasets by comparing it with existing methods, demonstrating
the superiority of LaPIG.",['cs.CV'],"['Leyang Wang', 'Joice Lin']",2025-03-20,2025-03-20,The success of modern machine learning particularly in facial translation networks is highly dependent on the availability of high quality paired large scale datasets. However acquiring sufficient data is often challenging and costly. Inspired by the recent success of diffusion models in high quality image synthesis and advancements in Large Language Models LLMs we propose a novel framework called LLM assisted Paired Image Generation LaPIG . This framework enables the construction of comprehensive high quality paired visible and thermal images using captions generated by LLMs. Our method encompasses three parts visible image synthesis with ArcFace embedding thermal image translation using Latent Diffusion Models LDMs and caption generation with LLMs. Our approach not only generates multi view paired visible and thermal images to increase data diversity but also produces high quality paired data while maintaining their identity information. We evaluate our method on public datasets by comparing it with existing methods demonstrating the superiority of LaPIG.,LaPIG Cross Modal Generation of Paired Thermal and Visible Facial Images,"['paired', 'high', 'high quality', 'image', 'quality', 'data', 'llms', 'models', 'quality paired', 'thermal']",The success of modern machine learning particularly in facial translation networks is highly dependent on the availability of high quality paired large scale datasets.
2503.16678v1,QCPINN: Quantum Classical Physics-Informed Neural Networks for Solving PDEs,"Hybrid quantum-classical neural network methods represent an emerging
approach to solving computational challenges by leveraging advantages from both
paradigms. As physics-informed neural networks (PINNs) have successfully
applied to solve partial differential equations (PDEs) by incorporating
physical constraints into neural architectures, this work investigates whether
quantum-classical physics-informed neural networks (QCPINNs) can efficiently
solve PDEs with reduced parameter counts compared to classical approaches. We
evaluate two quantum circuit paradigms: continuous-variable (CV) and
qubit-based discrete-variable (DV) across multiple circuit ansatze (Alternate,
Cascade, Cross mesh, and Layered). Benchmarking across five challenging PDEs
(Helmholtz, Cavity, Wave, Klein-Gordon, and Convection-Diffusion equations)
demonstrates that our hybrid approaches achieve comparable accuracy to
classical PINNs while requiring up to 89% fewer trainable parameters. DV-based
implementations, particularly those with angle encoding and cascade circuit
configurations, exhibit better stability and convergence properties across all
problem types. For the Convection-Diffusion equation, our angle-cascade QCPINN
achieves parameter efficiency and a 37% reduction in relative L2 error compared
to classical counterparts. Our findings highlight the potential of
quantum-enhanced architectures for physics-informed learning, establishing
parameter efficiency as a quantifiable quantum advantage while providing a
foundation for future quantum-classical hybrid systems solving complex physical
models.","['quant-ph', 'cs.LG']","['Afrah Farea', 'Saiful Khan', 'Mustafa Serdar Celebi']",2025-03-20,2025-03-20,Hybrid quantum classical neural network methods represent an emerging approach to solving computational challenges by leveraging advantages from both paradigms. As physics informed neural networks PINNs have successfully applied to solve partial differential equations PDEs by incorporating physical constraints into neural architectures this work investigates whether quantum classical physics informed neural networks QCPINNs can efficiently solve PDEs with reduced parameter counts compared to classical approaches. We evaluate two quantum circuit paradigms continuous variable CV and qubit based discrete variable DV across multiple circuit ansatze Alternate Cascade Cross mesh and Layered . Benchmarking across five challenging PDEs Helmholtz Cavity Wave Klein Gordon and Convection Diffusion equations demonstrates that our hybrid approaches achieve comparable accuracy to classical PINNs while requiring up to 89 fewer trainable parameters. DV based implementations particularly those with angle encoding and cascade circuit configurations exhibit better stability and convergence properties across all problem types. For the Convection Diffusion equation our angle cascade QCPINN achieves parameter efficiency and a 37 reduction in relative L2 error compared to classical counterparts. Our findings highlight the potential of quantum enhanced architectures for physics informed learning establishing parameter efficiency as a quantifiable quantum advantage while providing a foundation for future quantum classical hybrid systems solving complex physical models.,QCPINN Quantum Classical Physics Informed Neural Networks for Solving PDEs,"['classical', 'quantum', 'neural', 'cascade', 'circuit', 'hybrid', 'informed', 'parameter', 'pdes', 'physics']",Hybrid quantum classical neural network methods represent an emerging approach to solving computational challenges by leveraging advantages from both paradigms.
2503.17142v1,Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models,"Vision-Language Models (VLMs) learn a shared feature space for text and
images, enabling the comparison of inputs of different modalities. While prior
works demonstrated that VLMs organize natural language representations into
regular structures encoding composite meanings, it remains unclear if
compositional patterns also emerge in the visual embedding space. In this work,
we investigate compositionality in the image domain, where the analysis of
compositional properties is challenged by noise and sparsity of visual data. We
address these problems and propose a framework, called Geodesically
Decomposable Embeddings (GDE), that approximates image representations with
geometry-aware compositional structures in the latent space. We demonstrate
that visual embeddings of pre-trained VLMs exhibit a compositional arrangement,
and evaluate the effectiveness of this property in the tasks of compositional
classification and group robustness. GDE achieves stronger performance in
compositional classification compared to its counterpart method that assumes
linear geometry of the latent space. Notably, it is particularly effective for
group robustness, where we achieve higher results than task-specific solutions.
Our results indicate that VLMs can automatically develop a human-like form of
compositional reasoning in the visual domain, making their underlying processes
more interpretable. Code is available at
https://github.com/BerasiDavide/vlm_image_compositionality.","['cs.CV', 'cs.LG']","['Davide Berasi', 'Matteo Farina', 'Massimiliano Mancini', 'Elisa Ricci', 'Nicola Strisciuglio']",2025-03-21,2025-03-21,Vision Language Models VLMs learn a shared feature space for text and images enabling the comparison of inputs of different modalities. While prior works demonstrated that VLMs organize natural language representations into regular structures encoding composite meanings it remains unclear if compositional patterns also emerge in the visual embedding space. In this work we investigate compositionality in the image domain where the analysis of compositional properties is challenged by noise and sparsity of visual data. We address these problems and propose a framework called Geodesically Decomposable Embeddings GDE that approximates image representations with geometry aware compositional structures in the latent space. We demonstrate that visual embeddings of pre trained VLMs exhibit a compositional arrangement and evaluate the effectiveness of this property in the tasks of compositional classification and group robustness. GDE achieves stronger performance in compositional classification compared to its counterpart method that assumes linear geometry of the latent space. Notably it is particularly effective for group robustness where we achieve higher results than task specific solutions. Our results indicate that VLMs can automatically develop a human like form of compositional reasoning in the visual domain making their underlying processes more interpretable. Code is available at https github.com BerasiDavide vlm_image_compositionality.,Not Only Text Exploring Compositionality of Visual Representations in Vision Language Models,"['compositional', 'space', 'visual', 'vlms', 'classification', 'compositional classification', 'domain', 'embeddings', 'gde', 'geometry']",Vision Language Models VLMs learn a shared feature space for text and images enabling the comparison of inputs of different modalities.
2503.15017v1,Exploiting Diffusion Prior for Real-World Image Dehazing with Unpaired Training,"Unpaired training has been verified as one of the most effective paradigms
for real scene dehazing by learning from unpaired real-world hazy and clear
images. Although numerous studies have been proposed, current methods
demonstrate limited generalization for various real scenes due to limited
feature representation and insufficient use of real-world prior. Inspired by
the strong generative capabilities of diffusion models in producing both hazy
and clear images, we exploit diffusion prior for real-world image dehazing, and
propose an unpaired framework named Diff-Dehazer. Specifically, we leverage
diffusion prior as bijective mapping learners within the CycleGAN, a classic
unpaired learning framework. Considering that physical priors contain pivotal
statistics information of real-world data, we further excavate real-world
knowledge by integrating physical priors into our framework. Furthermore, we
introduce a new perspective for adequately leveraging the representation
ability of diffusion models by removing degradation in image and text
modalities, so as to improve the dehazing effect. Extensive experiments on
multiple real-world datasets demonstrate the superior performance of our
method. Our code https://github.com/ywxjm/Diff-Dehazer.",['cs.CV'],"['Yunwei Lan', 'Zhigao Cui', 'Chang Liu', 'Jialun Peng', 'Nian Wang', 'Xin Luo', 'Dong Liu']",2025-03-19,2025-03-19,Unpaired training has been verified as one of the most effective paradigms for real scene dehazing by learning from unpaired real world hazy and clear images. Although numerous studies have been proposed current methods demonstrate limited generalization for various real scenes due to limited feature representation and insufficient use of real world prior. Inspired by the strong generative capabilities of diffusion models in producing both hazy and clear images we exploit diffusion prior for real world image dehazing and propose an unpaired framework named Diff Dehazer. Specifically we leverage diffusion prior as bijective mapping learners within the CycleGAN a classic unpaired learning framework. Considering that physical priors contain pivotal statistics information of real world data we further excavate real world knowledge by integrating physical priors into our framework. Furthermore we introduce a new perspective for adequately leveraging the representation ability of diffusion models by removing degradation in image and text modalities so as to improve the dehazing effect. Extensive experiments on multiple real world datasets demonstrate the superior performance of our method. Our code https github.com ywxjm Diff Dehazer.,Exploiting Diffusion Prior for Real World Image Dehazing with Unpaired Training,"['real', 'real world', 'world', 'diffusion', 'unpaired', 'dehazing', 'framework', 'prior', 'clear', 'clear images']",Unpaired training has been verified as one of the most effective paradigms for real scene dehazing by learning from unpaired real world hazy and clear images.
2503.14346v1,3D Densification for Multi-Map Monocular VSLAM in Endoscopy,"Multi-map Sparse Monocular visual Simultaneous Localization and Mapping
applied to monocular endoscopic sequences has proven efficient to robustly
recover tracking after the frequent losses in endoscopy due to motion blur,
temporal occlusion, tools interaction or water jets. The sparse multi-maps are
adequate for robust camera localization, however they are very poor for
environment representation, they are noisy, with a high percentage of
inaccurately reconstructed 3D points, including significant outliers, and more
importantly with an unacceptable low density for clinical applications.
  We propose a method to remove outliers and densify the maps of the state of
the art for sparse endoscopy multi-map CudaSIFT-SLAM. The NN LightDepth for
up-to-scale depth dense predictions are aligned with the sparse CudaSIFT
submaps by means of the robust to spurious LMedS. Our system mitigates the
inherent scale ambiguity in monocular depth estimation while filtering
outliers, leading to reliable densified 3D maps.
  We provide experimental evidence of accurate densified maps 4.15 mm RMS
accuracy at affordable computing time in the C3VD phantom colon dataset. We
report qualitative results on the real colonoscopy from the Endomapper dataset.",['cs.CV'],"['X. Anadón', 'Javier Rodríguez-Puigvert', 'J. M. M. Montiel']",2025-03-18,2025-03-18,Multi map Sparse Monocular visual Simultaneous Localization and Mapping applied to monocular endoscopic sequences has proven efficient to robustly recover tracking after the frequent losses in endoscopy due to motion blur temporal occlusion tools interaction or water jets. The sparse multi maps are adequate for robust camera localization however they are very poor for environment representation they are noisy with a high percentage of inaccurately reconstructed 3D points including significant outliers and more importantly with an unacceptable low density for clinical applications. We propose a method to remove outliers and densify the maps of the state of the art for sparse endoscopy multi map CudaSIFT SLAM. The NN LightDepth for up to scale depth dense predictions are aligned with the sparse CudaSIFT submaps by means of the robust to spurious LMedS. Our system mitigates the inherent scale ambiguity in monocular depth estimation while filtering outliers leading to reliable densified 3D maps. We provide experimental evidence of accurate densified maps 4.15 mm RMS accuracy at affordable computing time in the C3VD phantom colon dataset. We report qualitative results on the real colonoscopy from the Endomapper dataset.,3D Densification for Multi Map Monocular VSLAM in Endoscopy,"['maps', 'sparse', 'monocular', 'multi', 'outliers', '3d', 'cudasift', 'dataset', 'densified', 'depth']",Multi map Sparse Monocular visual Simultaneous Localization and Mapping applied to monocular endoscopic sequences has proven efficient to robustly recover tracking after the frequent losses in endoscopy due to motion blur temporal occlusion tools interaction or water jets.
2503.17172v1,Principal Eigenvalue Regularization for Improved Worst-Class Certified Robustness of Smoothed Classifiers,"Recent studies have identified a critical challenge in deep neural networks
(DNNs) known as ``robust fairness"", where models exhibit significant
disparities in robust accuracy across different classes. While prior work has
attempted to address this issue in adversarial robustness, the study of
worst-class certified robustness for smoothed classifiers remains unexplored.
Our work bridges this gap by developing a PAC-Bayesian bound for the
worst-class error of smoothed classifiers. Through theoretical analysis, we
demonstrate that the largest eigenvalue of the smoothed confusion matrix
fundamentally influences the worst-class error of smoothed classifiers. Based
on this insight, we introduce a regularization method that optimizes the
largest eigenvalue of smoothed confusion matrix to enhance worst-class accuracy
of the smoothed classifier and further improve its worst-class certified
robustness. We provide extensive experimental validation across multiple
datasets and model architectures to demonstrate the effectiveness of our
approach.",['cs.LG'],"['Gaojie Jin', 'Tianjin Huang', 'Ronghui Mu', 'Xiaowei Huang']",2025-03-21,2025-03-21,Recent studies have identified a critical challenge in deep neural networks DNNs known as robust fairness where models exhibit significant disparities in robust accuracy across different classes. While prior work has attempted to address this issue in adversarial robustness the study of worst class certified robustness for smoothed classifiers remains unexplored. Our work bridges this gap by developing a PAC Bayesian bound for the worst class error of smoothed classifiers. Through theoretical analysis we demonstrate that the largest eigenvalue of the smoothed confusion matrix fundamentally influences the worst class error of smoothed classifiers. Based on this insight we introduce a regularization method that optimizes the largest eigenvalue of smoothed confusion matrix to enhance worst class accuracy of the smoothed classifier and further improve its worst class certified robustness. We provide extensive experimental validation across multiple datasets and model architectures to demonstrate the effectiveness of our approach.,Principal Eigenvalue Regularization for Improved Worst Class Certified Robustness of Smoothed Classifiers,"['smoothed', 'class', 'worst', 'worst class', 'classifiers', 'robustness', 'smoothed classifiers', 'accuracy', 'certified', 'certified robustness']",Recent studies have identified a critical challenge in deep neural networks DNNs known as robust fairness where models exhibit significant disparities in robust accuracy across different classes.
2503.17039v1,Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?,"Studies on evaluation metrics and LLM-as-a-Judge models for automatic text
summarization have largely been focused on English, limiting our understanding
of their effectiveness in other languages. Through our new dataset BASSE
(BAsque and Spanish Summarization Evaluation), we address this situation by
collecting human judgments on 2,040 abstractive summaries in Basque and
Spanish, generated either manually or by five LLMs with four different prompts.
For each summary, annotators evaluated five criteria on a 5-point Likert scale:
coherence, consistency, fluency, relevance, and 5W1H. We use these data to
reevaluate traditional automatic metrics used for evaluating summaries, as well
as several LLM-as-a-Judge models that show strong performance on this task in
English. Our results show that currently proprietary judge LLMs have the
highest correlation with human judgments, followed by criteria-specific
automatic metrics, while open-sourced judge LLMs perform poorly. We release
BASSE and our code publicly, along with the first large-scale Basque
summarization dataset containing 22,525 news articles with their subheads.","['cs.CL', 'cs.AI']","['Jeremy Barnes', 'Naiara Perez', 'Alba Bonet-Jover', 'Begoña Altuna']",2025-03-21,2025-03-21,Studies on evaluation metrics and LLM as a Judge models for automatic text summarization have largely been focused on English limiting our understanding of their effectiveness in other languages. Through our new dataset BASSE BAsque and Spanish Summarization Evaluation we address this situation by collecting human judgments on 2 040 abstractive summaries in Basque and Spanish generated either manually or by five LLMs with four different prompts. For each summary annotators evaluated five criteria on a 5 point Likert scale coherence consistency fluency relevance and 5W1H. We use these data to reevaluate traditional automatic metrics used for evaluating summaries as well as several LLM as a Judge models that show strong performance on this task in English. Our results show that currently proprietary judge LLMs have the highest correlation with human judgments followed by criteria specific automatic metrics while open sourced judge LLMs perform poorly. We release BASSE and our code publicly along with the first large scale Basque summarization dataset containing 22 525 news articles with their subheads.,Summarization Metrics for Spanish and Basque Do Automatic Scores and LLM Judges Correlate with Humans,"['judge', 'automatic', 'basque', 'llms', 'metrics', 'summarization', 'automatic metrics', 'basque spanish', 'basse', 'criteria']",Studies on evaluation metrics and LLM as a Judge models for automatic text summarization have largely been focused on English limiting our understanding of their effectiveness in other languages.
2503.16248v1,AI Agents in Cryptoland: Practical Attacks and No Silver Bullet,"The integration of AI agents with Web3 ecosystems harnesses their
complementary potential for autonomy and openness, yet also introduces
underexplored security risks, as these agents dynamically interact with
financial protocols and immutable smart contracts. This paper investigates the
vulnerabilities of AI agents within blockchain-based financial ecosystems when
exposed to adversarial threats in real-world scenarios. We introduce the
concept of context manipulation -- a comprehensive attack vector that exploits
unprotected context surfaces, including input channels, memory modules, and
external data feeds. Through empirical analysis of ElizaOS, a decentralized AI
agent framework for automated Web3 operations, we demonstrate how adversaries
can manipulate context by injecting malicious instructions into prompts or
historical interaction records, leading to unintended asset transfers and
protocol violations which could be financially devastating. Our findings
indicate that prompt-based defenses are insufficient, as malicious inputs can
corrupt an agent's stored context, creating cascading vulnerabilities across
interactions and platforms. This research highlights the urgent need to develop
AI agents that are both secure and fiduciarily responsible.","['cs.CR', 'cs.AI', 'I.2.7']","['Atharv Singh Patlan', 'Peiyao Sheng', 'S. Ashwin Hebbar', 'Prateek Mittal', 'Pramod Viswanath']",2025-03-20,2025-03-20,The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness yet also introduces underexplored security risks as these agents dynamically interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain based financial ecosystems when exposed to adversarial threats in real world scenarios. We introduce the concept of context manipulation a comprehensive attack vector that exploits unprotected context surfaces including input channels memory modules and external data feeds. Through empirical analysis of ElizaOS a decentralized AI agent framework for automated Web3 operations we demonstrate how adversaries can manipulate context by injecting malicious instructions into prompts or historical interaction records leading to unintended asset transfers and protocol violations which could be financially devastating. Our findings indicate that prompt based defenses are insufficient as malicious inputs can corrupt an agent s stored context creating cascading vulnerabilities across interactions and platforms. This research highlights the urgent need to develop AI agents that are both secure and fiduciarily responsible.,AI Agents in Cryptoland Practical Attacks and No Silver Bullet,"['agents', 'ai', 'context', 'ai agents', 'agent', 'based', 'ecosystems', 'financial', 'malicious', 'vulnerabilities']",The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness yet also introduces underexplored security risks as these agents dynamically interact with financial protocols and immutable smart contracts.
2503.16318v1,Dynamic Point Maps: A Versatile Representation for Dynamic 3D Reconstruction,"DUSt3R has recently shown that one can reduce many tasks in multi-view
geometry, including estimating camera intrinsics and extrinsics, reconstructing
the scene in 3D, and establishing image correspondences, to the prediction of a
pair of viewpoint-invariant point maps, i.e., pixel-aligned point clouds
defined in a common reference frame. This formulation is elegant and powerful,
but unable to tackle dynamic scenes. To address this challenge, we introduce
the concept of Dynamic Point Maps (DPM), extending standard point maps to
support 4D tasks such as motion segmentation, scene flow estimation, 3D object
tracking, and 2D correspondence. Our key intuition is that, when time is
introduced, there are several possible spatial and time references that can be
used to define the point maps. We identify a minimal subset of such
combinations that can be regressed by a network to solve the sub tasks
mentioned above. We train a DPM predictor on a mixture of synthetic and real
data and evaluate it across diverse benchmarks for video depth prediction,
dynamic point cloud reconstruction, 3D scene flow and object pose tracking,
achieving state-of-the-art performance. Code, models and additional results are
available at https://www.robots.ox.ac.uk/~vgg/research/dynamic-point-maps/.",['cs.CV'],"['Edgar Sucar', 'Zihang Lai', 'Eldar Insafutdinov', 'Andrea Vedaldi']",2025-03-20,2025-03-20,DUSt3R has recently shown that one can reduce many tasks in multi view geometry including estimating camera intrinsics and extrinsics reconstructing the scene in 3D and establishing image correspondences to the prediction of a pair of viewpoint invariant point maps i.e. pixel aligned point clouds defined in a common reference frame. This formulation is elegant and powerful but unable to tackle dynamic scenes. To address this challenge we introduce the concept of Dynamic Point Maps DPM extending standard point maps to support 4D tasks such as motion segmentation scene flow estimation 3D object tracking and 2D correspondence. Our key intuition is that when time is introduced there are several possible spatial and time references that can be used to define the point maps. We identify a minimal subset of such combinations that can be regressed by a network to solve the sub tasks mentioned above. We train a DPM predictor on a mixture of synthetic and real data and evaluate it across diverse benchmarks for video depth prediction dynamic point cloud reconstruction 3D scene flow and object pose tracking achieving state of the art performance. Code models and additional results are available at https www.robots.ox.ac.uk vgg research dynamic point maps .,Dynamic Point Maps A Versatile Representation for Dynamic 3D Reconstruction,"['point', 'maps', 'point maps', 'dynamic', '3d', 'dynamic point', 'scene', 'tasks', 'dpm', 'flow']",DUSt3R has recently shown that one can reduce many tasks in multi view geometry including estimating camera intrinsics and extrinsics reconstructing the scene in 3D and establishing image correspondences to the prediction of a pair of viewpoint invariant point maps i.e.
2503.15150v1,Preference Construction: A Bayesian Interactive Preference Elicitation Framework Based on Monte Carlo Tree Search,"We present a novel preference learning framework to capture participant
preferences efficiently within limited interaction rounds. It involves three
main contributions. First, we develop a variational Bayesian approach to infer
the participant's preference model by estimating posterior distributions and
managing uncertainty from limited information. Second, we propose an adaptive
questioning policy that maximizes cumulative uncertainty reduction, formulating
questioning as a finite Markov decision process and using Monte Carlo Tree
Search to prioritize promising question trajectories. By considering long-term
effects and leveraging the efficiency of the Bayesian approach, the policy
avoids shortsightedness. Third, we apply the framework to Multiple Criteria
Decision Aiding, with pairwise comparison as the preference information and an
additive value function as the preference model. We integrate the
reparameterization trick to address high-variance issues, enhancing robustness
and efficiency. Computational studies on real-world and synthetic datasets
demonstrate the framework's practical usability, outperforming baselines in
capturing preferences and achieving superior uncertainty reduction within
limited interactions.",['cs.LG'],"['Yan Wang', 'Jiapeng Liu', 'Milosz Kadziński', 'Xiuwu Liao']",2025-03-19,2025-03-19,We present a novel preference learning framework to capture participant preferences efficiently within limited interaction rounds. It involves three main contributions. First we develop a variational Bayesian approach to infer the participant s preference model by estimating posterior distributions and managing uncertainty from limited information. Second we propose an adaptive questioning policy that maximizes cumulative uncertainty reduction formulating questioning as a finite Markov decision process and using Monte Carlo Tree Search to prioritize promising question trajectories. By considering long term effects and leveraging the efficiency of the Bayesian approach the policy avoids shortsightedness. Third we apply the framework to Multiple Criteria Decision Aiding with pairwise comparison as the preference information and an additive value function as the preference model. We integrate the reparameterization trick to address high variance issues enhancing robustness and efficiency. Computational studies on real world and synthetic datasets demonstrate the framework s practical usability outperforming baselines in capturing preferences and achieving superior uncertainty reduction within limited interactions.,Preference Construction A Bayesian Interactive Preference Elicitation Framework Based on Monte Carlo Tree Search,"['preference', 'framework', 'limited', 'uncertainty', 'approach', 'bayesian', 'bayesian approach', 'decision', 'efficiency', 'information']",We present a novel preference learning framework to capture participant preferences efficiently within limited interaction rounds.
2503.14813v1,Scaled Supervision is an Implicit Lipschitz Regularizer,"In modern social media, recommender systems (RecSys) rely on the
click-through rate (CTR) as the standard metric to evaluate user engagement.
CTR prediction is traditionally framed as a binary classification task to
predict whether a user will interact with a given item. However, this approach
overlooks the complexity of real-world social modeling, where the user, item,
and their interactive features change dynamically in fast-paced online
environments. This dynamic nature often leads to model instability, reflected
in overfitting short-term fluctuations rather than higher-level interactive
patterns. While overfitting calls for more scaled and refined supervisions,
current solutions often rely on binary labels that overly simplify fine-grained
user preferences through the thresholding process, which significantly reduces
the richness of the supervision. Therefore, we aim to alleviate the overfitting
problem by increasing the supervision bandwidth in CTR training. Specifically,
(i) theoretically, we formulate the impact of fine-grained preferences on model
stability as a Lipschitz constrain; (ii) empirically, we discover that scaling
the supervision bandwidth can act as an implicit Lipschitz regularizer, stably
optimizing existing CTR models to achieve better generalizability. Extensive
experiments show that this scaled supervision significantly and consistently
improves the optimization process and the performance of existing CTR models,
even without the need for additional hyperparameter tuning.","['cs.LG', 'cs.IR']","['Zhongyu Ouyang', 'Chunhui Zhang', 'Yaning Jia', 'Soroush Vosoughi']",2025-03-19,2025-03-19,In modern social media recommender systems RecSys rely on the click through rate CTR as the standard metric to evaluate user engagement. CTR prediction is traditionally framed as a binary classification task to predict whether a user will interact with a given item. However this approach overlooks the complexity of real world social modeling where the user item and their interactive features change dynamically in fast paced online environments. This dynamic nature often leads to model instability reflected in overfitting short term fluctuations rather than higher level interactive patterns. While overfitting calls for more scaled and refined supervisions current solutions often rely on binary labels that overly simplify fine grained user preferences through the thresholding process which significantly reduces the richness of the supervision. Therefore we aim to alleviate the overfitting problem by increasing the supervision bandwidth in CTR training. Specifically i theoretically we formulate the impact of fine grained preferences on model stability as a Lipschitz constrain ii empirically we discover that scaling the supervision bandwidth can act as an implicit Lipschitz regularizer stably optimizing existing CTR models to achieve better generalizability. Extensive experiments show that this scaled supervision significantly and consistently improves the optimization process and the performance of existing CTR models even without the need for additional hyperparameter tuning.,Scaled Supervision is an Implicit Lipschitz Regularizer,"['ctr', 'supervision', 'user', 'overfitting', 'bandwidth', 'binary', 'ctr models', 'existing', 'existing ctr', 'fine']",In modern social media recommender systems RecSys rely on the click through rate CTR as the standard metric to evaluate user engagement.
2503.16392v1,Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment,"With AI-based software becoming widely available, the risk of exploiting its
capabilities, such as high automation and complex pattern recognition, could
significantly increase. An AI used offensively to attack non-AI assets is
referred to as offensive AI.
  Current research explores how offensive AI can be utilized and how its usage
can be classified. Additionally, methods for threat modeling are being
developed for AI-based assets within organizations. However, there are gaps
that need to be addressed. Firstly, there is a need to quantify the factors
contributing to the AI threat. Secondly, there is a requirement to create
threat models that analyze the risk of being attacked by AI for vulnerability
assessment across all assets of an organization. This is particularly crucial
and challenging in cloud environments, where sophisticated infrastructure and
access control landscapes are prevalent. The ability to quantify and further
analyze the threat posed by offensive AI enables analysts to rank
vulnerabilities and prioritize the implementation of proactive countermeasures.
  To address these gaps, this paper introduces the Graph of Effort, an
intuitive, flexible, and effective threat modeling method for analyzing the
effort required to use offensive AI for vulnerability exploitation by an
adversary. While the threat model is functional and provides valuable support,
its design choices need further empirical validation in future work.","['cs.CR', 'cs.AI', 'cs.DC']","['Anket Mehra', 'Andreas Aßmuth', 'Malte Prieß']",2025-03-20,2025-03-20,With AI based software becoming widely available the risk of exploiting its capabilities such as high automation and complex pattern recognition could significantly increase. An AI used offensively to attack non AI assets is referred to as offensive AI. Current research explores how offensive AI can be utilized and how its usage can be classified. Additionally methods for threat modeling are being developed for AI based assets within organizations. However there are gaps that need to be addressed. Firstly there is a need to quantify the factors contributing to the AI threat. Secondly there is a requirement to create threat models that analyze the risk of being attacked by AI for vulnerability assessment across all assets of an organization. This is particularly crucial and challenging in cloud environments where sophisticated infrastructure and access control landscapes are prevalent. The ability to quantify and further analyze the threat posed by offensive AI enables analysts to rank vulnerabilities and prioritize the implementation of proactive countermeasures. To address these gaps this paper introduces the Graph of Effort an intuitive flexible and effective threat modeling method for analyzing the effort required to use offensive AI for vulnerability exploitation by an adversary. While the threat model is functional and provides valuable support its design choices need further empirical validation in future work.,Graph of Effort Quantifying Risk of AI Usage for Vulnerability Assessment,"['ai', 'threat', 'offensive', 'offensive ai', 'assets', 'need', 'ai based', 'ai vulnerability', 'analyze', 'based']",With AI based software becoming widely available the risk of exploiting its capabilities such as high automation and complex pattern recognition could significantly increase.
2503.16874v1,MARS: A Multi-Agent Framework Incorporating Socratic Guidance for Automated Prompt Optimization,"The basic question-answering format of large language models involves
inputting a prompt and receiving a response, and the quality of the prompt
directly impacts the effectiveness of the response. Automated Prompt
Optimization (APO) aims to break free from the cognitive biases of manually
designed prompts and explores a broader design space for prompts. However,
existing APO methods suffer from limited flexibility of fixed templates and
inefficient search in prompt spaces as key issues. To this end, we propose a
Multi-Agent framework Incorporating Socratic guidance (MARS), which utilizes
multi-agent fusion technology for automatic planning, with gradual continuous
optimization and evaluation. Specifically, MARS comprises seven agents, each
with distinct functionalities, which autonomously use the Planner to devise an
optimization path that ensures flexibility. Additionally, it employs a
Teacher-Critic-Student Socratic dialogue pattern to iteratively optimize the
prompts while conducting effective search. We conduct extensive experiments on
various datasets to validate the effectiveness of our method, and perform
additional analytical experiments to assess the model's advancement as well as
the interpretability.","['cs.CL', 'cs.AI']","['Jian Zhang', 'Zhangqi Wang', 'Haiping Zhu', 'Jun Liu', 'Qika Lin', 'Erik Cambria']",2025-03-21,2025-03-21,The basic question answering format of large language models involves inputting a prompt and receiving a response and the quality of the prompt directly impacts the effectiveness of the response. Automated Prompt Optimization APO aims to break free from the cognitive biases of manually designed prompts and explores a broader design space for prompts. However existing APO methods suffer from limited flexibility of fixed templates and inefficient search in prompt spaces as key issues. To this end we propose a Multi Agent framework Incorporating Socratic guidance MARS which utilizes multi agent fusion technology for automatic planning with gradual continuous optimization and evaluation. Specifically MARS comprises seven agents each with distinct functionalities which autonomously use the Planner to devise an optimization path that ensures flexibility. Additionally it employs a Teacher Critic Student Socratic dialogue pattern to iteratively optimize the prompts while conducting effective search. We conduct extensive experiments on various datasets to validate the effectiveness of our method and perform additional analytical experiments to assess the model s advancement as well as the interpretability.,MARS A Multi Agent Framework Incorporating Socratic Guidance for Automated Prompt Optimization,"['prompt', 'optimization', 'prompts', 'agent', 'apo', 'effectiveness', 'experiments', 'flexibility', 'mars', 'multi']",The basic question answering format of large language models involves inputting a prompt and receiving a response and the quality of the prompt directly impacts the effectiveness of the response.
2503.15089v1,Continual Contrastive Learning on Tabular Data with Out of Distribution,"Out-of-distribution (OOD) prediction remains a significant challenge in
machine learning, particularly for tabular data where traditional methods often
fail to generalize beyond their training distribution. This paper introduces
Tabular Continual Contrastive Learning (TCCL), a novel framework designed to
address OOD challenges in tabular data processing. TCCL integrates contrastive
learning principles with continual learning mechanisms, featuring a
three-component architecture: an Encoder for data transformation, a Decoder for
representation learning, and a Learner Head. We evaluate TCCL against 14
baseline models, including state-of-the-art deep learning approaches and
gradient-boosted decision trees (GBDT), across eight diverse tabular datasets.
Our experimental results demonstrate that TCCL consistently outperforms
existing methods in both classification and regression tasks on OOD data, with
particular strength in handling distribution shifts. These findings suggest
that TCCL represents a significant advancement in handling OOD scenarios for
tabular data.",['cs.LG'],"['Achmad Ginanjar', 'Xue Li', 'Priyanka Singh', 'Wen Hua']",2025-03-19,2025-03-19,Out of distribution OOD prediction remains a significant challenge in machine learning particularly for tabular data where traditional methods often fail to generalize beyond their training distribution. This paper introduces Tabular Continual Contrastive Learning TCCL a novel framework designed to address OOD challenges in tabular data processing. TCCL integrates contrastive learning principles with continual learning mechanisms featuring a three component architecture an Encoder for data transformation a Decoder for representation learning and a Learner Head. We evaluate TCCL against 14 baseline models including state of the art deep learning approaches and gradient boosted decision trees GBDT across eight diverse tabular datasets. Our experimental results demonstrate that TCCL consistently outperforms existing methods in both classification and regression tasks on OOD data with particular strength in handling distribution shifts. These findings suggest that TCCL represents a significant advancement in handling OOD scenarios for tabular data.,Continual Contrastive Learning on Tabular Data with Out of Distribution,"['learning', 'data', 'tabular', 'tccl', 'ood', 'distribution', 'tabular data', 'continual', 'contrastive', 'contrastive learning']",Out of distribution OOD prediction remains a significant challenge in machine learning particularly for tabular data where traditional methods often fail to generalize beyond their training distribution.
2503.15421v1,Probing the topology of the space of tokens with structured prompts,"This article presents a general and flexible method for prompting a large
language model (LLM) to reveal its (hidden) token input embedding up to
homeomorphism. Moreover, this article provides strong theoretical justification
-- a mathematical proof for generic LLMs -- for why this method should be
expected to work. With this method in hand, we demonstrate its effectiveness by
recovering the token subspace of Llemma-7B. The results of this paper apply not
only to LLMs but also to general nonlinear autoregressive processes.","['math.DG', 'cs.AI', '53Z50, 58Z05', 'I.2.7']","['Michael Robinson', 'Sourya Dey', 'Taisa Kushner']",2025-03-19,2025-03-19,This article presents a general and flexible method for prompting a large language model LLM to reveal its hidden token input embedding up to homeomorphism. Moreover this article provides strong theoretical justification a mathematical proof for generic LLMs for why this method should be expected to work. With this method in hand we demonstrate its effectiveness by recovering the token subspace of Llemma 7B. The results of this paper apply not only to LLMs but also to general nonlinear autoregressive processes.,Probing the topology of the space of tokens with structured prompts,"['method', 'article', 'general', 'llms', 'token', '7b', '7b results', 'apply', 'apply llms', 'article presents']",This article presents a general and flexible method for prompting a large language model LLM to reveal its hidden token input embedding up to homeomorphism.
2503.14824v1,Prototype Perturbation for Relaxing Alignment Constraints in Backward-Compatible Learning,"The traditional paradigm to update retrieval models requires re-computing the
embeddings of the gallery data, a time-consuming and computationally intensive
process known as backfilling. To circumvent backfilling, Backward-Compatible
Learning (BCL) has been widely explored, which aims to train a new model
compatible with the old one. Many previous works focus on effectively aligning
the embeddings of the new model with those of the old one to enhance the
backward-compatibility. Nevertheless, such strong alignment constraints would
compromise the discriminative ability of the new model, particularly when
different classes are closely clustered and hard to distinguish in the old
feature space. To address this issue, we propose to relax the constraints by
introducing perturbations to the old feature prototypes. This allows us to
align the new feature space with a pseudo-old feature space defined by these
perturbed prototypes, thereby preserving the discriminative ability of the new
model in backward-compatible learning. We have developed two approaches for
calculating the perturbations: Neighbor-Driven Prototype Perturbation (NDPP)
and Optimization-Driven Prototype Perturbation (ODPP). Particularly, they take
into account the feature distributions of not only the old but also the new
models to obtain proper perturbations along with new model updating. Extensive
experiments on the landmark and commodity datasets demonstrate that our
approaches perform favorably against state-of-the-art BCL algorithms.",['cs.CV'],"['Zikun Zhou', 'Yushuai Sun', 'Wenjie Pei', 'Xin Li', 'Yaowei Wang']",2025-03-19,2025-03-19,The traditional paradigm to update retrieval models requires re computing the embeddings of the gallery data a time consuming and computationally intensive process known as backfilling. To circumvent backfilling Backward Compatible Learning BCL has been widely explored which aims to train a new model compatible with the old one. Many previous works focus on effectively aligning the embeddings of the new model with those of the old one to enhance the backward compatibility. Nevertheless such strong alignment constraints would compromise the discriminative ability of the new model particularly when different classes are closely clustered and hard to distinguish in the old feature space. To address this issue we propose to relax the constraints by introducing perturbations to the old feature prototypes. This allows us to align the new feature space with a pseudo old feature space defined by these perturbed prototypes thereby preserving the discriminative ability of the new model in backward compatible learning. We have developed two approaches for calculating the perturbations Neighbor Driven Prototype Perturbation NDPP and Optimization Driven Prototype Perturbation ODPP . Particularly they take into account the feature distributions of not only the old but also the new models to obtain proper perturbations along with new model updating. Extensive experiments on the landmark and commodity datasets demonstrate that our approaches perform favorably against state of the art BCL algorithms.,Prototype Perturbation for Relaxing Alignment Constraints in Backward Compatible Learning,"['new', 'old', 'feature', 'model', 'new model', 'backward', 'compatible', 'feature space', 'old feature', 'perturbations']",The traditional paradigm to update retrieval models requires re computing the embeddings of the gallery data a time consuming and computationally intensive process known as backfilling.
2503.14906v1,FetalFlex: Anatomy-Guided Diffusion Model for Flexible Control on Fetal Ultrasound Image Synthesis,"Fetal ultrasound (US) examinations require the acquisition of multiple
planes, each providing unique diagnostic information to evaluate fetal
development and screening for congenital anomalies. However, obtaining a
comprehensive, multi-plane annotated fetal US dataset remains challenging,
particularly for rare or complex anomalies owing to their low incidence and
numerous subtypes. This poses difficulties in training novice radiologists and
developing robust AI models, especially for detecting abnormal fetuses. In this
study, we introduce a Flexible Fetal US image generation framework (FetalFlex)
to address these challenges, which leverages anatomical structures and
multimodal information to enable controllable synthesis of fetal US images
across diverse planes. Specifically, FetalFlex incorporates a pre-alignment
module to enhance controllability and introduces a repaint strategy to ensure
consistent texture and appearance. Moreover, a two-stage adaptive sampling
strategy is developed to progressively refine image quality from coarse to fine
levels. We believe that FetalFlex is the first method capable of generating
both in-distribution normal and out-of-distribution abnormal fetal US images,
without requiring any abnormal data. Experiments on multi-center datasets
demonstrate that FetalFlex achieved state-of-the-art performance across
multiple image quality metrics. A reader study further confirms the close
alignment of the generated results with expert visual assessments. Furthermore,
synthetic images by FetalFlex significantly improve the performance of six
typical deep models in downstream classification and anomaly detection tasks.
Lastly, FetalFlex's anatomy-level controllable generation offers a unique
advantage for anomaly simulation and creating paired or counterfactual data at
the pixel level. The demo is available at:
https://dyf1023.github.io/FetalFlex/.","['eess.IV', 'cs.CV']","['Yaofei Duan', 'Tao Tan', 'Zhiyuan Zhu', 'Yuhao Huang', 'Yuanji Zhang', 'Rui Gao', 'Patrick Cheong-Iao Pang', 'Xinru Gao', 'Guowei Tao', 'Xiang Cong', 'Zhou Li', 'Lianying Liang', 'Guangzhi He', 'Linliang Yin', 'Xuedong Deng', 'Xin Yang', 'Dong Ni']",2025-03-19,2025-03-19,Fetal ultrasound US examinations require the acquisition of multiple planes each providing unique diagnostic information to evaluate fetal development and screening for congenital anomalies. However obtaining a comprehensive multi plane annotated fetal US dataset remains challenging particularly for rare or complex anomalies owing to their low incidence and numerous subtypes. This poses difficulties in training novice radiologists and developing robust AI models especially for detecting abnormal fetuses. In this study we introduce a Flexible Fetal US image generation framework FetalFlex to address these challenges which leverages anatomical structures and multimodal information to enable controllable synthesis of fetal US images across diverse planes. Specifically FetalFlex incorporates a pre alignment module to enhance controllability and introduces a repaint strategy to ensure consistent texture and appearance. Moreover a two stage adaptive sampling strategy is developed to progressively refine image quality from coarse to fine levels. We believe that FetalFlex is the first method capable of generating both in distribution normal and out of distribution abnormal fetal US images without requiring any abnormal data. Experiments on multi center datasets demonstrate that FetalFlex achieved state of the art performance across multiple image quality metrics. A reader study further confirms the close alignment of the generated results with expert visual assessments. Furthermore synthetic images by FetalFlex significantly improve the performance of six typical deep models in downstream classification and anomaly detection tasks. Lastly FetalFlex s anatomy level controllable generation offers a unique advantage for anomaly simulation and creating paired or counterfactual data at the pixel level. The demo is available at https dyf1023.github.io FetalFlex .,FetalFlex Anatomy Guided Diffusion Model for Flexible Control on Fetal Ultrasound Image Synthesis,"['fetalflex', 'fetal', 'abnormal', 'image', 'images', 'alignment', 'anomalies', 'anomaly', 'controllable', 'data']",Fetal ultrasound US examinations require the acquisition of multiple planes each providing unique diagnostic information to evaluate fetal development and screening for congenital anomalies.
2503.15222v1,"Model Hubs and Beyond: Analyzing Model Popularity, Performance, and Documentation","With the massive surge in ML models on platforms like Hugging Face, users
often lose track and struggle to choose the best model for their downstream
tasks, frequently relying on model popularity indicated by download counts,
likes, or recency. We investigate whether this popularity aligns with actual
model performance and how the comprehensiveness of model documentation
correlates with both popularity and performance. In our study, we evaluated a
comprehensive set of 500 Sentiment Analysis models on Hugging Face. This
evaluation involved massive annotation efforts, with human annotators
completing nearly 80,000 annotations, alongside extensive model training and
evaluation. Our findings reveal that model popularity does not necessarily
correlate with performance. Additionally, we identify critical inconsistencies
in model card reporting: approximately 80\% of the models analyzed lack
detailed information about the model, training, and evaluation processes.
Furthermore, about 88\% of model authors overstate their models' performance in
the model cards. Based on our findings, we provide a checklist of guidelines
for users to choose good models for downstream tasks.",['cs.CL'],"['Pritam Kadasi', 'Sriman Reddy', 'Srivathsa Vamsi Chaturvedula', 'Rudranshu Sen', 'Agnish Saha', 'Soumavo Sikdar', 'Sayani Sarkar', 'Suhani Mittal', 'Rohit Jindal', 'Mayank Singh']",2025-03-19,2025-03-19,With the massive surge in ML models on platforms like Hugging Face users often lose track and struggle to choose the best model for their downstream tasks frequently relying on model popularity indicated by download counts likes or recency. We investigate whether this popularity aligns with actual model performance and how the comprehensiveness of model documentation correlates with both popularity and performance. In our study we evaluated a comprehensive set of 500 Sentiment Analysis models on Hugging Face. This evaluation involved massive annotation efforts with human annotators completing nearly 80 000 annotations alongside extensive model training and evaluation. Our findings reveal that model popularity does not necessarily correlate with performance. Additionally we identify critical inconsistencies in model card reporting approximately 80 of the models analyzed lack detailed information about the model training and evaluation processes. Furthermore about 88 of model authors overstate their models performance in the model cards. Based on our findings we provide a checklist of guidelines for users to choose good models for downstream tasks.,Model Hubs and Beyond Analyzing Model Popularity Performance and Documentation,"['model', 'models', 'performance', 'popularity', 'evaluation', '80', 'choose', 'downstream', 'downstream tasks', 'face']",With the massive surge in ML models on platforms like Hugging Face users often lose track and struggle to choose the best model for their downstream tasks frequently relying on model popularity indicated by download counts likes or recency.
2503.15810v1,Big data comparison of quantum invariants,"We apply big data techniques, including exploratory and topological data
analysis, to investigate quantum invariants. More precisely, our study explores
the Jones polynomial's structural properties and contrasts its behavior under
four principal methods of enhancement: coloring, rank increase,
categorification, and leaving the realm of Lie algebras.","['math.GT', 'cs.LG', 'math.QA', 'Primary: 57K16, 62R07, secondary: 57K18, 68P05']","['Daniel Tubbenhauer', 'Victor Zhang']",2025-03-20,2025-03-20,We apply big data techniques including exploratory and topological data analysis to investigate quantum invariants. More precisely our study explores the Jones polynomial s structural properties and contrasts its behavior under four principal methods of enhancement coloring rank increase categorification and leaving the realm of Lie algebras.,Big data comparison of quantum invariants,"['data', 'algebras', 'analysis', 'analysis investigate', 'apply', 'apply big', 'behavior', 'behavior principal', 'big', 'big data']",We apply big data techniques including exploratory and topological data analysis to investigate quantum invariants.
2503.15130v1,A Foundational Theory for Decentralized Sensory Learning,"In both neuroscience and artificial intelligence, popular functional
frameworks and neural network formulations operate by making use of extrinsic
error measurements and global learning algorithms. Through a set of conjectures
based on evolutionary insights on the origin of cellular adaptive mechanisms,
we reinterpret the core meaning of sensory signals to allow the brain to be
interpreted as a negative feedback control system, and show how this could lead
to local learning algorithms without the need for global error correction
metrics. Thereby, a sufficiently good minima in sensory activity can be the
complete reward signal of the network, as well as being both necessary and
sufficient for biological learning to arise. We show that this method of
learning was likely already present in the earliest unicellular life forms on
earth. We show evidence that the same principle holds and scales to
multicellular organisms where it in addition can lead to division of labour
between cells. Available evidence shows that the evolution of the nervous
system likely was an adaptation to more effectively communicate intercellular
signals to support such division of labour. We therefore propose that the same
learning principle that evolved already in the earliest unicellular life forms,
i.e. negative feedback control of externally and internally generated sensor
signals, has simply been scaled up to become a fundament of the learning we see
in biological brains today. We illustrate diverse biological settings, from the
earliest unicellular organisms to humans, where this operational principle
appears to be a plausible interpretation of the meaning of sensor signals in
biology, and how this relates to current neuroscientific theories and findings.","['q-bio.NC', 'cs.AI']","['Linus Mårtensson', 'Jonas M. D. Enander', 'Udaya B. Rongala', 'Henrik Jörntell']",2025-03-19,2025-03-19,In both neuroscience and artificial intelligence popular functional frameworks and neural network formulations operate by making use of extrinsic error measurements and global learning algorithms. Through a set of conjectures based on evolutionary insights on the origin of cellular adaptive mechanisms we reinterpret the core meaning of sensory signals to allow the brain to be interpreted as a negative feedback control system and show how this could lead to local learning algorithms without the need for global error correction metrics. Thereby a sufficiently good minima in sensory activity can be the complete reward signal of the network as well as being both necessary and sufficient for biological learning to arise. We show that this method of learning was likely already present in the earliest unicellular life forms on earth. We show evidence that the same principle holds and scales to multicellular organisms where it in addition can lead to division of labour between cells. Available evidence shows that the evolution of the nervous system likely was an adaptation to more effectively communicate intercellular signals to support such division of labour. We therefore propose that the same learning principle that evolved already in the earliest unicellular life forms i.e. negative feedback control of externally and internally generated sensor signals has simply been scaled up to become a fundament of the learning we see in biological brains today. We illustrate diverse biological settings from the earliest unicellular organisms to humans where this operational principle appears to be a plausible interpretation of the meaning of sensor signals in biology and how this relates to current neuroscientific theories and findings.,A Foundational Theory for Decentralized Sensory Learning,"['learning', 'signals', 'biological', 'earliest', 'earliest unicellular', 'principle', 'unicellular', 'algorithms', 'control', 'division']",In both neuroscience and artificial intelligence popular functional frameworks and neural network formulations operate by making use of extrinsic error measurements and global learning algorithms.
2503.15931v1,DnLUT: Ultra-Efficient Color Image Denoising via Channel-Aware Lookup Tables,"While deep neural networks have revolutionized image denoising capabilities,
their deployment on edge devices remains challenging due to substantial
computational and memory requirements. To this end, we present DnLUT, an
ultra-efficient lookup table-based framework that achieves high-quality color
image denoising with minimal resource consumption. Our key innovation lies in
two complementary components: a Pairwise Channel Mixer (PCM) that effectively
captures inter-channel correlations and spatial dependencies in parallel, and a
novel L-shaped convolution design that maximizes receptive field coverage while
minimizing storage overhead. By converting these components into optimized
lookup tables post-training, DnLUT achieves remarkable efficiency - requiring
only 500KB storage and 0.1% energy consumption compared to its CNN contestant
DnCNN, while delivering 20X faster inference. Extensive experiments demonstrate
that DnLUT outperforms all existing LUT-based methods by over 1dB in PSNR,
establishing a new state-of-the-art in resource-efficient color image
denoising. The project is available at https://github.com/Stephen0808/DnLUT.",['cs.CV'],"['Sidi Yang', 'Binxiao Huang', 'Yulun Zhang', 'Dahai Yu', 'Yujiu Yang', 'Ngai Wong']",2025-03-20,2025-03-20,While deep neural networks have revolutionized image denoising capabilities their deployment on edge devices remains challenging due to substantial computational and memory requirements. To this end we present DnLUT an ultra efficient lookup table based framework that achieves high quality color image denoising with minimal resource consumption. Our key innovation lies in two complementary components a Pairwise Channel Mixer PCM that effectively captures inter channel correlations and spatial dependencies in parallel and a novel L shaped convolution design that maximizes receptive field coverage while minimizing storage overhead. By converting these components into optimized lookup tables post training DnLUT achieves remarkable efficiency requiring only 500KB storage and 0.1 energy consumption compared to its CNN contestant DnCNN while delivering 20X faster inference. Extensive experiments demonstrate that DnLUT outperforms all existing LUT based methods by over 1dB in PSNR establishing a new state of the art in resource efficient color image denoising. The project is available at https github.com Stephen0808 DnLUT.,DnLUT Ultra Efficient Color Image Denoising via Channel Aware Lookup Tables,"['dnlut', 'denoising', 'image', 'image denoising', 'achieves', 'based', 'channel', 'color', 'color image', 'components']",While deep neural networks have revolutionized image denoising capabilities their deployment on edge devices remains challenging due to substantial computational and memory requirements.
2503.15973v1,STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding,"Pre-trained on tremendous image-text pairs, vision-language models like CLIP
have demonstrated promising zero-shot generalization across numerous
image-based tasks. However, extending these capabilities to video tasks remains
challenging due to limited labeled video data and high training costs. Recent
video prompting methods attempt to adapt CLIP for video tasks by introducing
learnable prompts, but they typically rely on a single static prompt for all
video sequences, overlooking the diverse temporal dynamics and spatial
variations that exist across frames. This limitation significantly hinders the
model's ability to capture essential temporal information for effective video
understanding. To address this, we propose an integrated Spatial-TempOral
dynamic Prompting (STOP) model which consists of two complementary modules, the
intra-frame spatial prompting and inter-frame temporal prompting. Our
intra-frame spatial prompts are designed to adaptively highlight discriminative
regions within each frame by leveraging intra-frame attention and temporal
variation, allowing the model to focus on areas with substantial temporal
dynamics and capture fine-grained spatial details. Additionally, to highlight
the varying importance of frames for video understanding, we further introduce
inter-frame temporal prompts, dynamically inserting prompts between frames with
high temporal variance as measured by frame similarity. This enables the model
to prioritize key frames and enhances its capacity to understand temporal
dependencies across sequences. Extensive experiments on various video
benchmarks demonstrate that STOP consistently achieves superior performance
against state-of-the-art methods. The code is available at
https://github.com/zhoujiahuan1991/CVPR2025-STOP.",['cs.CV'],"['Zichen Liu', 'Kunlun Xu', 'Bing Su', 'Xu Zou', 'Yuxin Peng', 'Jiahuan Zhou']",2025-03-20,2025-03-20,Pre trained on tremendous image text pairs vision language models like CLIP have demonstrated promising zero shot generalization across numerous image based tasks. However extending these capabilities to video tasks remains challenging due to limited labeled video data and high training costs. Recent video prompting methods attempt to adapt CLIP for video tasks by introducing learnable prompts but they typically rely on a single static prompt for all video sequences overlooking the diverse temporal dynamics and spatial variations that exist across frames. This limitation significantly hinders the model s ability to capture essential temporal information for effective video understanding. To address this we propose an integrated Spatial TempOral dynamic Prompting STOP model which consists of two complementary modules the intra frame spatial prompting and inter frame temporal prompting. Our intra frame spatial prompts are designed to adaptively highlight discriminative regions within each frame by leveraging intra frame attention and temporal variation allowing the model to focus on areas with substantial temporal dynamics and capture fine grained spatial details. Additionally to highlight the varying importance of frames for video understanding we further introduce inter frame temporal prompts dynamically inserting prompts between frames with high temporal variance as measured by frame similarity. This enables the model to prioritize key frames and enhances its capacity to understand temporal dependencies across sequences. Extensive experiments on various video benchmarks demonstrate that STOP consistently achieves superior performance against state of the art methods. The code is available at https github.com zhoujiahuan1991 CVPR2025 STOP.,STOP Integrated Spatial Temporal Dynamic Prompting for Video Understanding,"['temporal', 'video', 'frame', 'spatial', 'frames', 'model', 'prompting', 'prompts', 'intra', 'intra frame']",Pre trained on tremendous image text pairs vision language models like CLIP have demonstrated promising zero shot generalization across numerous image based tasks.
2503.17261v1,Cross-Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET-CT Images,"Lung cancer is a leading cause of cancer-related deaths globally. PET-CT is
crucial for imaging lung tumors, providing essential metabolic and anatomical
information, while it faces challenges such as poor image quality, motion
artifacts, and complex tumor morphology. Deep learning-based models are
expected to address these problems, however, existing small-scale and private
datasets limit significant performance improvements for these methods. Hence,
we introduce a large-scale PET-CT lung tumor segmentation dataset, termed
PCLT20K, which comprises 21,930 pairs of PET-CT images from 605 patients.
Furthermore, we propose a cross-modal interactive perception network with Mamba
(CIPA) for lung tumor segmentation in PET-CT images. Specifically, we design a
channel-wise rectification module (CRM) that implements a channel state space
block across multi-modal features to learn correlated representations and helps
filter out modality-specific noise. A dynamic cross-modality interaction module
(DCIM) is designed to effectively integrate position and context information,
which employs PET images to learn regional position information and serves as a
bridge to assist in modeling the relationships between local features of CT
images. Extensive experiments on a comprehensive benchmark demonstrate the
effectiveness of our CIPA compared to the current state-of-the-art segmentation
methods. We hope our research can provide more exploration opportunities for
medical image segmentation. The dataset and code are available at
https://github.com/mj129/CIPA.","['eess.IV', 'cs.CV']","['Jie Mei', 'Chenyu Lin', 'Yu Qiu', 'Yaonan Wang', 'Hui Zhang', 'Ziyang Wang', 'Dong Dai']",2025-03-21,2025-03-21,Lung cancer is a leading cause of cancer related deaths globally. PET CT is crucial for imaging lung tumors providing essential metabolic and anatomical information while it faces challenges such as poor image quality motion artifacts and complex tumor morphology. Deep learning based models are expected to address these problems however existing small scale and private datasets limit significant performance improvements for these methods. Hence we introduce a large scale PET CT lung tumor segmentation dataset termed PCLT20K which comprises 21 930 pairs of PET CT images from 605 patients. Furthermore we propose a cross modal interactive perception network with Mamba CIPA for lung tumor segmentation in PET CT images. Specifically we design a channel wise rectification module CRM that implements a channel state space block across multi modal features to learn correlated representations and helps filter out modality specific noise. A dynamic cross modality interaction module DCIM is designed to effectively integrate position and context information which employs PET images to learn regional position information and serves as a bridge to assist in modeling the relationships between local features of CT images. Extensive experiments on a comprehensive benchmark demonstrate the effectiveness of our CIPA compared to the current state of the art segmentation methods. We hope our research can provide more exploration opportunities for medical image segmentation. The dataset and code are available at https github.com mj129 CIPA.,Cross Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET CT Images,"['ct', 'pet', 'images', 'lung', 'pet ct', 'segmentation', 'cipa', 'ct images', 'information', 'tumor']",Lung cancer is a leading cause of cancer related deaths globally.
2503.15777v1,Line Space Clustering (LSC): Feature-Based Clustering using K-medians and Dynamic Time Warping for Versatility,"Clustering high-dimensional data is a critical challenge in machine learning
due to the curse of dimensionality and the presence of noise. Traditional
clustering algorithms often fail to capture the intrinsic structures in such
data. This paper explores a combination of clustering methods, which we called
Line Space Clustering (LSC), a representation that transforms data points into
lines in a newly defined feature space, enabling clustering based on the
similarity of feature value patterns, essentially treating features as
sequences. LSC employs a combined distance metric that uses Euclidean and
Dynamic Time Warping (DTW) distances, weighted by a parameter {\alpha},
allowing flexibility in emphasizing shape or magnitude similarities. We delve
deeply into the mechanics of DTW and the Savitzky Golay filter, explaining
their roles in the algorithm. Extensive experiments demonstrate the efficacy of
LSC on synthetic and real-world datasets, showing that randomly experimenting
with time-series optimized methods sometimes might surprisingly work on a
complex dataset, particularly in noisy environments.
  Source code and experiments are available at:
https://github.com/JoanikijChulev/LSC.",['cs.LG'],"['Joanikij Chulev', 'Angela Mladenovska']",2025-03-20,2025-03-20,Clustering high dimensional data is a critical challenge in machine learning due to the curse of dimensionality and the presence of noise. Traditional clustering algorithms often fail to capture the intrinsic structures in such data. This paper explores a combination of clustering methods which we called Line Space Clustering LSC a representation that transforms data points into lines in a newly defined feature space enabling clustering based on the similarity of feature value patterns essentially treating features as sequences. LSC employs a combined distance metric that uses Euclidean and Dynamic Time Warping DTW distances weighted by a parameter alpha allowing flexibility in emphasizing shape or magnitude similarities. We delve deeply into the mechanics of DTW and the Savitzky Golay filter explaining their roles in the algorithm. Extensive experiments demonstrate the efficacy of LSC on synthetic and real world datasets showing that randomly experimenting with time series optimized methods sometimes might surprisingly work on a complex dataset particularly in noisy environments. Source code and experiments are available at https github.com JoanikijChulev LSC.,Line Space Clustering LSC Feature Based Clustering using K medians and Dynamic Time Warping for Versatility,"['clustering', 'lsc', 'data', 'dtw', 'experiments', 'feature', 'methods', 'space', 'time', 'algorithm']",Clustering high dimensional data is a critical challenge in machine learning due to the curse of dimensionality and the presence of noise.
2503.15629v1,Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning,"Control Lyapunov functions are traditionally used to design a controller
which ensures convergence to a desired state, yet deriving these functions for
nonlinear systems remains a complex challenge. This paper presents a novel,
sample-efficient method for neural approximation of nonlinear Lyapunov
functions, leveraging self-supervised Reinforcement Learning (RL) to enhance
training data generation, particularly for inaccurately represented regions of
the state space. The proposed approach employs a data-driven World Model to
train Lyapunov functions from off-policy trajectories. The method is validated
on both standard and goal-conditioned robotic tasks, demonstrating faster
convergence and higher approximation accuracy compared to the state-of-the-art
neural Lyapunov approximation baseline. The code is available at:
https://github.com/CAV-Research-Lab/SACLA.git","['cs.RO', 'cs.AI', 'cs.CG', 'cs.LG']","['Luc McCutcheon', 'Bahman Gharesifard', 'Saber Fallah']",2025-03-19,2025-03-19,Control Lyapunov functions are traditionally used to design a controller which ensures convergence to a desired state yet deriving these functions for nonlinear systems remains a complex challenge. This paper presents a novel sample efficient method for neural approximation of nonlinear Lyapunov functions leveraging self supervised Reinforcement Learning RL to enhance training data generation particularly for inaccurately represented regions of the state space. The proposed approach employs a data driven World Model to train Lyapunov functions from off policy trajectories. The method is validated on both standard and goal conditioned robotic tasks demonstrating faster convergence and higher approximation accuracy compared to the state of the art neural Lyapunov approximation baseline. The code is available at https github.com CAV Research Lab SACLA.git,Neural Lyapunov Function Approximation with Self Supervised Reinforcement Learning,"['functions', 'lyapunov', 'approximation', 'lyapunov functions', 'state', 'convergence', 'data', 'method', 'neural', 'nonlinear']",Control Lyapunov functions are traditionally used to design a controller which ensures convergence to a desired state yet deriving these functions for nonlinear systems remains a complex challenge.
2503.16153v1,FreeFlux: Understanding and Exploiting Layer-Specific Roles in RoPE-Based MMDiT for Versatile Image Editing,"The integration of Rotary Position Embedding (RoPE) in Multimodal Diffusion
Transformer (MMDiT) has significantly enhanced text-to-image generation
quality. However, the fundamental reliance of self-attention layers on
positional embedding versus query-key similarity during generation remains an
intriguing question. We present the first mechanistic analysis of RoPE-based
MMDiT models (e.g., FLUX), introducing an automated probing strategy that
disentangles positional information versus content dependencies by
strategically manipulating RoPE during generation. Our analysis reveals
distinct dependency patterns that do not straightforwardly correlate with
depth, offering new insights into the layer-specific roles in RoPE-based MMDiT.
Based on these findings, we propose a training-free, task-specific image
editing framework that categorizes editing tasks into three types:
position-dependent editing (e.g., object addition), content
similarity-dependent editing (e.g., non-rigid editing), and region-preserved
editing (e.g., background replacement). For each type, we design tailored
key-value injection strategies based on the characteristics of the editing
task. Extensive qualitative and quantitative evaluations demonstrate that our
method outperforms state-of-the-art approaches, particularly in preserving
original semantic content and achieving seamless modifications.",['cs.CV'],"['Tianyi Wei', 'Yifan Zhou', 'Dongdong Chen', 'Xingang Pan']",2025-03-20,2025-03-20,The integration of Rotary Position Embedding RoPE in Multimodal Diffusion Transformer MMDiT has significantly enhanced text to image generation quality. However the fundamental reliance of self attention layers on positional embedding versus query key similarity during generation remains an intriguing question. We present the first mechanistic analysis of RoPE based MMDiT models e.g. FLUX introducing an automated probing strategy that disentangles positional information versus content dependencies by strategically manipulating RoPE during generation. Our analysis reveals distinct dependency patterns that do not straightforwardly correlate with depth offering new insights into the layer specific roles in RoPE based MMDiT. Based on these findings we propose a training free task specific image editing framework that categorizes editing tasks into three types position dependent editing e.g. object addition content similarity dependent editing e.g. non rigid editing and region preserved editing e.g. background replacement . For each type we design tailored key value injection strategies based on the characteristics of the editing task. Extensive qualitative and quantitative evaluations demonstrate that our method outperforms state of the art approaches particularly in preserving original semantic content and achieving seamless modifications.,FreeFlux Understanding and Exploiting Layer Specific Roles in RoPE Based MMDiT for Versatile Image Editing,"['editing', 'based', 'rope', 'content', 'generation', 'mmdit', 'analysis', 'based mmdit', 'dependent', 'dependent editing']",The integration of Rotary Position Embedding RoPE in Multimodal Diffusion Transformer MMDiT has significantly enhanced text to image generation quality.
2503.16010v1,Patch-based learning of adaptive Total Variation parameter maps for blind image denoising,"We consider a patch-based learning approach defined in terms of neural
networks to estimate spatially adaptive regularisation parameter maps for image
denoising with weighted Total Variation and test it to situations when the
noise distribution is unknown. As an example, we consider situations where
noise could be either Gaussian or Poisson and perform preliminary model
selection by a standard binary classification network. Then, we define a
patch-based approach where at each image pixel an optimal weighting between TV
regularisation and the corresponding data fidelity is learned in a supervised
way using reference natural image patches upon optimisation of SSIM and in a
sliding window fashion. Extensive numerical results are reported for both noise
models, showing significant improvement w.r.t. results obtained by means of
optimal scalar regularisation.","['eess.IV', 'cs.LG', 'cs.NA', 'math.NA']","['Claudio Fantasia', 'Luca Calatroni', 'Xavier Descombes', 'Rim Rekik']",2025-03-20,2025-03-20,We consider a patch based learning approach defined in terms of neural networks to estimate spatially adaptive regularisation parameter maps for image denoising with weighted Total Variation and test it to situations when the noise distribution is unknown. As an example we consider situations where noise could be either Gaussian or Poisson and perform preliminary model selection by a standard binary classification network. Then we define a patch based approach where at each image pixel an optimal weighting between TV regularisation and the corresponding data fidelity is learned in a supervised way using reference natural image patches upon optimisation of SSIM and in a sliding window fashion. Extensive numerical results are reported for both noise models showing significant improvement w.r.t. results obtained by means of optimal scalar regularisation.,Patch based learning of adaptive Total Variation parameter maps for blind image denoising,"['image', 'noise', 'regularisation', 'approach', 'based', 'consider', 'optimal', 'patch', 'patch based', 'results']",We consider a patch based learning approach defined in terms of neural networks to estimate spatially adaptive regularisation parameter maps for image denoising with weighted Total Variation and test it to situations when the noise distribution is unknown.
2503.14837v1,SemanticFlow: A Self-Supervised Framework for Joint Scene Flow Prediction and Instance Segmentation in Dynamic Environments,"Accurate perception of dynamic traffic scenes is crucial for high-level
autonomous driving systems, requiring robust object motion estimation and
instance segmentation. However, traditional methods often treat them as
separate tasks, leading to suboptimal performance, spatio-temporal
inconsistencies, and inefficiency in complex scenarios due to the absence of
information sharing. This paper proposes a multi-task SemanticFlow framework to
simultaneously predict scene flow and instance segmentation of full-resolution
point clouds. The novelty of this work is threefold: 1) developing a
coarse-to-fine prediction based multi-task scheme, where an initial coarse
segmentation of static backgrounds and dynamic objects is used to provide
contextual information for refining motion and semantic information through a
shared feature processing module; 2) developing a set of loss functions to
enhance the performance of scene flow estimation and instance segmentation,
while can help ensure spatial and temporal consistency of both static and
dynamic objects within traffic scenes; 3) developing a self-supervised learning
scheme, which utilizes coarse segmentation to detect rigid objects and compute
their transformation matrices between sequential frames, enabling the
generation of self-supervised labels. The proposed framework is validated on
the Argoverse and Waymo datasets, demonstrating superior performance in
instance segmentation accuracy, scene flow estimation, and computational
efficiency, establishing a new benchmark for self-supervised methods in dynamic
scene understanding.","['cs.CV', 'cs.RO']","['Yinqi Chen', 'Meiying Zhang', 'Qi Hao', 'Guang Zhou']",2025-03-19,2025-03-19,Accurate perception of dynamic traffic scenes is crucial for high level autonomous driving systems requiring robust object motion estimation and instance segmentation. However traditional methods often treat them as separate tasks leading to suboptimal performance spatio temporal inconsistencies and inefficiency in complex scenarios due to the absence of information sharing. This paper proposes a multi task SemanticFlow framework to simultaneously predict scene flow and instance segmentation of full resolution point clouds. The novelty of this work is threefold 1 developing a coarse to fine prediction based multi task scheme where an initial coarse segmentation of static backgrounds and dynamic objects is used to provide contextual information for refining motion and semantic information through a shared feature processing module 2 developing a set of loss functions to enhance the performance of scene flow estimation and instance segmentation while can help ensure spatial and temporal consistency of both static and dynamic objects within traffic scenes 3 developing a self supervised learning scheme which utilizes coarse segmentation to detect rigid objects and compute their transformation matrices between sequential frames enabling the generation of self supervised labels. The proposed framework is validated on the Argoverse and Waymo datasets demonstrating superior performance in instance segmentation accuracy scene flow estimation and computational efficiency establishing a new benchmark for self supervised methods in dynamic scene understanding.,SemanticFlow A Self Supervised Framework for Joint Scene Flow Prediction and Instance Segmentation in Dynamic Environments,"['segmentation', 'dynamic', 'instance', 'instance segmentation', 'scene', 'coarse', 'developing', 'estimation', 'flow', 'information']",Accurate perception of dynamic traffic scenes is crucial for high level autonomous driving systems requiring robust object motion estimation and instance segmentation.
2503.16055v1,SALT: Singular Value Adaptation with Low-Rank Transformation,"The complex nature of medical image segmentation calls for models that are
specifically designed to capture detailed, domain-specific features. Large
foundation models offer considerable flexibility, yet the cost of fine-tuning
these models remains a significant barrier. Parameter-Efficient Fine-Tuning
(PEFT) methods, such as Low-Rank Adaptation (LoRA), efficiently update model
weights with low-rank matrices but may suffer from underfitting when the chosen
rank is insufficient to capture domain-specific nuances. Conversely, full-rank
Singular Value Decomposition (SVD) based methods provide comprehensive updates
by modifying all singular values, yet they often lack flexibility and exhibit
variable performance across datasets. We propose SALT (Singular Value
Adaptation with Low-Rank Transformation), a method that selectively adapts the
most influential singular values using trainable scale and shift parameters
while complementing this with a low-rank update for the remaining subspace.
This hybrid approach harnesses the advantages of both LoRA and SVD, enabling
effective adaptation without relying on increasing model size or depth.
Evaluated on 5 challenging medical datasets, ranging from as few as 20 samples
to 1000, SALT outperforms state-of-the-art PEFT (LoRA and SVD) by 2% to 5% in
Dice with only 3.9% trainable parameters, demonstrating robust adaptation even
in low-resource settings. The code for SALT is available at:
https://github.com/BioMedIA-MBZUAI/SALT","['eess.IV', 'cs.CV']","['Abdelrahman Elsayed', 'Sarim Hashmi', 'Mohammed Elseiagy', 'Hu Wang', 'Mohammad Yaqub', 'Ibrahim Almakky']",2025-03-20,2025-03-20,The complex nature of medical image segmentation calls for models that are specifically designed to capture detailed domain specific features. Large foundation models offer considerable flexibility yet the cost of fine tuning these models remains a significant barrier. Parameter Efficient Fine Tuning PEFT methods such as Low Rank Adaptation LoRA efficiently update model weights with low rank matrices but may suffer from underfitting when the chosen rank is insufficient to capture domain specific nuances. Conversely full rank Singular Value Decomposition SVD based methods provide comprehensive updates by modifying all singular values yet they often lack flexibility and exhibit variable performance across datasets. We propose SALT Singular Value Adaptation with Low Rank Transformation a method that selectively adapts the most influential singular values using trainable scale and shift parameters while complementing this with a low rank update for the remaining subspace. This hybrid approach harnesses the advantages of both LoRA and SVD enabling effective adaptation without relying on increasing model size or depth. Evaluated on 5 challenging medical datasets ranging from as few as 20 samples to 1000 SALT outperforms state of the art PEFT LoRA and SVD by 2 to 5 in Dice with only 3.9 trainable parameters demonstrating robust adaptation even in low resource settings. The code for SALT is available at https github.com BioMedIA MBZUAI SALT,SALT Singular Value Adaptation with Low Rank Transformation,"['rank', 'low', 'adaptation', 'low rank', 'salt', 'singular', 'lora', 'models', 'svd', 'adaptation low']",The complex nature of medical image segmentation calls for models that are specifically designed to capture detailed domain specific features.
2503.15558v1,Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning,"Physical AI systems need to perceive, understand, and perform complex actions
in the physical world. In this paper, we present the Cosmos-Reason1 models that
can understand the physical world and generate appropriate embodied decisions
(e.g., next step action) in natural language through long chain-of-thought
reasoning processes. We begin by defining key capabilities for Physical AI
reasoning, with a focus on physical common sense and embodied reasoning. To
represent physical common sense, we use a hierarchical ontology that captures
fundamental knowledge about space, time, and physics. For embodied reasoning,
we rely on a two-dimensional ontology that generalizes across different
physical embodiments. Building on these capabilities, we develop two multimodal
large language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B. We curate data
and train our models in four stages: vision pre-training, general supervised
fine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL)
as the post-training. To evaluate our models, we build comprehensive benchmarks
for physical common sense and embodied reasoning according to our ontologies.
Evaluation results show that Physical AI SFT and reinforcement learning bring
significant improvements. To facilitate the development of Physical AI, we will
make our code and pre-trained models available under the NVIDIA Open Model
License at https://github.com/nvidia-cosmos/cosmos-reason1.","['cs.AI', 'cs.CV', 'cs.LG', 'cs.RO']","['NVIDIA', ':', 'Alisson Azzolini', 'Hannah Brandon', 'Prithvijit Chattopadhyay', 'Huayu Chen', 'Jinju Chu', 'Yin Cui', 'Jenna Diamond', 'Yifan Ding', 'Francesco Ferroni', 'Rama Govindaraju', 'Jinwei Gu', 'Siddharth Gururani', 'Imad El Hanafi', 'Zekun Hao', 'Jacob Huffman', 'Jingyi Jin', 'Brendan Johnson', 'Rizwan Khan', 'George Kurian', 'Elena Lantz', 'Nayeon Lee', 'Zhaoshuo Li', 'Xuan Li', 'Tsung-Yi Lin', 'Yen-Chen Lin', 'Ming-Yu Liu', 'Andrew Mathau', 'Yun Ni', 'Lindsey Pavao', 'Wei Ping', 'David W. Romero', 'Misha Smelyanskiy', 'Shuran Song', 'Lyne Tchapmi', 'Andrew Z. Wang', 'Boxin Wang', 'Haoxiang Wang', 'Fangyin Wei', 'Jiashu Xu', 'Yao Xu', 'Xiaodong Yang', 'Zhuolin Yang', 'Xiaohui Zeng', 'Zhe Zhang']",2025-03-18,2025-03-18,Physical AI systems need to perceive understand and perform complex actions in the physical world. In this paper we present the Cosmos Reason1 models that can understand the physical world and generate appropriate embodied decisions e.g. next step action in natural language through long chain of thought reasoning processes. We begin by defining key capabilities for Physical AI reasoning with a focus on physical common sense and embodied reasoning. To represent physical common sense we use a hierarchical ontology that captures fundamental knowledge about space time and physics. For embodied reasoning we rely on a two dimensional ontology that generalizes across different physical embodiments. Building on these capabilities we develop two multimodal large language models Cosmos Reason1 8B and Cosmos Reason1 56B. We curate data and train our models in four stages vision pre training general supervised fine tuning SFT Physical AI SFT and Physical AI reinforcement learning RL as the post training. To evaluate our models we build comprehensive benchmarks for physical common sense and embodied reasoning according to our ontologies. Evaluation results show that Physical AI SFT and reinforcement learning bring significant improvements. To facilitate the development of Physical AI we will make our code and pre trained models available under the NVIDIA Open Model License at https github.com nvidia cosmos cosmos reason1.,Cosmos Reason1 From Physical Common Sense To Embodied Reasoning,"['physical', 'ai', 'physical ai', 'cosmos', 'models', 'reasoning', 'cosmos reason1', 'embodied', 'reason1', 'common']",Physical AI systems need to perceive understand and perform complex actions in the physical world.
2503.15569v1,RAG-based User Profiling for Precision Planning in Mixed-precision Over-the-Air Federated Learning,"Mixed-precision computing, a widely applied technique in AI, offers a larger
trade-off space between accuracy and efficiency. The recent purposed
Mixed-Precision Over-the-Air Federated Learning (MP-OTA-FL) enables clients to
operate at appropriate precision levels based on their heterogeneous hardware,
taking advantages of the larger trade-off space while covering the quantization
overheads in the mixed-precision modulation scheme for the OTA aggregation
process. A key to further exploring the potential of the MP-OTA-FL framework is
the optimization of client precision levels. The choice of precision level
hinges on multifaceted factors including hardware capability, potential client
contribution, and user satisfaction, among which factors can be difficult to
define or quantify.
  In this paper, we propose a RAG-based User Profiling for precision planning
framework that integrates retrieval-augmented LLMs and dynamic client profiling
to optimize satisfaction and contributions. This includes a hybrid interface
for gathering device/user insights and an RAG database storing historical
quantization decisions with feedback. Experiments show that our method boosts
satisfaction, energy savings, and global model accuracy in MP-OTA-FL systems.","['cs.LG', 'cs.HC']","['Jinsheng Yuan', 'Yun Tang', 'Weisi Guo']",2025-03-19,2025-03-19,Mixed precision computing a widely applied technique in AI offers a larger trade off space between accuracy and efficiency. The recent purposed Mixed Precision Over the Air Federated Learning MP OTA FL enables clients to operate at appropriate precision levels based on their heterogeneous hardware taking advantages of the larger trade off space while covering the quantization overheads in the mixed precision modulation scheme for the OTA aggregation process. A key to further exploring the potential of the MP OTA FL framework is the optimization of client precision levels. The choice of precision level hinges on multifaceted factors including hardware capability potential client contribution and user satisfaction among which factors can be difficult to define or quantify. In this paper we propose a RAG based User Profiling for precision planning framework that integrates retrieval augmented LLMs and dynamic client profiling to optimize satisfaction and contributions. This includes a hybrid interface for gathering device user insights and an RAG database storing historical quantization decisions with feedback. Experiments show that our method boosts satisfaction energy savings and global model accuracy in MP OTA FL systems.,RAG based User Profiling for Precision Planning in Mixed precision Over the Air Federated Learning,"['precision', 'ota', 'client', 'fl', 'mixed', 'mixed precision', 'mp', 'mp ota', 'ota fl', 'satisfaction']",Mixed precision computing a widely applied technique in AI offers a larger trade off space between accuracy and efficiency.
2503.15914v1,Text-Driven Diffusion Model for Sign Language Production,"We introduce the hfut-lmc team's solution to the SLRTP Sign Production
Challenge. The challenge aims to generate semantically aligned sign language
pose sequences from text inputs. To this end, we propose a Text-driven
Diffusion Model (TDM) framework. During the training phase, TDM utilizes an
encoder to encode text sequences and incorporates them into the diffusion model
as conditional input to generate sign pose sequences. To guarantee the high
quality and accuracy of the generated pose sequences, we utilize two key loss
functions. The joint loss function L_{joint} is used to precisely measure and
minimize the differences between the joint positions of the generated pose
sequences and those of the ground truth. Similarly, the bone orientation loss
function L_{bone} is instrumental in ensuring that the orientation of the bones
in the generated poses aligns with the actual, correct orientations. In the
inference stage, the TDM framework takes on a different yet equally important
task. It starts with noisy sequences and, under the strict constraints of the
text conditions, gradually refines and generates semantically consistent sign
language pose sequences. Our carefully designed framework performs well on the
sign language production task, and our solution achieves a BLEU-1 score of
20.17, placing second in the challenge.",['cs.CV'],"['Jiayi He', 'Xu Wang', 'Ruobei Zhang', 'Shengeng Tang', 'Yaxiong Wang', 'Lechao Cheng']",2025-03-20,2025-03-20,We introduce the hfut lmc team s solution to the SLRTP Sign Production Challenge. The challenge aims to generate semantically aligned sign language pose sequences from text inputs. To this end we propose a Text driven Diffusion Model TDM framework. During the training phase TDM utilizes an encoder to encode text sequences and incorporates them into the diffusion model as conditional input to generate sign pose sequences. To guarantee the high quality and accuracy of the generated pose sequences we utilize two key loss functions. The joint loss function L_ joint is used to precisely measure and minimize the differences between the joint positions of the generated pose sequences and those of the ground truth. Similarly the bone orientation loss function L_ bone is instrumental in ensuring that the orientation of the bones in the generated poses aligns with the actual correct orientations. In the inference stage the TDM framework takes on a different yet equally important task. It starts with noisy sequences and under the strict constraints of the text conditions gradually refines and generates semantically consistent sign language pose sequences. Our carefully designed framework performs well on the sign language production task and our solution achieves a BLEU 1 score of 20.17 placing second in the challenge.,Text Driven Diffusion Model for Sign Language Production,"['sequences', 'pose', 'pose sequences', 'sign', 'text', 'challenge', 'framework', 'generated', 'joint', 'language']",We introduce the hfut lmc team s solution to the SLRTP Sign Production Challenge.
2503.16851v1,Towards LLM Guardrails via Sparse Representation Steering,"Large Language Models (LLMs) have demonstrated remarkable performance in
natural language generation tasks, yet their uncontrolled outputs pose
significant ethical and safety risks. Recently, representation engineering
methods have shown promising results in steering model behavior by modifying
the rich semantic information encoded in activation vectors. However, due to
the difficulty of precisely disentangling semantic directions within
high-dimensional representation space, existing approaches suffer from three
major limitations: lack of fine-grained control, quality degradation of
generated content, and poor interpretability. To address these challenges, we
propose a sparse encoding-based representation engineering method, named SRE,
which decomposes polysemantic activations into a structured, monosemantic
feature space. By leveraging sparse autoencoding, our approach isolates and
adjusts only task-specific sparse feature dimensions, enabling precise and
interpretable steering of model behavior while preserving content quality. We
validate our method on three critical domains, i.e., safety, fairness, and
truthfulness using the open-source LLM Gemma-2-2B-it. Experimental results show
that SRE achieves superior controllability while maintaining the overall
quality of generated content (i.e., controllability and quality), demonstrating
its effectiveness as a fine-grained and interpretable activation steering
framework.","['cs.CR', 'cs.CL']","['Zeqing He', 'Zhibo Wang', 'Huiyu Xu', 'Kui Ren']",2025-03-21,2025-03-21,Large Language Models LLMs have demonstrated remarkable performance in natural language generation tasks yet their uncontrolled outputs pose significant ethical and safety risks. Recently representation engineering methods have shown promising results in steering model behavior by modifying the rich semantic information encoded in activation vectors. However due to the difficulty of precisely disentangling semantic directions within high dimensional representation space existing approaches suffer from three major limitations lack of fine grained control quality degradation of generated content and poor interpretability. To address these challenges we propose a sparse encoding based representation engineering method named SRE which decomposes polysemantic activations into a structured monosemantic feature space. By leveraging sparse autoencoding our approach isolates and adjusts only task specific sparse feature dimensions enabling precise and interpretable steering of model behavior while preserving content quality. We validate our method on three critical domains i.e. safety fairness and truthfulness using the open source LLM Gemma 2 2B it. Experimental results show that SRE achieves superior controllability while maintaining the overall quality of generated content i.e. controllability and quality demonstrating its effectiveness as a fine grained and interpretable activation steering framework.,Towards LLM Guardrails via Sparse Representation Steering,"['quality', 'content', 'representation', 'sparse', 'steering', 'activation', 'behavior', 'controllability', 'engineering', 'feature']",Large Language Models LLMs have demonstrated remarkable performance in natural language generation tasks yet their uncontrolled outputs pose significant ethical and safety risks.
2503.14709v1,Better Private Distribution Testing by Leveraging Unverified Auxiliary Data,"We extend the framework of augmented distribution testing (Aliakbarpour,
Indyk, Rubinfeld, and Silwal, NeurIPS 2024) to the differentially private
setting. This captures scenarios where a data analyst must perform hypothesis
testing tasks on sensitive data, but is able to leverage prior knowledge
(public, but possibly erroneous or untrusted) about the data distribution.
  We design private algorithms in this augmented setting for three flagship
distribution testing tasks, uniformity, identity, and closeness testing, whose
sample complexity smoothly scales with the claimed quality of the auxiliary
information. We complement our algorithms with information-theoretic lower
bounds, showing that their sample complexity is optimal (up to logarithmic
factors).","['cs.LG', 'cs.CR', 'cs.DS']","['Maryam Aliakbarpour', 'Arnav Burudgunte', 'Clément Cannone', 'Ronitt Rubinfeld']",2025-03-18,2025-03-18,We extend the framework of augmented distribution testing Aliakbarpour Indyk Rubinfeld and Silwal NeurIPS 2024 to the differentially private setting. This captures scenarios where a data analyst must perform hypothesis testing tasks on sensitive data but is able to leverage prior knowledge public but possibly erroneous or untrusted about the data distribution. We design private algorithms in this augmented setting for three flagship distribution testing tasks uniformity identity and closeness testing whose sample complexity smoothly scales with the claimed quality of the auxiliary information. We complement our algorithms with information theoretic lower bounds showing that their sample complexity is optimal up to logarithmic factors .,Better Private Distribution Testing by Leveraging Unverified Auxiliary Data,"['testing', 'data', 'distribution', 'algorithms', 'augmented', 'complexity', 'distribution testing', 'information', 'private', 'sample']",We extend the framework of augmented distribution testing Aliakbarpour Indyk Rubinfeld and Silwal NeurIPS 2024 to the differentially private setting.
2503.16666v1,Efficient Training of Neural Fractional-Order Differential Equation via Adjoint Backpropagation,"Fractional-order differential equations (FDEs) enhance traditional
differential equations by extending the order of differential operators from
integers to real numbers, offering greater flexibility in modeling complex
dynamical systems with nonlocal characteristics. Recent progress at the
intersection of FDEs and deep learning has catalyzed a new wave of innovative
models, demonstrating the potential to address challenges such as graph
representation learning. However, training neural FDEs has primarily relied on
direct differentiation through forward-pass operations in FDE numerical
solvers, leading to increased memory usage and computational complexity,
particularly in large-scale applications. To address these challenges, we
propose a scalable adjoint backpropagation method for training neural FDEs by
solving an augmented FDE backward in time, which substantially reduces memory
requirements. This approach provides a practical neural FDE toolbox and holds
considerable promise for diverse applications. We demonstrate the effectiveness
of our method in several tasks, achieving performance comparable to baseline
models while significantly reducing computational overhead.",['cs.LG'],"['Qiyu Kang', 'Xuhao Li', 'Kai Zhao', 'Wenjun Cui', 'Yanan Zhao', 'Weihua Deng', 'Wee Peng Tay']",2025-03-20,2025-03-20,Fractional order differential equations FDEs enhance traditional differential equations by extending the order of differential operators from integers to real numbers offering greater flexibility in modeling complex dynamical systems with nonlocal characteristics. Recent progress at the intersection of FDEs and deep learning has catalyzed a new wave of innovative models demonstrating the potential to address challenges such as graph representation learning. However training neural FDEs has primarily relied on direct differentiation through forward pass operations in FDE numerical solvers leading to increased memory usage and computational complexity particularly in large scale applications. To address these challenges we propose a scalable adjoint backpropagation method for training neural FDEs by solving an augmented FDE backward in time which substantially reduces memory requirements. This approach provides a practical neural FDE toolbox and holds considerable promise for diverse applications. We demonstrate the effectiveness of our method in several tasks achieving performance comparable to baseline models while significantly reducing computational overhead.,Efficient Training of Neural Fractional Order Differential Equation via Adjoint Backpropagation,"['fdes', 'differential', 'fde', 'neural', 'address', 'address challenges', 'applications', 'challenges', 'computational', 'differential equations']",Fractional order differential equations FDEs enhance traditional differential equations by extending the order of differential operators from integers to real numbers offering greater flexibility in modeling complex dynamical systems with nonlocal characteristics.
2503.16395v1,Truthful Elicitation of Imprecise Forecasts,"The quality of probabilistic forecasts is crucial for decision-making under
uncertainty. While proper scoring rules incentivize truthful reporting of
precise forecasts, they fall short when forecasters face epistemic uncertainty
about their beliefs, limiting their use in safety-critical domains where
decision-makers (DMs) prioritize proper uncertainty management. To address
this, we propose a framework for scoring imprecise forecasts -- forecasts given
as a set of beliefs. Despite existing impossibility results for deterministic
scoring rules, we enable truthful elicitation by drawing connection to social
choice theory and introducing a two-way communication framework where DMs first
share their aggregation rules (e.g., averaging or min-max) used in downstream
decisions for resolving forecast ambiguity. This, in turn, helps forecasters
resolve indecision during elicitation. We further show that truthful
elicitation of imprecise forecasts is achievable using proper scoring rules
randomized over the aggregation procedure. Our approach allows DM to elicit and
integrate the forecaster's epistemic uncertainty into their decision-making
process, thus improving credibility.",['cs.LG'],"['Anurag Singh', 'Siu Lun Chau', 'Krikamol Muandet']",2025-03-20,2025-03-20,The quality of probabilistic forecasts is crucial for decision making under uncertainty. While proper scoring rules incentivize truthful reporting of precise forecasts they fall short when forecasters face epistemic uncertainty about their beliefs limiting their use in safety critical domains where decision makers DMs prioritize proper uncertainty management. To address this we propose a framework for scoring imprecise forecasts forecasts given as a set of beliefs. Despite existing impossibility results for deterministic scoring rules we enable truthful elicitation by drawing connection to social choice theory and introducing a two way communication framework where DMs first share their aggregation rules e.g. averaging or min max used in downstream decisions for resolving forecast ambiguity. This in turn helps forecasters resolve indecision during elicitation. We further show that truthful elicitation of imprecise forecasts is achievable using proper scoring rules randomized over the aggregation procedure. Our approach allows DM to elicit and integrate the forecaster s epistemic uncertainty into their decision making process thus improving credibility.,Truthful Elicitation of Imprecise Forecasts,"['forecasts', 'rules', 'scoring', 'uncertainty', 'decision', 'elicitation', 'proper', 'scoring rules', 'truthful', 'aggregation']",The quality of probabilistic forecasts is crucial for decision making under uncertainty.
2503.17167v1,DiTEC-WDN: A Large-Scale Dataset of Water Distribution Network Scenarios under Diverse Hydraulic Conditions,"Privacy restrictions hinder the sharing of real-world Water Distribution
Network (WDN) models, limiting the application of emerging data-driven machine
learning, which typically requires extensive observations. To address this
challenge, we propose the dataset DiTEC-WDN that comprises 36,000 unique
scenarios simulated over either short-term (24 hours) or long-term (1 year)
periods. We constructed this dataset using an automated pipeline that optimizes
crucial parameters (e.g., pressure, flow rate, and demand patterns),
facilitates large-scale simulations, and records discrete, synthetic but
hydraulically realistic states under standard conditions via rule validation
and post-hoc analysis. With a total of 228 million generated graph-based
states, DiTEC-WDN can support a variety of machine-learning tasks, including
graph-level, node-level, and link-level regression, as well as time-series
forecasting. This contribution, released under a public license, encourages
open scientific research in the critical water sector, eliminates the risk of
exposing sensitive data, and fulfills the need for a large-scale water
distribution network benchmark for study comparisons and scenario analysis.","['cs.LG', 'cs.AI']","['Huy Truong', 'Andrés Tello', 'Alexander Lazovik', 'Victoria Degeler']",2025-03-21,2025-03-21,Privacy restrictions hinder the sharing of real world Water Distribution Network WDN models limiting the application of emerging data driven machine learning which typically requires extensive observations. To address this challenge we propose the dataset DiTEC WDN that comprises 36 000 unique scenarios simulated over either short term 24 hours or long term 1 year periods. We constructed this dataset using an automated pipeline that optimizes crucial parameters e.g. pressure flow rate and demand patterns facilitates large scale simulations and records discrete synthetic but hydraulically realistic states under standard conditions via rule validation and post hoc analysis. With a total of 228 million generated graph based states DiTEC WDN can support a variety of machine learning tasks including graph level node level and link level regression as well as time series forecasting. This contribution released under a public license encourages open scientific research in the critical water sector eliminates the risk of exposing sensitive data and fulfills the need for a large scale water distribution network benchmark for study comparisons and scenario analysis.,DiTEC WDN A Large Scale Dataset of Water Distribution Network Scenarios under Diverse Hydraulic Conditions,"['level', 'water', 'wdn', 'analysis', 'data', 'dataset', 'distribution', 'distribution network', 'ditec', 'ditec wdn']",Privacy restrictions hinder the sharing of real world Water Distribution Network WDN models limiting the application of emerging data driven machine learning which typically requires extensive observations.
2503.15712v1,SPNeRF: Open Vocabulary 3D Neural Scene Segmentation with Superpoints,"Open-vocabulary segmentation, powered by large visual-language models like
CLIP, has expanded 2D segmentation capabilities beyond fixed classes predefined
by the dataset, enabling zero-shot understanding across diverse scenes.
Extending these capabilities to 3D segmentation introduces challenges, as
CLIP's image-based embeddings often lack the geometric detail necessary for 3D
scene segmentation. Recent methods tend to address this by introducing
additional segmentation models or replacing CLIP with variations trained on
segmentation data, which lead to redundancy or loss on CLIP's general language
capabilities. To overcome this limitation, we introduce SPNeRF, a NeRF based
zero-shot 3D segmentation approach that leverages geometric priors. We
integrate geometric primitives derived from the 3D scene into NeRF training to
produce primitive-wise CLIP features, avoiding the ambiguity of point-wise
features. Additionally, we propose a primitive-based merging mechanism enhanced
with affinity scores. Without relying on additional segmentation models, our
method further explores CLIP's capability for 3D segmentation and achieves
notable improvements over original LERF.",['cs.CV'],"['Weiwen Hu', 'Niccolò Parodi', 'Marcus Zepp', 'Ingo Feldmann', 'Oliver Schreer', 'Peter Eisert']",2025-03-19,2025-03-19,Open vocabulary segmentation powered by large visual language models like CLIP has expanded 2D segmentation capabilities beyond fixed classes predefined by the dataset enabling zero shot understanding across diverse scenes. Extending these capabilities to 3D segmentation introduces challenges as CLIP s image based embeddings often lack the geometric detail necessary for 3D scene segmentation. Recent methods tend to address this by introducing additional segmentation models or replacing CLIP with variations trained on segmentation data which lead to redundancy or loss on CLIP s general language capabilities. To overcome this limitation we introduce SPNeRF a NeRF based zero shot 3D segmentation approach that leverages geometric priors. We integrate geometric primitives derived from the 3D scene into NeRF training to produce primitive wise CLIP features avoiding the ambiguity of point wise features. Additionally we propose a primitive based merging mechanism enhanced with affinity scores. Without relying on additional segmentation models our method further explores CLIP s capability for 3D segmentation and achieves notable improvements over original LERF.,SPNeRF Open Vocabulary 3D Neural Scene Segmentation with Superpoints,"['segmentation', 'clip', '3d', '3d segmentation', 'based', 'capabilities', 'geometric', 'models', '3d scene', 'additional']",Open vocabulary segmentation powered by large visual language models like CLIP has expanded 2D segmentation capabilities beyond fixed classes predefined by the dataset enabling zero shot understanding across diverse scenes.
2503.15361v1,Boosting HDR Image Reconstruction via Semantic Knowledge Transfer,"Recovering High Dynamic Range (HDR) images from multiple Low Dynamic Range
(LDR) images becomes challenging when the LDR images exhibit noticeable
degradation and missing content. Leveraging scene-specific semantic priors
offers a promising solution for restoring heavily degraded regions. However,
these priors are typically extracted from sRGB Standard Dynamic Range (SDR)
images, the domain/format gap poses a significant challenge when applying it to
HDR imaging. To address this issue, we propose a general framework that
transfers semantic knowledge derived from SDR domain via self-distillation to
boost existing HDR reconstruction. Specifically, the proposed framework first
introduces the Semantic Priors Guided Reconstruction Model (SPGRM), which
leverages SDR image semantic knowledge to address ill-posed problems in the
initial HDR reconstruction results. Subsequently, we leverage a
self-distillation mechanism that constrains the color and content information
with semantic knowledge, aligning the external outputs between the baseline and
SPGRM. Furthermore, to transfer the semantic knowledge of the internal
features, we utilize a semantic knowledge alignment module (SKAM) to fill the
missing semantic contents with the complementary masks. Extensive experiments
demonstrate that our method can significantly improve the HDR imaging quality
of existing methods.",['cs.CV'],"['Qingsen Yan', 'Tao Hu', 'Genggeng Chen', 'Wei Dong', 'Yanning Zhang']",2025-03-19,2025-03-19,Recovering High Dynamic Range HDR images from multiple Low Dynamic Range LDR images becomes challenging when the LDR images exhibit noticeable degradation and missing content. Leveraging scene specific semantic priors offers a promising solution for restoring heavily degraded regions. However these priors are typically extracted from sRGB Standard Dynamic Range SDR images the domain format gap poses a significant challenge when applying it to HDR imaging. To address this issue we propose a general framework that transfers semantic knowledge derived from SDR domain via self distillation to boost existing HDR reconstruction. Specifically the proposed framework first introduces the Semantic Priors Guided Reconstruction Model SPGRM which leverages SDR image semantic knowledge to address ill posed problems in the initial HDR reconstruction results. Subsequently we leverage a self distillation mechanism that constrains the color and content information with semantic knowledge aligning the external outputs between the baseline and SPGRM. Furthermore to transfer the semantic knowledge of the internal features we utilize a semantic knowledge alignment module SKAM to fill the missing semantic contents with the complementary masks. Extensive experiments demonstrate that our method can significantly improve the HDR imaging quality of existing methods.,Boosting HDR Image Reconstruction via Semantic Knowledge Transfer,"['semantic', 'hdr', 'knowledge', 'semantic knowledge', 'images', 'dynamic', 'dynamic range', 'priors', 'range', 'reconstruction']",Recovering High Dynamic Range HDR images from multiple Low Dynamic Range LDR images becomes challenging when the LDR images exhibit noticeable degradation and missing content.
2503.15808v1,ChatGPT and U(X): A Rapid Review on Measuring the User Experience,"ChatGPT, powered by a large language model (LLM), has revolutionized everyday
human-computer interaction (HCI) since its 2022 release. While now used by
millions around the world, a coherent pathway for evaluating the user
experience (UX) ChatGPT offers remains missing. In this rapid review (N = 58),
I explored how ChatGPT UX has been approached quantitatively so far. I focused
on the independent variables (IVs) manipulated, the dependent variables (DVs)
measured, and the methods used for measurement. Findings reveal trends, gaps,
and emerging consensus in UX assessments. This work offers a first step towards
synthesizing existing approaches to measuring ChatGPT UX, urgent trajectories
to advance standardization and breadth, and two preliminary frameworks aimed at
guiding future research and tool development. I seek to elevate the field of
ChatGPT UX by empowering researchers and practitioners in optimizing user
interactions with ChatGPT and similar LLM-based systems.","['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY']",['Katie Seaborn'],2025-03-20,2025-03-20,ChatGPT powered by a large language model LLM has revolutionized everyday human computer interaction HCI since its 2022 release. While now used by millions around the world a coherent pathway for evaluating the user experience UX ChatGPT offers remains missing. In this rapid review N 58 I explored how ChatGPT UX has been approached quantitatively so far. I focused on the independent variables IVs manipulated the dependent variables DVs measured and the methods used for measurement. Findings reveal trends gaps and emerging consensus in UX assessments. This work offers a first step towards synthesizing existing approaches to measuring ChatGPT UX urgent trajectories to advance standardization and breadth and two preliminary frameworks aimed at guiding future research and tool development. I seek to elevate the field of ChatGPT UX by empowering researchers and practitioners in optimizing user interactions with ChatGPT and similar LLM based systems.,ChatGPT and U X A Rapid Review on Measuring the User Experience,"['chatgpt', 'ux', 'chatgpt ux', 'llm', 'offers', 'used', 'user', 'variables', '2022', 'coherent pathway']",ChatGPT powered by a large language model LLM has revolutionized everyday human computer interaction HCI since its 2022 release.
2503.16579v1,World Knowledge from AI Image Generation for Robot Control,"When interacting with the world robots face a number of difficult questions,
having to make decisions when given under-specified tasks where they need to
make choices, often without clearly defined right and wrong answers. Humans, on
the other hand, can often rely on their knowledge and experience to fill in the
gaps. For example, the simple task of organizing newly bought produce into the
fridge involves deciding where to put each thing individually, how to arrange
them together meaningfully, e.g. putting related things together, all while
there is no clear right and wrong way to accomplish this task. We could encode
all this information on how to do such things explicitly into the robots'
knowledge base, but this can quickly become overwhelming, considering the
number of potential tasks and circumstances the robot could encounter. However,
images of the real world often implicitly encode answers to such questions and
can show which configurations of objects are meaningful or are usually used by
humans. An image of a full fridge can give a lot of information about how
things are usually arranged in relation to each other and the full fridge at
large. Modern generative systems are capable of generating plausible images of
the real world and can be conditioned on the environment in which the robot
operates. Here we investigate the idea of using the implicit knowledge about
the world of modern generative AI systems given by their ability to generate
convincing images of the real world to solve under-specified tasks.","['cs.CV', 'cs.RO']","['Jonas Krumme', 'Christoph Zetzsche']",2025-03-20,2025-03-20,When interacting with the world robots face a number of difficult questions having to make decisions when given under specified tasks where they need to make choices often without clearly defined right and wrong answers. Humans on the other hand can often rely on their knowledge and experience to fill in the gaps. For example the simple task of organizing newly bought produce into the fridge involves deciding where to put each thing individually how to arrange them together meaningfully e.g. putting related things together all while there is no clear right and wrong way to accomplish this task. We could encode all this information on how to do such things explicitly into the robots knowledge base but this can quickly become overwhelming considering the number of potential tasks and circumstances the robot could encounter. However images of the real world often implicitly encode answers to such questions and can show which configurations of objects are meaningful or are usually used by humans. An image of a full fridge can give a lot of information about how things are usually arranged in relation to each other and the full fridge at large. Modern generative systems are capable of generating plausible images of the real world and can be conditioned on the environment in which the robot operates. Here we investigate the idea of using the implicit knowledge about the world of modern generative AI systems given by their ability to generate convincing images of the real world to solve under specified tasks.,World Knowledge from AI Image Generation for Robot Control,"['world', 'fridge', 'images', 'images real', 'knowledge', 'real', 'real world', 'tasks', 'things', 'answers']",When interacting with the world robots face a number of difficult questions having to make decisions when given under specified tasks where they need to make choices often without clearly defined right and wrong answers.
2503.14939v1,VisNumBench: Evaluating Number Sense of Multimodal Large Language Models,"Can Multimodal Large Language Models (MLLMs) develop an intuitive number
sense similar to humans? Targeting this problem, we introduce Visual Number
Benchmark (VisNumBench) to evaluate the number sense abilities of MLLMs across
a wide range of visual numerical tasks. VisNumBench consists of about 1,900
multiple-choice question-answer pairs derived from both synthetic and
real-world visual data, covering seven visual numerical attributes and four
types of visual numerical estimation tasks. Our experiments on VisNumBench led
to the following key findings: (i) The 17 MLLMs we tested, including
open-source models such as Qwen2.5-VL and InternVL2.5, as well as proprietary
models like GPT-4o and Gemini 2.0 Flash, perform significantly below human
levels in number sense-related tasks. (ii) Multimodal mathematical models and
multimodal chain-of-thought (CoT) models did not exhibit significant
improvements in number sense abilities. (iii) Stronger MLLMs with larger
parameter sizes and broader general abilities demonstrate modest gains in
number sense abilities. We believe VisNumBench will serve as a valuable
resource for the research community, encouraging further advancements in
enhancing MLLMs' number sense abilities. All benchmark resources, including
code and datasets, will be publicly available at
https://wwwtttjjj.github.io/VisNumBench/.",['cs.CV'],"['Tengjin Weng', 'Jingyi Wang', 'Wenhao Jiang', 'Zhong Ming']",2025-03-19,2025-03-19,Can Multimodal Large Language Models MLLMs develop an intuitive number sense similar to humans Targeting this problem we introduce Visual Number Benchmark VisNumBench to evaluate the number sense abilities of MLLMs across a wide range of visual numerical tasks. VisNumBench consists of about 1 900 multiple choice question answer pairs derived from both synthetic and real world visual data covering seven visual numerical attributes and four types of visual numerical estimation tasks. Our experiments on VisNumBench led to the following key findings i The 17 MLLMs we tested including open source models such as Qwen2.5 VL and InternVL2.5 as well as proprietary models like GPT 4o and Gemini 2.0 Flash perform significantly below human levels in number sense related tasks. ii Multimodal mathematical models and multimodal chain of thought CoT models did not exhibit significant improvements in number sense abilities. iii Stronger MLLMs with larger parameter sizes and broader general abilities demonstrate modest gains in number sense abilities. We believe VisNumBench will serve as a valuable resource for the research community encouraging further advancements in enhancing MLLMs number sense abilities. All benchmark resources including code and datasets will be publicly available at https wwwtttjjj.github.io VisNumBench .,VisNumBench Evaluating Number Sense of Multimodal Large Language Models,"['number', 'number sense', 'sense', 'abilities', 'mllms', 'models', 'visnumbench', 'visual', 'sense abilities', 'multimodal']",Can Multimodal Large Language Models MLLMs develop an intuitive number sense similar to humans Targeting this problem we introduce Visual Number Benchmark VisNumBench to evaluate the number sense abilities of MLLMs across a wide range of visual numerical tasks.
2503.15029v1,DRoPE: Directional Rotary Position Embedding for Efficient Agent Interaction Modeling,"Accurate and efficient modeling of agent interactions is essential for
trajectory generation, the core of autonomous driving systems. Existing
methods, scene-centric, agent-centric, and query-centric frameworks, each
present distinct advantages and drawbacks, creating an impossible triangle
among accuracy, computational time, and memory efficiency. To break this
limitation, we propose Directional Rotary Position Embedding (DRoPE), a novel
adaptation of Rotary Position Embedding (RoPE), originally developed in natural
language processing. Unlike traditional relative position embedding (RPE),
which introduces significant space complexity, RoPE efficiently encodes
relative positions without explicitly increasing complexity but faces inherent
limitations in handling angular information due to periodicity. DRoPE overcomes
this limitation by introducing a uniform identity scalar into RoPE's 2D rotary
transformation, aligning rotation angles with realistic agent headings to
naturally encode relative angular information. We theoretically analyze DRoPE's
correctness and efficiency, demonstrating its capability to simultaneously
optimize trajectory generation accuracy, time complexity, and space complexity.
Empirical evaluations compared with various state-of-the-art trajectory
generation models, confirm DRoPE's good performance and significantly reduced
space complexity, indicating both theoretical soundness and practical
effectiveness. The video documentation is available at
https://drope-traj.github.io/.","['cs.RO', 'cs.CV']","['Jianbo Zhao', 'Taiyu Ban', 'Zhihao Liu', 'Hangning Zhou', 'Xiyang Wang', 'Qibin Zhou', 'Hailong Qin', 'Mu Yang', 'Lei Liu', 'Bin Li']",2025-03-19,2025-03-19,Accurate and efficient modeling of agent interactions is essential for trajectory generation the core of autonomous driving systems. Existing methods scene centric agent centric and query centric frameworks each present distinct advantages and drawbacks creating an impossible triangle among accuracy computational time and memory efficiency. To break this limitation we propose Directional Rotary Position Embedding DRoPE a novel adaptation of Rotary Position Embedding RoPE originally developed in natural language processing. Unlike traditional relative position embedding RPE which introduces significant space complexity RoPE efficiently encodes relative positions without explicitly increasing complexity but faces inherent limitations in handling angular information due to periodicity. DRoPE overcomes this limitation by introducing a uniform identity scalar into RoPE s 2D rotary transformation aligning rotation angles with realistic agent headings to naturally encode relative angular information. We theoretically analyze DRoPE s correctness and efficiency demonstrating its capability to simultaneously optimize trajectory generation accuracy time complexity and space complexity. Empirical evaluations compared with various state of the art trajectory generation models confirm DRoPE s good performance and significantly reduced space complexity indicating both theoretical soundness and practical effectiveness. The video documentation is available at https drope traj.github.io .,DRoPE Directional Rotary Position Embedding for Efficient Agent Interaction Modeling,"['complexity', 'drope', 'agent', 'centric', 'embedding', 'generation', 'position', 'position embedding', 'relative', 'rope']",Accurate and efficient modeling of agent interactions is essential for trajectory generation the core of autonomous driving systems.
2503.16112v1,PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming,"Traditional video compression algorithms exhibit significant quality
degradation at extremely low bitrates. Promptus emerges as a new paradigm for
video streaming, substantially cutting down the bandwidth essential for video
streaming. However, Promptus is computationally intensive and can not run in
real-time on mobile devices. This paper presents PromptMobile, an efficient
acceleration framework tailored for on-device Promptus. Specifically, we
propose (1) a two-stage efficient generation framework to reduce computational
cost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant
computations by 16.6\%, (3) system-level optimizations to further enhance
efficiency. The evaluations demonstrate that compared with the original
Promptus, PromptMobile achieves a 13.6x increase in image generation speed.
Compared with other streaming methods, PromptMobile achives an average LPIPS
improvement of 0.016 (compared with H.265), reducing 60\% of severely distorted
frames (compared to VQGAN).","['cs.NI', 'cs.AI', 'cs.MM']","['Liming Liu', 'Jiangkai Wu', 'Haoyang Wang', 'Peiheng Wang', 'Xinggong Zhang', 'Zongming Guo']",2025-03-20,2025-03-20,Traditional video compression algorithms exhibit significant quality degradation at extremely low bitrates. Promptus emerges as a new paradigm for video streaming substantially cutting down the bandwidth essential for video streaming. However Promptus is computationally intensive and can not run in real time on mobile devices. This paper presents PromptMobile an efficient acceleration framework tailored for on device Promptus. Specifically we propose 1 a two stage efficient generation framework to reduce computational cost by 8.1x 2 a fine grained inter frame caching to reduce redundant computations by 16.6 3 system level optimizations to further enhance efficiency. The evaluations demonstrate that compared with the original Promptus PromptMobile achieves a 13.6x increase in image generation speed. Compared with other streaming methods PromptMobile achives an average LPIPS improvement of 0.016 compared with H.265 reducing 60 of severely distorted frames compared to VQGAN .,PromptMobile Efficient Promptus for Low Bandwidth Mobile Video Streaming,"['compared', 'promptus', 'promptmobile', 'streaming', 'video', 'efficient', 'framework', 'generation', 'reduce', 'video streaming']",Traditional video compression algorithms exhibit significant quality degradation at extremely low bitrates.
2503.15979v1,Exploratory Study into Relations between Cognitive Distortions and Emotional Appraisals,"In recent years, there has been growing interest in studying cognitive
distortions and emotional appraisals from both computational and psychological
perspectives. Despite considerable similarities between emotional reappraisal
and cognitive reframing as emotion regulation techniques, these concepts have
largely been examined in isolation. This research explores the relationship
between cognitive distortions and emotional appraisal dimensions, examining
their potential connections and relevance for future interdisciplinary studies.
Under this pretext, we conduct an exploratory computational study, aimed at
investigating the relationship between cognitive distortion and emotional
appraisals. We show that the patterns of statistically significant
relationships between cognitive distortions and appraisal dimensions vary
across different distortion categories, giving rise to distinct appraisal
profiles for individual distortion classes. Additionally, we analyze the impact
of cognitive restructuring on appraisal dimensions, exemplifying the emotion
regulation aspect of cognitive restructuring.",['cs.CL'],"['Navneet Agarwal', 'Kairit Sirts']",2025-03-20,2025-03-20,In recent years there has been growing interest in studying cognitive distortions and emotional appraisals from both computational and psychological perspectives. Despite considerable similarities between emotional reappraisal and cognitive reframing as emotion regulation techniques these concepts have largely been examined in isolation. This research explores the relationship between cognitive distortions and emotional appraisal dimensions examining their potential connections and relevance for future interdisciplinary studies. Under this pretext we conduct an exploratory computational study aimed at investigating the relationship between cognitive distortion and emotional appraisals. We show that the patterns of statistically significant relationships between cognitive distortions and appraisal dimensions vary across different distortion categories giving rise to distinct appraisal profiles for individual distortion classes. Additionally we analyze the impact of cognitive restructuring on appraisal dimensions exemplifying the emotion regulation aspect of cognitive restructuring.,Exploratory Study into Relations between Cognitive Distortions and Emotional Appraisals,"['cognitive', 'appraisal', 'emotional', 'appraisal dimensions', 'cognitive distortions', 'dimensions', 'distortion', 'distortions', 'appraisals', 'cognitive restructuring']",In recent years there has been growing interest in studying cognitive distortions and emotional appraisals from both computational and psychological perspectives.
2503.17231v1,LoGoFair: Post-Processing for Local and Global Fairness in Federated Learning,"Federated learning (FL) has garnered considerable interest for its capability
to learn from decentralized data sources. Given the increasing application of
FL in decision-making scenarios, addressing fairness issues across different
sensitive groups (e.g., female, male) in FL is crucial. Current research often
focuses on facilitating fairness at each client's data (local fairness) or
within the entire dataset across all clients (global fairness). However,
existing approaches that focus exclusively on either local or global fairness
fail to address two key challenges: (\textbf{CH1}) Under statistical
heterogeneity, global fairness does not imply local fairness, and vice versa.
(\textbf{CH2}) Achieving fairness under model-agnostic setting. To tackle the
aforementioned challenges, this paper proposes a novel post-processing
framework for achieving both Local and Global Fairness in the FL context,
namely LoGoFair. To address CH1, LoGoFair endeavors to seek the Bayes optimal
classifier under local and global fairness constraints, which strikes the
optimal accuracy-fairness balance in the probabilistic sense. To address CH2,
LoGoFair employs a model-agnostic federated post-processing procedure that
enables clients to collaboratively optimize global fairness while ensuring
local fairness, thereby achieving the optimal fair classifier within FL.
Experimental results on three real-world datasets further illustrate the
effectiveness of the proposed LoGoFair framework.","['cs.LG', 'cs.DC']","['Li Zhang', 'Chaochao Chen', 'Zhongxuan Han', 'Qiyong Zhong', 'Xiaolin Zheng']",2025-03-21,2025-03-21,Federated learning FL has garnered considerable interest for its capability to learn from decentralized data sources. Given the increasing application of FL in decision making scenarios addressing fairness issues across different sensitive groups e.g. female male in FL is crucial. Current research often focuses on facilitating fairness at each client s data local fairness or within the entire dataset across all clients global fairness . However existing approaches that focus exclusively on either local or global fairness fail to address two key challenges textbf CH1 Under statistical heterogeneity global fairness does not imply local fairness and vice versa. textbf CH2 Achieving fairness under model agnostic setting. To tackle the aforementioned challenges this paper proposes a novel post processing framework for achieving both Local and Global Fairness in the FL context namely LoGoFair. To address CH1 LoGoFair endeavors to seek the Bayes optimal classifier under local and global fairness constraints which strikes the optimal accuracy fairness balance in the probabilistic sense. To address CH2 LoGoFair employs a model agnostic federated post processing procedure that enables clients to collaboratively optimize global fairness while ensuring local fairness thereby achieving the optimal fair classifier within FL. Experimental results on three real world datasets further illustrate the effectiveness of the proposed LoGoFair framework.,LoGoFair Post Processing for Local and Global Fairness in Federated Learning,"['fairness', 'global', 'global fairness', 'local', 'fl', 'logofair', 'achieving', 'address', 'local fairness', 'local global']",Federated learning FL has garnered considerable interest for its capability to learn from decentralized data sources.
2503.14827v1,MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models,"Multimodal foundation models (MMFMs) play a crucial role in various
applications, including autonomous driving, healthcare, and virtual assistants.
However, several studies have revealed vulnerabilities in these models, such as
generating unsafe content by text-to-image models. Existing benchmarks on
multimodal models either predominantly assess the helpfulness of these models,
or only focus on limited perspectives such as fairness and privacy. In this
paper, we present the first unified platform, MMDT (Multimodal DecodingTrust),
designed to provide a comprehensive safety and trustworthiness evaluation for
MMFMs. Our platform assesses models from multiple perspectives, including
safety, hallucination, fairness/bias, privacy, adversarial robustness, and
out-of-distribution (OOD) generalization. We have designed various evaluation
scenarios and red teaming algorithms under different tasks for each perspective
to generate challenging data, forming a high-quality benchmark. We evaluate a
range of multimodal models using MMDT, and our findings reveal a series of
vulnerabilities and areas for improvement across these perspectives. This work
introduces the first comprehensive and unique safety and trustworthiness
evaluation platform for MMFMs, paving the way for developing safer and more
reliable MMFMs and systems. Our platform and benchmark are available at
https://mmdecodingtrust.github.io/.","['cs.CL', 'cs.AI', 'cs.CR']","['Chejian Xu', 'Jiawei Zhang', 'Zhaorun Chen', 'Chulin Xie', 'Mintong Kang', 'Yujin Potter', 'Zhun Wang', 'Zhuowen Yuan', 'Alexander Xiong', 'Zidi Xiong', 'Chenhui Zhang', 'Lingzhi Yuan', 'Yi Zeng', 'Peiyang Xu', 'Chengquan Guo', 'Andy Zhou', 'Jeffrey Ziwei Tan', 'Xuandong Zhao', 'Francesco Pinto', 'Zhen Xiang', 'Yu Gai', 'Zinan Lin', 'Dan Hendrycks', 'Bo Li', 'Dawn Song']",2025-03-19,2025-03-19,Multimodal foundation models MMFMs play a crucial role in various applications including autonomous driving healthcare and virtual assistants. However several studies have revealed vulnerabilities in these models such as generating unsafe content by text to image models. Existing benchmarks on multimodal models either predominantly assess the helpfulness of these models or only focus on limited perspectives such as fairness and privacy. In this paper we present the first unified platform MMDT Multimodal DecodingTrust designed to provide a comprehensive safety and trustworthiness evaluation for MMFMs. Our platform assesses models from multiple perspectives including safety hallucination fairness bias privacy adversarial robustness and out of distribution OOD generalization. We have designed various evaluation scenarios and red teaming algorithms under different tasks for each perspective to generate challenging data forming a high quality benchmark. We evaluate a range of multimodal models using MMDT and our findings reveal a series of vulnerabilities and areas for improvement across these perspectives. This work introduces the first comprehensive and unique safety and trustworthiness evaluation platform for MMFMs paving the way for developing safer and more reliable MMFMs and systems. Our platform and benchmark are available at https mmdecodingtrust.github.io .,MMDT Decoding the Trustworthiness and Safety of Multimodal Foundation Models,"['models', 'mmfms', 'multimodal', 'platform', 'evaluation', 'perspectives', 'safety', 'benchmark', 'comprehensive', 'designed']",Multimodal foundation models MMFMs play a crucial role in various applications including autonomous driving healthcare and virtual assistants.
2503.14998v1,TGV: Tabular Data-Guided Learning of Visual Cardiac Representations,"Contrastive learning methods in computer vision typically rely on different
views of the same image to form pairs. However, in medical imaging, we often
seek to compare entire patients with different phenotypes rather than just
multiple augmentations of one scan. We propose harnessing clinically relevant
tabular data to identify distinct patient phenotypes and form more meaningful
pairs in a contrastive learning framework. Our method uses tabular attributes
to guide the training of visual representations, without requiring a joint
embedding space. We demonstrate its strength using short-axis cardiac MR images
and clinical attributes from the UK Biobank, where tabular data helps to more
effectively distinguish between patient subgroups. Evaluation on downstream
tasks, including fine-tuning and zero-shot prediction of cardiovascular artery
diseases and cardiac phenotypes, shows that incorporating tabular data yields
stronger visual representations than conventional methods that rely solely on
image augmentations or combined image-tabular embeddings. Furthermore, we
demonstrate that image encoders trained with tabular guidance are capable of
embedding demographic information in their representations, allowing them to
use insights from tabular data for unimodal predictions, making them
well-suited to real-world medical settings where extensive clinical annotations
may not be routinely available at inference time. The code will be available on
GitHub.",['cs.CV'],"['Marta Hasny', 'Maxime Di Folco', 'Keno Bressem', 'Julia Schnabel']",2025-03-19,2025-03-19,Contrastive learning methods in computer vision typically rely on different views of the same image to form pairs. However in medical imaging we often seek to compare entire patients with different phenotypes rather than just multiple augmentations of one scan. We propose harnessing clinically relevant tabular data to identify distinct patient phenotypes and form more meaningful pairs in a contrastive learning framework. Our method uses tabular attributes to guide the training of visual representations without requiring a joint embedding space. We demonstrate its strength using short axis cardiac MR images and clinical attributes from the UK Biobank where tabular data helps to more effectively distinguish between patient subgroups. Evaluation on downstream tasks including fine tuning and zero shot prediction of cardiovascular artery diseases and cardiac phenotypes shows that incorporating tabular data yields stronger visual representations than conventional methods that rely solely on image augmentations or combined image tabular embeddings. Furthermore we demonstrate that image encoders trained with tabular guidance are capable of embedding demographic information in their representations allowing them to use insights from tabular data for unimodal predictions making them well suited to real world medical settings where extensive clinical annotations may not be routinely available at inference time. The code will be available on GitHub.,TGV Tabular Data Guided Learning of Visual Cardiac Representations,"['tabular', 'data', 'image', 'tabular data', 'phenotypes', 'representations', 'attributes', 'augmentations', 'available', 'cardiac']",Contrastive learning methods in computer vision typically rely on different views of the same image to form pairs.
2503.17195v1,TreeSynth: Synthesizing Diverse Data from Scratch via Tree-Guided Subspace Partitioning,"Model customization requires high-quality and diverse datasets, but acquiring
such data remains challenging and costly. Although large language models (LLMs)
can synthesize training data, current approaches are constrained by limited
seed data, model bias and insufficient control over the generation process,
resulting in limited diversity and biased distribution with the increase of
data scales. To tackle this challenge, we present TreeSynth, a tree-guided
subspace-based data synthesis framework that recursively partitions the entire
data space into hierar-chical subspaces, enabling comprehensive and diverse
scaling of data synthesis. Briefly, given a task-specific description, we
construct a data space partitioning tree by iteratively executing criteria
determination and subspace coverage steps. This hierarchically divides the
whole space (i.e., root node) into mutually exclusive and complementary atomic
subspaces (i.e., leaf nodes). By collecting synthesized data according to the
attributes of each leaf node, we obtain a diverse dataset that fully covers the
data space. Empirically, our extensive experiments demonstrate that TreeSynth
surpasses both human-designed datasets and the state-of-the-art data synthesis
baselines, achieving maximum improvements of 45.2% in data diversity and 17.6%
in downstream task performance across various models and tasks. Hopefully,
TreeSynth provides a scalable solution to synthesize diverse and comprehensive
datasets from scratch without human intervention.","['cs.LG', 'cs.AI']","['Sheng Wang', 'Pengan Chen', 'Jingqi Zhou', 'Qintong Li', 'Jingwei Dong', 'Jiahui Gao', 'Boyang Xue', 'Jiyue Jiang', 'Lingpeng Kong', 'Chuan Wu']",2025-03-21,2025-03-21,Model customization requires high quality and diverse datasets but acquiring such data remains challenging and costly. Although large language models LLMs can synthesize training data current approaches are constrained by limited seed data model bias and insufficient control over the generation process resulting in limited diversity and biased distribution with the increase of data scales. To tackle this challenge we present TreeSynth a tree guided subspace based data synthesis framework that recursively partitions the entire data space into hierar chical subspaces enabling comprehensive and diverse scaling of data synthesis. Briefly given a task specific description we construct a data space partitioning tree by iteratively executing criteria determination and subspace coverage steps. This hierarchically divides the whole space i.e. root node into mutually exclusive and complementary atomic subspaces i.e. leaf nodes . By collecting synthesized data according to the attributes of each leaf node we obtain a diverse dataset that fully covers the data space. Empirically our extensive experiments demonstrate that TreeSynth surpasses both human designed datasets and the state of the art data synthesis baselines achieving maximum improvements of 45.2 in data diversity and 17.6 in downstream task performance across various models and tasks. Hopefully TreeSynth provides a scalable solution to synthesize diverse and comprehensive datasets from scratch without human intervention.,TreeSynth Synthesizing Diverse Data from Scratch via Tree Guided Subspace Partitioning,"['data', 'diverse', 'space', 'data space', 'data synthesis', 'datasets', 'synthesis', 'treesynth', 'comprehensive', 'diversity']",Model customization requires high quality and diverse datasets but acquiring such data remains challenging and costly.
2503.16581v1,Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models,"Accurate and contextually faithful responses are critical when applying large
language models (LLMs) to sensitive and domain-specific tasks, such as
answering queries related to quranic studies. General-purpose LLMs often
struggle with hallucinations, where generated responses deviate from
authoritative sources, raising concerns about their reliability in religious
contexts. This challenge highlights the need for systems that can integrate
domain-specific knowledge while maintaining response accuracy, relevance, and
faithfulness. In this study, we investigate 13 open-source LLMs categorized
into large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b,
Llama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented
Generation (RAG) is used to make up for the problems that come with using
separate models. This research utilizes a descriptive dataset of Quranic surahs
including the meanings, historical context, and qualities of the 114 surahs,
allowing the model to gather relevant knowledge before responding. The models
are evaluated using three key metrics set by human evaluators: context
relevance, answer faithfulness, and answer relevance. The findings reveal that
large models consistently outperform smaller models in capturing query
semantics and producing accurate, contextually grounded responses. The
Llama3.2:3b model, even though it is considered small, does very well on
faithfulness (4.619) and relevance (4.857), showing the promise of smaller
architectures that have been well optimized. This article examines the
trade-offs between model size, computational efficiency, and response quality
while using LLMs in domain-specific applications.","['cs.CL', 'cs.AI', 'cs.LG']","['Zahra Khalila', 'Arbi Haza Nasution', 'Winda Monika', 'Aytug Onan', 'Yohei Murakami', 'Yasir Bin Ismail Radi', 'Noor Mohammad Osmani']",2025-03-20,2025-03-20,Accurate and contextually faithful responses are critical when applying large language models LLMs to sensitive and domain specific tasks such as answering queries related to quranic studies. General purpose LLMs often struggle with hallucinations where generated responses deviate from authoritative sources raising concerns about their reliability in religious contexts. This challenge highlights the need for systems that can integrate domain specific knowledge while maintaining response accuracy relevance and faithfulness. In this study we investigate 13 open source LLMs categorized into large e.g. Llama3 70b Gemma2 27b QwQ 32b medium e.g. Gemma2 9b Llama3 8b and small e.g. Llama3.2 3b Phi3 3.8b . A Retrieval Augmented Generation RAG is used to make up for the problems that come with using separate models. This research utilizes a descriptive dataset of Quranic surahs including the meanings historical context and qualities of the 114 surahs allowing the model to gather relevant knowledge before responding. The models are evaluated using three key metrics set by human evaluators context relevance answer faithfulness and answer relevance. The findings reveal that large models consistently outperform smaller models in capturing query semantics and producing accurate contextually grounded responses. The Llama3.2 3b model even though it is considered small does very well on faithfulness 4.619 and relevance 4.857 showing the promise of smaller architectures that have been well optimized. This article examines the trade offs between model size computational efficiency and response quality while using LLMs in domain specific applications.,Investigating Retrieval Augmented Generation in Quranic Studies A Study of 13 Open Source Large Language Models,"['models', 'llama3', 'llms', 'relevance', 'domain', 'domain specific', 'faithfulness', 'large', 'model', 'responses']",Accurate and contextually faithful responses are critical when applying large language models LLMs to sensitive and domain specific tasks such as answering queries related to quranic studies.
2503.14863v1,Temporal-Consistent Video Restoration with Pre-trained Diffusion Models,"Video restoration (VR) aims to recover high-quality videos from degraded
ones. Although recent zero-shot VR methods using pre-trained diffusion models
(DMs) show good promise, they suffer from approximation errors during reverse
diffusion and insufficient temporal consistency. Moreover, dealing with 3D
video data, VR is inherently computationally intensive. In this paper, we
advocate viewing the reverse process in DMs as a function and present a novel
Maximum a Posterior (MAP) framework that directly parameterizes video frames in
the seed space of DMs, eliminating approximation errors. We also introduce
strategies to promote bilevel temporal consistency: semantic consistency by
leveraging clustering structures in the seed space, and pixel-level consistency
by progressive warping with optical flow refinements. Extensive experiments on
multiple virtual reality tasks demonstrate superior visual quality and temporal
consistency achieved by our method compared to the state-of-the-art.",['cs.CV'],"['Hengkang Wang', 'Yang Liu', 'Huidong Liu', 'Chien-Chih Wang', 'Yanhui Guo', 'Hongdong Li', 'Bryan Wang', 'Ju Sun']",2025-03-19,2025-03-19,Video restoration VR aims to recover high quality videos from degraded ones. Although recent zero shot VR methods using pre trained diffusion models DMs show good promise they suffer from approximation errors during reverse diffusion and insufficient temporal consistency. Moreover dealing with 3D video data VR is inherently computationally intensive. In this paper we advocate viewing the reverse process in DMs as a function and present a novel Maximum a Posterior MAP framework that directly parameterizes video frames in the seed space of DMs eliminating approximation errors. We also introduce strategies to promote bilevel temporal consistency semantic consistency by leveraging clustering structures in the seed space and pixel level consistency by progressive warping with optical flow refinements. Extensive experiments on multiple virtual reality tasks demonstrate superior visual quality and temporal consistency achieved by our method compared to the state of the art.,Temporal Consistent Video Restoration with Pre trained Diffusion Models,"['consistency', 'dms', 'temporal', 'temporal consistency', 'video', 'vr', 'approximation', 'approximation errors', 'diffusion', 'errors']",Video restoration VR aims to recover high quality videos from degraded ones.
2503.16718v1,CAARMA: Class Augmentation with Adversarial Mixup Regularization,"Speaker verification is a typical zero-shot learning task, where inference of
unseen classes is performed by comparing embeddings of test instances to known
examples. The models performing inference must hence naturally generate
embeddings that cluster same-class instances compactly, while maintaining
separation across classes. In order to learn to do so, they are typically
trained on a large number of classes (speakers), often using specialized
losses. However real-world speaker datasets often lack the class diversity
needed to effectively learn this in a generalizable manner. We introduce
CAARMA, a class augmentation framework that addresses this problem by
generating synthetic classes through data mixing in the embedding space,
expanding the number of training classes. To ensure the authenticity of the
synthetic classes we adopt a novel adversarial refinement mechanism that
minimizes categorical distinctions between synthetic and real classes. We
evaluate CAARMA on multiple speaker verification tasks, as well as other
representative zero-shot comparison-based speech analysis tasks and obtain
consistent improvements: our framework demonstrates a significant improvement
of 8\% over all baseline models. Code for CAARMA will be released.","['cs.SD', 'cs.CL', 'cs.LG']","['Massa Baali', 'Xiang Li', 'Hao Chen', 'Rita Singh', 'Bhiksha Raj']",2025-03-20,2025-03-20,Speaker verification is a typical zero shot learning task where inference of unseen classes is performed by comparing embeddings of test instances to known examples. The models performing inference must hence naturally generate embeddings that cluster same class instances compactly while maintaining separation across classes. In order to learn to do so they are typically trained on a large number of classes speakers often using specialized losses. However real world speaker datasets often lack the class diversity needed to effectively learn this in a generalizable manner. We introduce CAARMA a class augmentation framework that addresses this problem by generating synthetic classes through data mixing in the embedding space expanding the number of training classes. To ensure the authenticity of the synthetic classes we adopt a novel adversarial refinement mechanism that minimizes categorical distinctions between synthetic and real classes. We evaluate CAARMA on multiple speaker verification tasks as well as other representative zero shot comparison based speech analysis tasks and obtain consistent improvements our framework demonstrates a significant improvement of 8 over all baseline models. Code for CAARMA will be released.,CAARMA Class Augmentation with Adversarial Mixup Regularization,"['classes', 'caarma', 'class', 'speaker', 'synthetic', 'embeddings', 'framework', 'inference', 'instances', 'learn']",Speaker verification is a typical zero shot learning task where inference of unseen classes is performed by comparing embeddings of test instances to known examples.
2503.14674v1,Elevating Visual Question Answering through Implicitly Learned Reasoning Pathways in LVLMs,"Large Vision-Language Models (LVLMs) have shown remarkable progress in
various multimodal tasks, yet they often struggle with complex visual reasoning
that requires multi-step inference. To address this limitation, we propose
MF-SQ-LLaVA, a novel approach that enhances LVLMs by enabling implicit
self-questioning through end-to-end training. Our method involves augmenting
visual question answering datasets with reasoning chains consisting of
sub-question and answer pairs, and training the LVLM with a multi-task loss
that encourages the generation and answering of these intermediate steps, as
well as the prediction of the final answer. We conduct extensive experiments on
the ScienceQA and VQAv2 datasets, demonstrating that MF-SQ-LLaVA significantly
outperforms existing state-of-the-art models, including the base LLaVA and the
original SQ-LLaVA. Ablation studies further validate the contribution of each
component of our approach, and human evaluation confirms the improved accuracy
and coherence of the reasoning process enabled by our method.",['cs.CV'],"['Liu Jing', 'Amirul Rahman']",2025-03-18,2025-03-18,Large Vision Language Models LVLMs have shown remarkable progress in various multimodal tasks yet they often struggle with complex visual reasoning that requires multi step inference. To address this limitation we propose MF SQ LLaVA a novel approach that enhances LVLMs by enabling implicit self questioning through end to end training. Our method involves augmenting visual question answering datasets with reasoning chains consisting of sub question and answer pairs and training the LVLM with a multi task loss that encourages the generation and answering of these intermediate steps as well as the prediction of the final answer. We conduct extensive experiments on the ScienceQA and VQAv2 datasets demonstrating that MF SQ LLaVA significantly outperforms existing state of the art models including the base LLaVA and the original SQ LLaVA. Ablation studies further validate the contribution of each component of our approach and human evaluation confirms the improved accuracy and coherence of the reasoning process enabled by our method.,Elevating Visual Question Answering through Implicitly Learned Reasoning Pathways in LVLMs,"['llava', 'reasoning', 'sq', 'sq llava', 'answer', 'answering', 'approach', 'datasets', 'end', 'lvlms']",Large Vision Language Models LVLMs have shown remarkable progress in various multimodal tasks yet they often struggle with complex visual reasoning that requires multi step inference.
2503.15182v1,Foundation models may exhibit staged progression in novel CBRN threat disclosure,"The extent to which foundation models can disclose novel chemical,
biological, radiation, and nuclear (CBRN) threats to expert users is unclear
due to a lack of test cases. I leveraged the unique opportunity presented by an
upcoming publication describing a novel catastrophic biothreat - ""Technical
Report on Mirror Bacteria: Feasibility and Risks"" - to conduct a small
controlled study before it became public. Graduate-trained biologists tasked
with predicting the consequences of releasing mirror E. coli showed no
significant differences in rubric-graded accuracy using Claude Sonnet 3.5 new
(n=10) or web search only (n=2); both groups scored comparably to a web
baseline (28 and 43 versus 36). However, Sonnet reasoned correctly when
prompted by a report author, but a smaller model, Haiku 3.5, failed even with
author guidance (80 versus 5). These results suggest distinct stages of model
capability: Haiku is unable to reason about mirror life even with threat-aware
expert guidance (Stage 1), while Sonnet correctly reasons only with
threat-aware prompting (Stage 2). Continued advances may allow future models to
disclose novel CBRN threats to naive experts (Stage 3) or unskilled users
(Stage 4). While mirror life represents only one case study, monitoring new
models' ability to reason about privately known threats may allow protective
measures to be implemented before widespread disclosure.","['cs.CY', 'cs.AI', 'q-bio.OT']",['Kevin M Esvelt'],2025-03-19,2025-03-19,The extent to which foundation models can disclose novel chemical biological radiation and nuclear CBRN threats to expert users is unclear due to a lack of test cases. I leveraged the unique opportunity presented by an upcoming publication describing a novel catastrophic biothreat Technical Report on Mirror Bacteria Feasibility and Risks to conduct a small controlled study before it became public. Graduate trained biologists tasked with predicting the consequences of releasing mirror E. coli showed no significant differences in rubric graded accuracy using Claude Sonnet 3.5 new n 10 or web search only n 2 both groups scored comparably to a web baseline 28 and 43 versus 36 . However Sonnet reasoned correctly when prompted by a report author but a smaller model Haiku 3.5 failed even with author guidance 80 versus 5 . These results suggest distinct stages of model capability Haiku is unable to reason about mirror life even with threat aware expert guidance Stage 1 while Sonnet correctly reasons only with threat aware prompting Stage 2 . Continued advances may allow future models to disclose novel CBRN threats to naive experts Stage 3 or unskilled users Stage 4 . While mirror life represents only one case study monitoring new models ability to reason about privately known threats may allow protective measures to be implemented before widespread disclosure.,Foundation models may exhibit staged progression in novel CBRN threat disclosure,"['mirror', 'stage', 'models', 'novel', 'sonnet', 'threats', 'allow', 'author', 'aware', 'cbrn']",The extent to which foundation models can disclose novel chemical biological radiation and nuclear CBRN threats to expert users is unclear due to a lack of test cases.
2503.14428v1,MagicComp: Training-free Dual-Phase Refinement for Compositional Video Generation,"Text-to-video (T2V) generation has made significant strides with diffusion
models. However, existing methods still struggle with accurately binding
attributes, determining spatial relationships, and capturing complex action
interactions between multiple subjects. To address these limitations, we
propose MagicComp, a training-free method that enhances compositional T2V
generation through dual-phase refinement. Specifically, (1) During the
Conditioning Stage: We introduce the Semantic Anchor Disambiguation to
reinforces subject-specific semantics and resolve inter-subject ambiguity by
progressively injecting the directional vectors of semantic anchors into
original text embedding; (2) During the Denoising Stage: We propose Dynamic
Layout Fusion Attention, which integrates grounding priors and model-adaptive
spatial perception to flexibly bind subjects to their spatiotemporal regions
through masked attention modulation. Furthermore, MagicComp is a model-agnostic
and versatile approach, which can be seamlessly integrated into existing T2V
architectures. Extensive experiments on T2V-CompBench and VBench demonstrate
that MagicComp outperforms state-of-the-art methods, highlighting its potential
for applications such as complex prompt-based and trajectory-controllable video
generation. Project page: https://hong-yu-zhang.github.io/MagicComp-Page/.","['cs.CV', 'cs.AI']","['Hongyu Zhang', 'Yufan Deng', 'Shenghai Yuan', 'Peng Jin', 'Zesen Cheng', 'Yian Zhao', 'Chang Liu', 'Jie Chen']",2025-03-18,2025-03-18,Text to video T2V generation has made significant strides with diffusion models. However existing methods still struggle with accurately binding attributes determining spatial relationships and capturing complex action interactions between multiple subjects. To address these limitations we propose MagicComp a training free method that enhances compositional T2V generation through dual phase refinement. Specifically 1 During the Conditioning Stage We introduce the Semantic Anchor Disambiguation to reinforces subject specific semantics and resolve inter subject ambiguity by progressively injecting the directional vectors of semantic anchors into original text embedding 2 During the Denoising Stage We propose Dynamic Layout Fusion Attention which integrates grounding priors and model adaptive spatial perception to flexibly bind subjects to their spatiotemporal regions through masked attention modulation. Furthermore MagicComp is a model agnostic and versatile approach which can be seamlessly integrated into existing T2V architectures. Extensive experiments on T2V CompBench and VBench demonstrate that MagicComp outperforms state of the art methods highlighting its potential for applications such as complex prompt based and trajectory controllable video generation. Project page https hong yu zhang.github.io MagicComp Page .,MagicComp Training free Dual Phase Refinement for Compositional Video Generation,"['magiccomp', 't2v', 'generation', 'attention', 'complex', 'existing', 'methods', 'model', 'page', 'propose']",Text to video T2V generation has made significant strides with diffusion models.
2503.15996v1,Animating the Uncaptured: Humanoid Mesh Animation with Video Diffusion Models,"Animation of humanoid characters is essential in various graphics
applications, but requires significant time and cost to create realistic
animations. We propose an approach to synthesize 4D animated sequences of input
static 3D humanoid meshes, leveraging strong generalized motion priors from
generative video models -- as such video models contain powerful motion
information covering a wide variety of human motions. From an input static 3D
humanoid mesh and a text prompt describing the desired animation, we synthesize
a corresponding video conditioned on a rendered image of the 3D mesh. We then
employ an underlying SMPL representation to animate the corresponding 3D mesh
according to the video-generated motion, based on our motion optimization. This
enables a cost-effective and accessible solution to enable the synthesis of
diverse and realistic 4D animations.","['cs.GR', 'cs.CV']","['Marc Benedí San Millán', 'Angela Dai', 'Matthias Nießner']",2025-03-20,2025-03-20,Animation of humanoid characters is essential in various graphics applications but requires significant time and cost to create realistic animations. We propose an approach to synthesize 4D animated sequences of input static 3D humanoid meshes leveraging strong generalized motion priors from generative video models as such video models contain powerful motion information covering a wide variety of human motions. From an input static 3D humanoid mesh and a text prompt describing the desired animation we synthesize a corresponding video conditioned on a rendered image of the 3D mesh. We then employ an underlying SMPL representation to animate the corresponding 3D mesh according to the video generated motion based on our motion optimization. This enables a cost effective and accessible solution to enable the synthesis of diverse and realistic 4D animations.,Animating the Uncaptured Humanoid Mesh Animation with Video Diffusion Models,"['3d', 'motion', 'video', 'humanoid', 'mesh', '3d humanoid', '3d mesh', '4d', 'animation', 'animations']",Animation of humanoid characters is essential in various graphics applications but requires significant time and cost to create realistic animations.
2503.15793v1,DNA Bench: When Silence is Smarter -- Benchmarking Over-Reasoning in Reasoning LLMs,"Test-time scaling has significantly improved large language model
performance, enabling deeper reasoning to solve complex problems. However, this
increased reasoning capability also leads to excessive token generation and
unnecessary problem-solving attempts. We introduce Don\'t Answer Bench (DNA
Bench), a new benchmark designed to evaluate LLMs ability to robustly
understand the tricky reasoning triggers and avoiding unnecessary generation.
DNA Bench consists of 150 adversarially designed prompts that are easy for
humans to understand and respond to, but surprisingly not for many of the
recent prominent LLMs. DNA Bench tests models abilities across different
capabilities, such as instruction adherence, hallucination avoidance,
redundancy filtering, and unanswerable question recognition. We evaluate
reasoning LLMs (RLMs), including DeepSeek-R1, OpenAI O3-mini, Claude-3.7-sonnet
and compare them against a powerful non-reasoning model, e.g., GPT-4o. Our
experiments reveal that RLMs generate up to 70x more tokens than necessary,
often failing at tasks that simpler non-reasoning models handle efficiently
with higher accuracy. Our findings underscore the need for more effective
training and inference strategies in RLMs.",['cs.LG'],"['Masoud Hashemi', 'Oluwanifemi Bamgbose', 'Sathwik Tejaswi Madhusudhan', 'Jishnu Sethumadhavan Nair', 'Aman Tiwari', 'Vikas Yadav']",2025-03-20,2025-03-20,Test time scaling has significantly improved large language model performance enabling deeper reasoning to solve complex problems. However this increased reasoning capability also leads to excessive token generation and unnecessary problem solving attempts. We introduce Don t Answer Bench DNA Bench a new benchmark designed to evaluate LLMs ability to robustly understand the tricky reasoning triggers and avoiding unnecessary generation. DNA Bench consists of 150 adversarially designed prompts that are easy for humans to understand and respond to but surprisingly not for many of the recent prominent LLMs. DNA Bench tests models abilities across different capabilities such as instruction adherence hallucination avoidance redundancy filtering and unanswerable question recognition. We evaluate reasoning LLMs RLMs including DeepSeek R1 OpenAI O3 mini Claude 3.7 sonnet and compare them against a powerful non reasoning model e.g. GPT 4o. Our experiments reveal that RLMs generate up to 70x more tokens than necessary often failing at tasks that simpler non reasoning models handle efficiently with higher accuracy. Our findings underscore the need for more effective training and inference strategies in RLMs.,DNA Bench When Silence is Smarter Benchmarking Over Reasoning in Reasoning LLMs,"['reasoning', 'bench', 'dna', 'dna bench', 'llms', 'rlms', 'designed', 'evaluate', 'generation', 'model']",Test time scaling has significantly improved large language model performance enabling deeper reasoning to solve complex problems.
2503.14421v1,ExDDV: A New Dataset for Explainable Deepfake Detection in Video,"The ever growing realism and quality of generated videos makes it
increasingly harder for humans to spot deepfake content, who need to rely more
and more on automatic deepfake detectors. However, deepfake detectors are also
prone to errors, and their decisions are not explainable, leaving humans
vulnerable to deepfake-based fraud and misinformation. To this end, we
introduce ExDDV, the first dataset and benchmark for Explainable Deepfake
Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that
are manually annotated with text descriptions (to explain the artifacts) and
clicks (to point out the artifacts). We evaluate a number of vision-language
models on ExDDV, performing experiments with various fine-tuning and in-context
learning strategies. Our results show that text and click supervision are both
required to develop robust explainable models for deepfake videos, which are
able to localize and describe the observed artifacts. Our novel dataset and
code to reproduce the results are available at
https://github.com/vladhondru25/ExDDV.","['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM']","['Vlad Hondru', 'Eduard Hogea', 'Darian Onchis', 'Radu Tudor Ionescu']",2025-03-18,2025-03-18,The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content who need to rely more and more on automatic deepfake detectors. However deepfake detectors are also prone to errors and their decisions are not explainable leaving humans vulnerable to deepfake based fraud and misinformation. To this end we introduce ExDDV the first dataset and benchmark for Explainable Deepfake Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that are manually annotated with text descriptions to explain the artifacts and clicks to point out the artifacts . We evaluate a number of vision language models on ExDDV performing experiments with various fine tuning and in context learning strategies. Our results show that text and click supervision are both required to develop robust explainable models for deepfake videos which are able to localize and describe the observed artifacts. Our novel dataset and code to reproduce the results are available at https github.com vladhondru25 ExDDV.,ExDDV A New Dataset for Explainable Deepfake Detection in Video,"['deepfake', 'exddv', 'artifacts', 'explainable', 'videos', 'dataset', 'deepfake detectors', 'deepfake videos', 'detectors', 'humans']",The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content who need to rely more and more on automatic deepfake detectors.
2503.14718v1,Second language Korean Universal Dependency treebank v1.2: Focus on data augmentation and annotation scheme refinement,"We expand the second language (L2) Korean Universal Dependencies (UD)
treebank with 5,454 manually annotated sentences. The annotation guidelines are
also revised to better align with the UD framework. Using this enhanced
treebank, we fine-tune three Korean language models and evaluate their
performance on in-domain and out-of-domain L2-Korean datasets. The results show
that fine-tuning significantly improves their performance across various
metrics, thus highlighting the importance of using well-tailored L2 datasets
for fine-tuning first-language-based, general-purpose language models for the
morphosyntactic analysis of L2 data.",['cs.CL'],"['Hakyung Sung', 'Gyu-Ho Shin']",2025-03-18,2025-03-18,We expand the second language L2 Korean Universal Dependencies UD treebank with 5 454 manually annotated sentences. The annotation guidelines are also revised to better align with the UD framework. Using this enhanced treebank we fine tune three Korean language models and evaluate their performance on in domain and out of domain L2 Korean datasets. The results show that fine tuning significantly improves their performance across various metrics thus highlighting the importance of using well tailored L2 datasets for fine tuning first language based general purpose language models for the morphosyntactic analysis of L2 data.,Second language Korean Universal Dependency treebank v1.2 Focus on data augmentation and annotation scheme refinement,"['l2', 'language', 'fine', 'korean', 'datasets', 'domain', 'fine tuning', 'l2 korean', 'language models', 'models']",We expand the second language L2 Korean Universal Dependencies UD treebank with 5 454 manually annotated sentences.
2503.15561v1,Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization,"We introduce a simultaneous and meshfree topology optimization (TO) framework
based on physics-informed Gaussian processes (GPs). Our framework endows all
design and state variables via GP priors which have a shared, multi-output mean
function that is parametrized via a customized deep neural network (DNN). The
parameters of this mean function are estimated by minimizing a multi-component
loss function that depends on the performance metric, design constraints, and
the residuals on the state equations. Our TO approach yields well-defined
material interfaces and has a built-in continuation nature that promotes global
optimality. Other unique features of our approach include (1) its customized
DNN which, unlike fully connected feed-forward DNNs, has a localized learning
capacity that enables capturing intricate topologies and reducing residuals in
high gradient fields, (2) its loss function that leverages localized weights to
promote solution accuracy around interfaces, and (3) its use of curriculum
training to avoid local optimality.To demonstrate the power of our framework,
we validate it against commercial TO package COMSOL on three problems involving
dissipated power minimization in Stokes flow.",['cs.LG'],"['Amin Yousefpour', 'Shirin Hosseinmardi', 'Xiangyu Sun', 'Ramin Bostanabad']",2025-03-18,2025-03-18,We introduce a simultaneous and meshfree topology optimization TO framework based on physics informed Gaussian processes GPs . Our framework endows all design and state variables via GP priors which have a shared multi output mean function that is parametrized via a customized deep neural network DNN . The parameters of this mean function are estimated by minimizing a multi component loss function that depends on the performance metric design constraints and the residuals on the state equations. Our TO approach yields well defined material interfaces and has a built in continuation nature that promotes global optimality. Other unique features of our approach include 1 its customized DNN which unlike fully connected feed forward DNNs has a localized learning capacity that enables capturing intricate topologies and reducing residuals in high gradient fields 2 its loss function that leverages localized weights to promote solution accuracy around interfaces and 3 its use of curriculum training to avoid local optimality.To demonstrate the power of our framework we validate it against commercial TO package COMSOL on three problems involving dissipated power minimization in Stokes flow.,Localized Physics informed Gaussian Processes with Curriculum Training for Topology Optimization,"['function', 'framework', 'approach', 'customized', 'design', 'dnn', 'interfaces', 'localized', 'loss', 'loss function']",We introduce a simultaneous and meshfree topology optimization TO framework based on physics informed Gaussian processes GPs .
2503.15107v1,Interpretability of Graph Neural Networks to Assert Effects of Global Change Drivers on Ecological Networks,"Pollinators play a crucial role for plant reproduction, either in natural
ecosystem or in human-modified landscape. Global change drivers,including
climate change or land use modifications, can alter the plant-pollinator
interactions. To assert the potential influence of global change drivers on
pollination, large-scale interactions, climate and land use data are required.
While recent machine learning methods, such as graph neural networks (GNNs),
allow the analysis of such datasets, interpreting their results can be
challenging. We explore existing methods for interpreting GNNs in order to
highlight the effects of various environmental covariates on pollination
network connectivity. A large simulation study is performed to confirm whether
these methods can detect the interactive effect between a covariate and a genus
of plant on connectivity, and whether the application of debiasing techniques
influences the estimation of these effects. An application on the Spipoll
dataset, with and without accounting for sampling effects, highlights the
potential impact of land use on network connectivity and shows that accounting
for sampling effects partially alters the estimation of these effects.","['stat.ML', 'cs.LG']","['Emre Anakok', 'Pierre Barbillon', 'Colin Fontaine', 'Elisa Thebault']",2025-03-19,2025-03-19,Pollinators play a crucial role for plant reproduction either in natural ecosystem or in human modified landscape. Global change drivers including climate change or land use modifications can alter the plant pollinator interactions. To assert the potential influence of global change drivers on pollination large scale interactions climate and land use data are required. While recent machine learning methods such as graph neural networks GNNs allow the analysis of such datasets interpreting their results can be challenging. We explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity. A large simulation study is performed to confirm whether these methods can detect the interactive effect between a covariate and a genus of plant on connectivity and whether the application of debiasing techniques influences the estimation of these effects. An application on the Spipoll dataset with and without accounting for sampling effects highlights the potential impact of land use on network connectivity and shows that accounting for sampling effects partially alters the estimation of these effects.,Interpretability of Graph Neural Networks to Assert Effects of Global Change Drivers on Ecological Networks,"['effects', 'change', 'connectivity', 'land', 'land use', 'methods', 'plant', 'use', 'accounting', 'accounting sampling']",Pollinators play a crucial role for plant reproduction either in natural ecosystem or in human modified landscape.
2503.15653v1,Transport-Related Surface Detection with Machine Learning: Analyzing Temporal Trends in Madrid and Vienna,"This study explores the integration of machine learning into urban aerial
image analysis, with a focus on identifying infrastructure surfaces for cars
and pedestrians and analyzing historical trends. It emphasizes the transition
from convolutional architectures to transformer-based pre-trained models,
underscoring their potential in global geospatial analysis. A workflow is
presented for automatically generating geospatial datasets, enabling the
creation of semantic segmentation datasets from various sources, including
WMS/WMTS links, vectorial cartography, and OpenStreetMap (OSM) overpass-turbo
requests. The developed code allows a fast dataset generation process for
training machine learning models using openly available data without manual
labelling. Using aerial imagery and vectorial data from the respective
geographical offices of Madrid and Vienna, two datasets were generated for car
and pedestrian surface detection. A transformer-based model was trained and
evaluated for each city, demonstrating good accuracy values. The historical
trend analysis involved applying the trained model to earlier images predating
the availability of vectorial data 10 to 20 years, successfully identifying
temporal trends in infrastructure for pedestrians and cars across different
city areas. This technique is applicable for municipal governments to gather
valuable data at a minimal cost.",['cs.CV'],"['Miguel Ureña Pliego', 'Rubén Martínez Marín', 'Nianfang Shi', 'Takeru Shibayama', 'Ulrich Leth', 'Miguel Marchamalo Sacristán']",2025-03-19,2025-03-19,This study explores the integration of machine learning into urban aerial image analysis with a focus on identifying infrastructure surfaces for cars and pedestrians and analyzing historical trends. It emphasizes the transition from convolutional architectures to transformer based pre trained models underscoring their potential in global geospatial analysis. A workflow is presented for automatically generating geospatial datasets enabling the creation of semantic segmentation datasets from various sources including WMS WMTS links vectorial cartography and OpenStreetMap OSM overpass turbo requests. The developed code allows a fast dataset generation process for training machine learning models using openly available data without manual labelling. Using aerial imagery and vectorial data from the respective geographical offices of Madrid and Vienna two datasets were generated for car and pedestrian surface detection. A transformer based model was trained and evaluated for each city demonstrating good accuracy values. The historical trend analysis involved applying the trained model to earlier images predating the availability of vectorial data 10 to 20 years successfully identifying temporal trends in infrastructure for pedestrians and cars across different city areas. This technique is applicable for municipal governments to gather valuable data at a minimal cost.,Transport Related Surface Detection with Machine Learning Analyzing Temporal Trends in Madrid and Vienna,"['data', 'analysis', 'datasets', 'trained', 'vectorial', 'aerial', 'based', 'cars', 'city', 'geospatial']",This study explores the integration of machine learning into urban aerial image analysis with a focus on identifying infrastructure surfaces for cars and pedestrians and analyzing historical trends.
2503.14494v1,Deeply Supervised Flow-Based Generative Models,"Flow based generative models have charted an impressive path across multiple
visual generation tasks by adhering to a simple principle: learning velocity
representations of a linear interpolant. However, we observe that training
velocity solely from the final layer output underutilizes the rich inter layer
representations, potentially impeding model convergence. To address this
limitation, we introduce DeepFlow, a novel framework that enhances velocity
representation through inter layer communication. DeepFlow partitions
transformer layers into balanced branches with deep supervision and inserts a
lightweight Velocity Refiner with Acceleration (VeRA) block between adjacent
branches, which aligns the intermediate velocity features within transformer
blocks. Powered by the improved deep supervision via the internal velocity
alignment, DeepFlow converges 8 times faster on ImageNet with equivalent
performance and further reduces FID by 2.6 while halving training time compared
to previous flow based models without a classifier free guidance. DeepFlow also
outperforms baselines in text to image generation tasks, as evidenced by
evaluations on MSCOCO and zero shot GenEval.",['cs.CV'],"['Inkyu Shin', 'Chenglin Yang', 'Liang-Chieh Chen']",2025-03-18,2025-03-18,Flow based generative models have charted an impressive path across multiple visual generation tasks by adhering to a simple principle learning velocity representations of a linear interpolant. However we observe that training velocity solely from the final layer output underutilizes the rich inter layer representations potentially impeding model convergence. To address this limitation we introduce DeepFlow a novel framework that enhances velocity representation through inter layer communication. DeepFlow partitions transformer layers into balanced branches with deep supervision and inserts a lightweight Velocity Refiner with Acceleration VeRA block between adjacent branches which aligns the intermediate velocity features within transformer blocks. Powered by the improved deep supervision via the internal velocity alignment DeepFlow converges 8 times faster on ImageNet with equivalent performance and further reduces FID by 2.6 while halving training time compared to previous flow based models without a classifier free guidance. DeepFlow also outperforms baselines in text to image generation tasks as evidenced by evaluations on MSCOCO and zero shot GenEval.,Deeply Supervised Flow Based Generative Models,"['velocity', 'deepflow', 'layer', 'based', 'branches', 'deep', 'deep supervision', 'flow', 'flow based', 'generation']",Flow based generative models have charted an impressive path across multiple visual generation tasks by adhering to a simple principle learning velocity representations of a linear interpolant.
2503.17352v1,OpenVLThinker: An Early Exploration to Complex Vision-Language Reasoning via Iterative Self-Improvement,"Recent advancements demonstrated by DeepSeek-R1 have shown that complex
reasoning abilities in large language models (LLMs), including sophisticated
behaviors such as self-verification and self-correction, can be achieved by RL
with verifiable rewards and significantly improves model performance on
challenging tasks such as AIME. Motivated by these findings, our study
investigates whether similar reasoning capabilities can be successfully
integrated into large vision-language models (LVLMs) and assesses their impact
on challenging multimodal reasoning tasks. We consider an approach that
iteratively leverages supervised fine-tuning (SFT) on lightweight training data
and Reinforcement Learning (RL) to further improve model generalization.
Initially, reasoning capabilities were distilled from pure-text R1 models by
generating reasoning steps using high-quality captions of the images sourced
from diverse visual datasets. Subsequently, iterative RL training further
enhance reasoning skills, with each iteration's RL-improved model generating
refined SFT datasets for the next round. This iterative process yielded
OpenVLThinker, a LVLM exhibiting consistently improved reasoning performance on
challenging benchmarks such as MathVista, MathVerse, and MathVision,
demonstrating the potential of our strategy for robust vision-language
reasoning. The code, model and data are held at
https://github.com/yihedeng9/OpenVLThinker.","['cs.CV', 'cs.CL']","['Yihe Deng', 'Hritik Bansal', 'Fan Yin', 'Nanyun Peng', 'Wei Wang', 'Kai-Wei Chang']",2025-03-21,2025-03-21,Recent advancements demonstrated by DeepSeek R1 have shown that complex reasoning abilities in large language models LLMs including sophisticated behaviors such as self verification and self correction can be achieved by RL with verifiable rewards and significantly improves model performance on challenging tasks such as AIME. Motivated by these findings our study investigates whether similar reasoning capabilities can be successfully integrated into large vision language models LVLMs and assesses their impact on challenging multimodal reasoning tasks. We consider an approach that iteratively leverages supervised fine tuning SFT on lightweight training data and Reinforcement Learning RL to further improve model generalization. Initially reasoning capabilities were distilled from pure text R1 models by generating reasoning steps using high quality captions of the images sourced from diverse visual datasets. Subsequently iterative RL training further enhance reasoning skills with each iteration s RL improved model generating refined SFT datasets for the next round. This iterative process yielded OpenVLThinker a LVLM exhibiting consistently improved reasoning performance on challenging benchmarks such as MathVista MathVerse and MathVision demonstrating the potential of our strategy for robust vision language reasoning. The code model and data are held at https github.com yihedeng9 OpenVLThinker.,OpenVLThinker An Early Exploration to Complex Vision Language Reasoning via Iterative Self Improvement,"['reasoning', 'model', 'rl', 'challenging', 'language', 'models', 'capabilities', 'data', 'datasets', 'generating']",Recent advancements demonstrated by DeepSeek R1 have shown that complex reasoning abilities in large language models LLMs including sophisticated behaviors such as self verification and self correction can be achieved by RL with verifiable rewards and significantly improves model performance on challenging tasks such as AIME.
2503.14862v2,"Fine-Grained Open-Vocabulary Object Detection with Fined-Grained Prompts: Task, Dataset and Benchmark","Open-vocabulary detectors are proposed to locate and recognize objects in
novel classes. However, variations in vision-aware language vocabulary data
used for open-vocabulary learning can lead to unfair and unreliable
evaluations. Recent evaluation methods have attempted to address this issue by
incorporating object properties or adding locations and characteristics to the
captions. Nevertheless, since these properties and locations depend on the
specific details of the images instead of classes, detectors can not make
accurate predictions without precise descriptions provided through human
annotation. This paper introduces 3F-OVD, a novel task that extends supervised
fine-grained object detection to the open-vocabulary setting. Our task is
intuitive and challenging, requiring a deep understanding of Fine-grained
captions and careful attention to Fine-grained details in images in order to
accurately detect Fine-grained objects. Additionally, due to the scarcity of
qualified fine-grained object detection datasets, we have created a new
dataset, NEU-171K, tailored for both supervised and open-vocabulary settings.
We benchmark state-of-the-art object detectors on our dataset for both
settings. Furthermore, we propose a simple yet effective post-processing
technique.","['cs.CV', 'I.2.0']","['Ying Liu', 'Yijing Hua', 'Haojiang Chai', 'Yanbo Wang', 'TengQi Ye']",2025-03-19,2025-03-20,Open vocabulary detectors are proposed to locate and recognize objects in novel classes. However variations in vision aware language vocabulary data used for open vocabulary learning can lead to unfair and unreliable evaluations. Recent evaluation methods have attempted to address this issue by incorporating object properties or adding locations and characteristics to the captions. Nevertheless since these properties and locations depend on the specific details of the images instead of classes detectors can not make accurate predictions without precise descriptions provided through human annotation. This paper introduces 3F OVD a novel task that extends supervised fine grained object detection to the open vocabulary setting. Our task is intuitive and challenging requiring a deep understanding of Fine grained captions and careful attention to Fine grained details in images in order to accurately detect Fine grained objects. Additionally due to the scarcity of qualified fine grained object detection datasets we have created a new dataset NEU 171K tailored for both supervised and open vocabulary settings. We benchmark state of the art object detectors on our dataset for both settings. Furthermore we propose a simple yet effective post processing technique.,Fine Grained Open Vocabulary Object Detection with Fined Grained Prompts Task Dataset and Benchmark,"['fine', 'fine grained', 'grained', 'vocabulary', 'object', 'open', 'open vocabulary', 'detectors', 'captions', 'classes']",Open vocabulary detectors are proposed to locate and recognize objects in novel classes.
2503.14577v1,PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease,"The accurate diagnosis of Alzheimer's disease (AD) and prognosis of mild
cognitive impairment (MCI) conversion are crucial for early intervention.
However, existing multimodal methods face several challenges, from the
heterogeneity of input data, to underexplored modality interactions, missing
data due to patient dropouts, and limited data caused by the time-consuming and
costly data collection process. In this paper, we propose a novel Prompted
Hypergraph Neural Network (PHGNN) framework that addresses these limitations by
integrating hypergraph based learning with prompt learning. Hypergraphs capture
higher-order relationships between different modalities, while our prompt
learning approach for hypergraphs, adapted from NLP, enables efficient training
with limited data. Our model is validated through extensive experiments on the
ADNI dataset, outperforming SOTA methods in both AD diagnosis and the
prediction of MCI conversion.","['cs.LG', 'cs.AI']","['Chenyu Liu', 'Luca Rossi']",2025-03-18,2025-03-18,The accurate diagnosis of Alzheimer s disease AD and prognosis of mild cognitive impairment MCI conversion are crucial for early intervention. However existing multimodal methods face several challenges from the heterogeneity of input data to underexplored modality interactions missing data due to patient dropouts and limited data caused by the time consuming and costly data collection process. In this paper we propose a novel Prompted Hypergraph Neural Network PHGNN framework that addresses these limitations by integrating hypergraph based learning with prompt learning. Hypergraphs capture higher order relationships between different modalities while our prompt learning approach for hypergraphs adapted from NLP enables efficient training with limited data. Our model is validated through extensive experiments on the ADNI dataset outperforming SOTA methods in both AD diagnosis and the prediction of MCI conversion.,PHGNN A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer s Disease,"['data', 'learning', 'ad', 'conversion', 'diagnosis', 'hypergraph', 'hypergraphs', 'limited', 'limited data', 'mci']",The accurate diagnosis of Alzheimer s disease AD and prognosis of mild cognitive impairment MCI conversion are crucial for early intervention.
2503.15583v1,Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing,"Since state-of-the-art uncertainty estimation methods are often
computationally demanding, we investigate whether incorporating prior
information can improve uncertainty estimates in conventional deep neural
networks. Our focus is on machine learning tasks where meaningful predictions
can be made from sub-parts of the input. For example, in speaker
classification, the speech waveform can be divided into sequential patches,
each containing information about the same speaker. We observe that the
variance between sub-predictions serves as a reliable proxy for uncertainty in
such settings. Our proposed variance-based scaling framework produces
competitive uncertainty estimates in classification while being less
computationally demanding and allowing for integration as a post-hoc
calibration tool. This approach also leads to a simple extension of deep
ensembles, improving the expressiveness of their predicted distributions.",['cs.LG'],"['Fabian Denoodt', 'José Oramas']",2025-03-19,2025-03-19,Since state of the art uncertainty estimation methods are often computationally demanding we investigate whether incorporating prior information can improve uncertainty estimates in conventional deep neural networks. Our focus is on machine learning tasks where meaningful predictions can be made from sub parts of the input. For example in speaker classification the speech waveform can be divided into sequential patches each containing information about the same speaker. We observe that the variance between sub predictions serves as a reliable proxy for uncertainty in such settings. Our proposed variance based scaling framework produces competitive uncertainty estimates in classification while being less computationally demanding and allowing for integration as a post hoc calibration tool. This approach also leads to a simple extension of deep ensembles improving the expressiveness of their predicted distributions.,Efficient Post Hoc Uncertainty Calibration via Variance Based Smoothing,"['uncertainty', 'classification', 'computationally', 'computationally demanding', 'deep', 'demanding', 'estimates', 'information', 'predictions', 'speaker']",Since state of the art uncertainty estimation methods are often computationally demanding we investigate whether incorporating prior information can improve uncertainty estimates in conventional deep neural networks.
2503.17002v1,Targetless 6DoF Calibration of LiDAR and 2D Scanning Radar Based on Cylindrical Occupancy,"Owing to the capability for reliable and all-weather long-range sensing, the
fusion of LiDAR and Radar has been widely applied to autonomous vehicles for
robust perception. In practical operation, well manually calibrated extrinsic
parameters, which are crucial for the fusion of multi-modal sensors, may drift
due to the vibration. To address this issue, we present a novel targetless
calibration approach, termed LiRaCo, for the extrinsic 6DoF calibration of
LiDAR and Radar sensors. Although both types of sensors can obtain geometric
information, bridging the geometric correspondences between multi-modal data
without any clues of explicit artificial markers is nontrivial, mainly due to
the low vertical resolution of scanning Radar. To achieve the targetless
calibration, LiRaCo leverages a spatial occupancy consistency between LiDAR
point clouds and Radar scans in a common cylindrical representation,
considering the increasing data sparsity with distance for both sensors.
Specifically, LiRaCo expands the valid Radar scanned pixels into 3D occupancy
grids to constrain LiDAR point clouds based on spatial consistency.
Consequently, a cost function involving extrinsic calibration parameters is
formulated based on the spatial overlap of 3D grids and LiDAR points. Extrinsic
parameters are finally estimated by optimizing the cost function. Comprehensive
quantitative and qualitative experiments on two real outdoor datasets with
different LiDAR sensors demonstrate the feasibility and accuracy of the
proposed method. The source code will be publicly available.","['cs.RO', 'cs.AI']","['Weimin Wang', 'Yu Du', 'Ting Yang', 'Yu Liu']",2025-03-21,2025-03-21,Owing to the capability for reliable and all weather long range sensing the fusion of LiDAR and Radar has been widely applied to autonomous vehicles for robust perception. In practical operation well manually calibrated extrinsic parameters which are crucial for the fusion of multi modal sensors may drift due to the vibration. To address this issue we present a novel targetless calibration approach termed LiRaCo for the extrinsic 6DoF calibration of LiDAR and Radar sensors. Although both types of sensors can obtain geometric information bridging the geometric correspondences between multi modal data without any clues of explicit artificial markers is nontrivial mainly due to the low vertical resolution of scanning Radar. To achieve the targetless calibration LiRaCo leverages a spatial occupancy consistency between LiDAR point clouds and Radar scans in a common cylindrical representation considering the increasing data sparsity with distance for both sensors. Specifically LiRaCo expands the valid Radar scanned pixels into 3D occupancy grids to constrain LiDAR point clouds based on spatial consistency. Consequently a cost function involving extrinsic calibration parameters is formulated based on the spatial overlap of 3D grids and LiDAR points. Extrinsic parameters are finally estimated by optimizing the cost function. Comprehensive quantitative and qualitative experiments on two real outdoor datasets with different LiDAR sensors demonstrate the feasibility and accuracy of the proposed method. The source code will be publicly available.,Targetless 6DoF Calibration of LiDAR and 2D Scanning Radar Based on Cylindrical Occupancy,"['lidar', 'radar', 'sensors', 'calibration', 'extrinsic', 'liraco', 'parameters', 'spatial', '3d', 'based']",Owing to the capability for reliable and all weather long range sensing the fusion of LiDAR and Radar has been widely applied to autonomous vehicles for robust perception.
2503.17015v1,Do regularization methods for shortcut mitigation work as intended?,"Mitigating shortcuts, where models exploit spurious correlations in training
data, remains a significant challenge for improving generalization.
Regularization methods have been proposed to address this issue by enhancing
model generalizability. However, we demonstrate that these methods can
sometimes overregularize, inadvertently suppressing causal features along with
spurious ones. In this work, we analyze the theoretical mechanisms by which
regularization mitigates shortcuts and explore the limits of its effectiveness.
Additionally, we identify the conditions under which regularization can
successfully eliminate shortcuts without compromising causal features. Through
experiments on synthetic and real-world datasets, our comprehensive analysis
provides valuable insights into the strengths and limitations of regularization
techniques for addressing shortcuts, offering guidance for developing more
robust models.","['cs.LG', 'stat.ML']","['Haoyang Hong', 'Ioanna Papanikolaou', 'Sonali Parbhoo']",2025-03-21,2025-03-21,Mitigating shortcuts where models exploit spurious correlations in training data remains a significant challenge for improving generalization. Regularization methods have been proposed to address this issue by enhancing model generalizability. However we demonstrate that these methods can sometimes overregularize inadvertently suppressing causal features along with spurious ones. In this work we analyze the theoretical mechanisms by which regularization mitigates shortcuts and explore the limits of its effectiveness. Additionally we identify the conditions under which regularization can successfully eliminate shortcuts without compromising causal features. Through experiments on synthetic and real world datasets our comprehensive analysis provides valuable insights into the strengths and limitations of regularization techniques for addressing shortcuts offering guidance for developing more robust models.,Do regularization methods for shortcut mitigation work as intended,"['regularization', 'shortcuts', 'causal', 'causal features', 'features', 'methods', 'models', 'spurious', 'additionally', 'additionally identify']",Mitigating shortcuts where models exploit spurious correlations in training data remains a significant challenge for improving generalization.
2503.17351v1,Time-Series U-Net with Recurrence for Noise-Robust Imaging Photoplethysmography,"Remote estimation of vital signs enables health monitoring for situations in
which contact-based devices are either not available, too intrusive, or too
expensive. In this paper, we present a modular, interpretable pipeline for
pulse signal estimation from video of the face that achieves state-of-the-art
results on publicly available datasets.Our imaging photoplethysmography (iPPG)
system consists of three modules: face and landmark detection, time-series
extraction, and pulse signal/pulse rate estimation. Unlike many deep learning
methods that make use of a single black-box model that maps directly from input
video to output signal or heart rate, our modular approach enables each of the
three parts of the pipeline to be interpreted individually. The pulse signal
estimation module, which we call TURNIP (Time-Series U-Net with Recurrence for
Noise-Robust Imaging Photoplethysmography), allows the system to faithfully
reconstruct the underlying pulse signal waveform and uses it to measure heart
rate and pulse rate variability metrics, even in the presence of motion. When
parts of the face are occluded due to extreme head poses, our system explicitly
detects such ""self-occluded"" regions and maintains estimation robustness
despite the missing information. Our algorithm provides reliable heart rate
estimates without the need for specialized sensors or contact with the skin,
outperforming previous iPPG methods on both color (RGB) and near-infrared (NIR)
datasets.",['cs.CV'],"['Vineet R. Shenoy', 'Shaoju Wu', 'Armand Comas', 'Tim K. Marks', 'Suhas Lohit', 'Hassan Mansour']",2025-03-21,2025-03-21,Remote estimation of vital signs enables health monitoring for situations in which contact based devices are either not available too intrusive or too expensive. In this paper we present a modular interpretable pipeline for pulse signal estimation from video of the face that achieves state of the art results on publicly available datasets.Our imaging photoplethysmography iPPG system consists of three modules face and landmark detection time series extraction and pulse signal pulse rate estimation. Unlike many deep learning methods that make use of a single black box model that maps directly from input video to output signal or heart rate our modular approach enables each of the three parts of the pipeline to be interpreted individually. The pulse signal estimation module which we call TURNIP Time Series U Net with Recurrence for Noise Robust Imaging Photoplethysmography allows the system to faithfully reconstruct the underlying pulse signal waveform and uses it to measure heart rate and pulse rate variability metrics even in the presence of motion. When parts of the face are occluded due to extreme head poses our system explicitly detects such self occluded regions and maintains estimation robustness despite the missing information. Our algorithm provides reliable heart rate estimates without the need for specialized sensors or contact with the skin outperforming previous iPPG methods on both color RGB and near infrared NIR datasets.,Time Series U Net with Recurrence for Noise Robust Imaging Photoplethysmography,"['pulse', 'estimation', 'rate', 'signal', 'pulse signal', 'face', 'heart', 'heart rate', 'available', 'contact']",Remote estimation of vital signs enables health monitoring for situations in which contact based devices are either not available too intrusive or too expensive.
2503.16206v1,Interpretable Neural Causal Models with TRAM-DAGs,"The ultimate goal of most scientific studies is to understand the underlying
causal mechanism between the involved variables. Structural causal models
(SCMs) are widely used to represent such causal mechanisms. Given an SCM,
causal queries on all three levels of Pearl's causal hierarchy can be answered:
$L_1$ observational, $L_2$ interventional, and $L_3$ counterfactual. An
essential aspect of modeling the SCM is to model the dependency of each
variable on its causal parents. Traditionally this is done by parametric
statistical models, such as linear or logistic regression models. This allows
to handle all kinds of data types and fit interpretable models but bears the
risk of introducing a bias. More recently neural causal models came up using
neural networks (NNs) to model the causal relationships, allowing the
estimation of nearly any underlying functional form without bias. However,
current neural causal models are generally restricted to continuous variables
and do not yield an interpretable form of the causal relationships.
Transformation models range from simple statistical regressions to complex
networks and can handle continuous, ordinal, and binary data. Here, we propose
to use TRAMs to model the functional relationships in SCMs allowing us to
bridge the gap between interpretability and flexibility in causal modeling. We
call this method TRAM-DAG and assume currently that the underlying directed
acyclic graph is known. For the fully observed case, we benchmark TRAM-DAGs
against state-of-the-art statistical and NN-based causal models. We show that
TRAM-DAGs are interpretable but also achieve equal or superior performance in
queries ranging from $L_1$ to $L_3$ in the causal hierarchy. For the continuous
case, TRAM-DAGs allow for counterfactual queries for three common causal
structures, including unobserved confounding.","['stat.ML', 'cs.LG']","['Beate Sick', 'Oliver Dürr']",2025-03-20,2025-03-20,The ultimate goal of most scientific studies is to understand the underlying causal mechanism between the involved variables. Structural causal models SCMs are widely used to represent such causal mechanisms. Given an SCM causal queries on all three levels of Pearl s causal hierarchy can be answered L_1 observational L_2 interventional and L_3 counterfactual. An essential aspect of modeling the SCM is to model the dependency of each variable on its causal parents. Traditionally this is done by parametric statistical models such as linear or logistic regression models. This allows to handle all kinds of data types and fit interpretable models but bears the risk of introducing a bias. More recently neural causal models came up using neural networks NNs to model the causal relationships allowing the estimation of nearly any underlying functional form without bias. However current neural causal models are generally restricted to continuous variables and do not yield an interpretable form of the causal relationships. Transformation models range from simple statistical regressions to complex networks and can handle continuous ordinal and binary data. Here we propose to use TRAMs to model the functional relationships in SCMs allowing us to bridge the gap between interpretability and flexibility in causal modeling. We call this method TRAM DAG and assume currently that the underlying directed acyclic graph is known. For the fully observed case we benchmark TRAM DAGs against state of the art statistical and NN based causal models. We show that TRAM DAGs are interpretable but also achieve equal or superior performance in queries ranging from L_1 to L_3 in the causal hierarchy. For the continuous case TRAM DAGs allow for counterfactual queries for three common causal structures including unobserved confounding.,Interpretable Neural Causal Models with TRAM DAGs,"['causal', 'models', 'causal models', 'tram', 'continuous', 'dags', 'interpretable', 'model', 'neural', 'queries']",The ultimate goal of most scientific studies is to understand the underlying causal mechanism between the involved variables.
2503.16544v1,Causal Discovery and Counterfactual Reasoning to Optimize Persuasive Dialogue Policies,"Tailoring persuasive conversations to users leads to more effective
persuasion. However, existing dialogue systems often struggle to adapt to
dynamically evolving user states. This paper presents a novel method that
leverages causal discovery and counterfactual reasoning for optimizing system
persuasion capability and outcomes. We employ the Greedy Relaxation of the
Sparsest Permutation (GRaSP) algorithm to identify causal relationships between
user and system utterance strategies, treating user strategies as states and
system strategies as actions. GRaSP identifies user strategies as causal
factors influencing system responses, which inform Bidirectional Conditional
Generative Adversarial Networks (BiCoGAN) in generating counterfactual
utterances for the system. Subsequently, we use the Dueling Double Deep
Q-Network (D3QN) model to utilize counterfactual data to determine the best
policy for selecting system utterances. Our experiments with the
PersuasionForGood dataset show measurable improvements in persuasion outcomes
using our approach over baseline methods. The observed increase in cumulative
rewards and Q-values highlights the effectiveness of causal discovery in
enhancing counterfactual reasoning and optimizing reinforcement learning
policies for online dialogue systems.","['cs.CL', 'cs.AI', 'cs.HC']","['Donghuo Zeng', 'Roberto Legaspi', 'Yuewen Sun', 'Xinshuai Dong', 'Kazushi Ikeda', 'Peter Spirtes', 'Kun Zhang']",2025-03-19,2025-03-19,Tailoring persuasive conversations to users leads to more effective persuasion. However existing dialogue systems often struggle to adapt to dynamically evolving user states. This paper presents a novel method that leverages causal discovery and counterfactual reasoning for optimizing system persuasion capability and outcomes. We employ the Greedy Relaxation of the Sparsest Permutation GRaSP algorithm to identify causal relationships between user and system utterance strategies treating user strategies as states and system strategies as actions. GRaSP identifies user strategies as causal factors influencing system responses which inform Bidirectional Conditional Generative Adversarial Networks BiCoGAN in generating counterfactual utterances for the system. Subsequently we use the Dueling Double Deep Q Network D3QN model to utilize counterfactual data to determine the best policy for selecting system utterances. Our experiments with the PersuasionForGood dataset show measurable improvements in persuasion outcomes using our approach over baseline methods. The observed increase in cumulative rewards and Q values highlights the effectiveness of causal discovery in enhancing counterfactual reasoning and optimizing reinforcement learning policies for online dialogue systems.,Causal Discovery and Counterfactual Reasoning to Optimize Persuasive Dialogue Policies,"['causal', 'counterfactual', 'strategies', 'user', 'persuasion', 'causal discovery', 'counterfactual reasoning', 'dialogue', 'dialogue systems', 'discovery']",Tailoring persuasive conversations to users leads to more effective persuasion.
2503.16742v1,Digitally Prototype Your Eye Tracker: Simulating Hardware Performance using 3D Synthetic Data,"Eye tracking (ET) is a key enabler for Augmented and Virtual Reality (AR/VR).
Prototyping new ET hardware requires assessing the impact of hardware choices
on eye tracking performance. This task is compounded by the high cost of
obtaining data from sufficiently many variations of real hardware, especially
for machine learning, which requires large training datasets. We propose a
method for end-to-end evaluation of how hardware changes impact machine
learning-based ET performance using only synthetic data. We utilize a dataset
of real 3D eyes, reconstructed from light dome data using neural radiance
fields (NeRF), to synthesize captured eyes from novel viewpoints and camera
parameters. Using this framework, we demonstrate that we can predict the
relative performance across various hardware configurations, accounting for
variations in sensor noise, illumination brightness, and optical blur. We also
compare our simulator with the publicly available eye tracking dataset from the
Project Aria glasses, demonstrating a strong correlation with real-world
performance. Finally, we present a first-of-its-kind analysis in which we vary
ET camera positions, evaluating ET performance ranging from on-axis direct
views of the eye to peripheral views on the frame. Such an analysis would have
previously required manufacturing physical devices to capture evaluation data.
In short, our method enables faster prototyping of ET hardware.",['cs.CV'],"['Esther Y. H. Lin', 'Yimin Ding', 'Jogendra Kundu', 'Yatong An', 'Mohamed T. El-Haddad', 'Alexander Fix']",2025-03-20,2025-03-20,Eye tracking ET is a key enabler for Augmented and Virtual Reality AR VR . Prototyping new ET hardware requires assessing the impact of hardware choices on eye tracking performance. This task is compounded by the high cost of obtaining data from sufficiently many variations of real hardware especially for machine learning which requires large training datasets. We propose a method for end to end evaluation of how hardware changes impact machine learning based ET performance using only synthetic data. We utilize a dataset of real 3D eyes reconstructed from light dome data using neural radiance fields NeRF to synthesize captured eyes from novel viewpoints and camera parameters. Using this framework we demonstrate that we can predict the relative performance across various hardware configurations accounting for variations in sensor noise illumination brightness and optical blur. We also compare our simulator with the publicly available eye tracking dataset from the Project Aria glasses demonstrating a strong correlation with real world performance. Finally we present a first of its kind analysis in which we vary ET camera positions evaluating ET performance ranging from on axis direct views of the eye to peripheral views on the frame. Such an analysis would have previously required manufacturing physical devices to capture evaluation data. In short our method enables faster prototyping of ET hardware.,Digitally Prototype Your Eye Tracker Simulating Hardware Performance using 3D Synthetic Data,"['et', 'hardware', 'performance', 'data', 'eye', 'eye tracking', 'real', 'tracking', 'using', 'analysis']",Eye tracking ET is a key enabler for Augmented and Virtual Reality AR VR .
2503.14922v1,A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks,"Graph Convolutional Networks (GCNs) have shown excellent performance in
graph-structured tasks such as node classification and graph classification.
However, recent research has shown that GCNs are vulnerable to a new type of
threat called the backdoor attack, where the adversary can inject a hidden
backdoor into the GCNs so that the backdoored model performs well on benign
samples, whereas its prediction will be maliciously changed to the
attacker-specified target label if the hidden backdoor is activated by the
attacker-defined trigger. Clean-label backdoor attack and semantic backdoor
attack are two new backdoor attacks to Deep Neural Networks (DNNs), they are
more imperceptible and have posed new and serious threats. The semantic and
clean-label backdoor attack is not fully explored in GCNs. In this paper, we
propose a semantic and clean-label backdoor attack against GCNs under the
context of graph classification to reveal the existence of this security
vulnerability in GCNs. Specifically, SCLBA conducts an importance analysis on
graph samples to select one type of node as semantic trigger, which is then
inserted into the graph samples to create poisoning samples without changing
the labels of the poisoning samples to the attacker-specified target label. We
evaluate SCLBA on multiple datasets and the results show that SCLBA can achieve
attack success rates close to 99% with poisoning rates of less than 3%, and
with almost no impact on the performance of model on benign samples.","['cs.LG', 'cs.AI', 'cs.CR']","['Jiazhu Dai', 'Haoyu Sun']",2025-03-19,2025-03-19,Graph Convolutional Networks GCNs have shown excellent performance in graph structured tasks such as node classification and graph classification. However recent research has shown that GCNs are vulnerable to a new type of threat called the backdoor attack where the adversary can inject a hidden backdoor into the GCNs so that the backdoored model performs well on benign samples whereas its prediction will be maliciously changed to the attacker specified target label if the hidden backdoor is activated by the attacker defined trigger. Clean label backdoor attack and semantic backdoor attack are two new backdoor attacks to Deep Neural Networks DNNs they are more imperceptible and have posed new and serious threats. The semantic and clean label backdoor attack is not fully explored in GCNs. In this paper we propose a semantic and clean label backdoor attack against GCNs under the context of graph classification to reveal the existence of this security vulnerability in GCNs. Specifically SCLBA conducts an importance analysis on graph samples to select one type of node as semantic trigger which is then inserted into the graph samples to create poisoning samples without changing the labels of the poisoning samples to the attacker specified target label. We evaluate SCLBA on multiple datasets and the results show that SCLBA can achieve attack success rates close to 99 with poisoning rates of less than 3 and with almost no impact on the performance of model on benign samples.,A Semantic and Clean label Backdoor Attack against Graph Convolutional Networks,"['backdoor', 'attack', 'gcns', 'graph', 'samples', 'backdoor attack', 'label', 'semantic', 'attacker', 'classification']",Graph Convolutional Networks GCNs have shown excellent performance in graph structured tasks such as node classification and graph classification.
2503.17032v1,TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting,"Realistic 3D full-body talking avatars hold great potential in AR, with
applications ranging from e-commerce live streaming to holographic
communication. Despite advances in 3D Gaussian Splatting (3DGS) for lifelike
avatar creation, existing methods struggle with fine-grained control of facial
expressions and body movements in full-body talking tasks. Additionally, they
often lack sufficient details and cannot run in real-time on mobile devices. We
present TaoAvatar, a high-fidelity, lightweight, 3DGS-based full-body talking
avatar driven by various signals. Our approach starts by creating a
personalized clothed human parametric template that binds Gaussians to
represent appearances. We then pre-train a StyleUnet-based network to handle
complex pose-dependent non-rigid deformation, which can capture high-frequency
appearance details but is too resource-intensive for mobile devices. To
overcome this, we ""bake"" the non-rigid deformations into a lightweight
MLP-based network using a distillation technique and develop blend shapes to
compensate for details. Extensive experiments show that TaoAvatar achieves
state-of-the-art rendering quality while running in real-time across various
devices, maintaining 90 FPS on high-definition stereo devices such as the Apple
Vision Pro.",['cs.CV'],"['Jianchuan Chen', 'Jingchuan Hu', 'Gaige Wang', 'Zhonghua Jiang', 'Tiansong Zhou', 'Zhiwen Chen', 'Chengfei Lv']",2025-03-21,2025-03-21,Realistic 3D full body talking avatars hold great potential in AR with applications ranging from e commerce live streaming to holographic communication. Despite advances in 3D Gaussian Splatting 3DGS for lifelike avatar creation existing methods struggle with fine grained control of facial expressions and body movements in full body talking tasks. Additionally they often lack sufficient details and cannot run in real time on mobile devices. We present TaoAvatar a high fidelity lightweight 3DGS based full body talking avatar driven by various signals. Our approach starts by creating a personalized clothed human parametric template that binds Gaussians to represent appearances. We then pre train a StyleUnet based network to handle complex pose dependent non rigid deformation which can capture high frequency appearance details but is too resource intensive for mobile devices. To overcome this we bake the non rigid deformations into a lightweight MLP based network using a distillation technique and develop blend shapes to compensate for details. Extensive experiments show that TaoAvatar achieves state of the art rendering quality while running in real time across various devices maintaining 90 FPS on high definition stereo devices such as the Apple Vision Pro.,TaoAvatar Real Time Lifelike Full Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting,"['body', 'devices', 'based', 'body talking', 'details', 'high', 'talking', '3d', '3dgs', 'avatar']",Realistic 3D full body talking avatars hold great potential in AR with applications ranging from e commerce live streaming to holographic communication.
2503.15055v1,ELTEX: A Framework for Domain-Driven Synthetic Data Generation,"We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework
for generating high-quality synthetic training data in specialized domains.
While Large Language Models (LLMs) have shown impressive general capabilities,
their performance in specialized domains like cybersecurity remains limited by
the scarcity of domain-specific training data. ELTEX addresses this challenge
by systematically integrating explicit domain indicator extraction with dynamic
prompting to preserve critical domain knowledge throughout the generation
process. We demonstrate ELTEX's effectiveness in the context of
blockchain-related cyberattack detection, where we fine-tune Gemma-2B using
various combinations of real and ELTEX-generated data. Our results show that
the ELTEX-enhanced model achieves performance competitive with GPT-4 across
both standard classification metrics and uncertainty calibration, while
requiring significantly fewer computational resources. We release a curated
synthetic dataset of social media texts for cyberattack detection in
blockchain. Our work demonstrates that domain-driven synthetic data generation
can effectively bridge the performance gap between resource-efficient models
and larger architectures in specialized domains.",['cs.CL'],"['Arina Razmyslovich', 'Kseniia Murasheva', 'Sofia Sedlova', 'Julien Capitaine', 'Eugene Dmitriev']",2025-03-19,2025-03-19,We present ELTEX Efficient LLM Token Extraction a domain driven framework for generating high quality synthetic training data in specialized domains. While Large Language Models LLMs have shown impressive general capabilities their performance in specialized domains like cybersecurity remains limited by the scarcity of domain specific training data. ELTEX addresses this challenge by systematically integrating explicit domain indicator extraction with dynamic prompting to preserve critical domain knowledge throughout the generation process. We demonstrate ELTEX s effectiveness in the context of blockchain related cyberattack detection where we fine tune Gemma 2B using various combinations of real and ELTEX generated data. Our results show that the ELTEX enhanced model achieves performance competitive with GPT 4 across both standard classification metrics and uncertainty calibration while requiring significantly fewer computational resources. We release a curated synthetic dataset of social media texts for cyberattack detection in blockchain. Our work demonstrates that domain driven synthetic data generation can effectively bridge the performance gap between resource efficient models and larger architectures in specialized domains.,ELTEX A Framework for Domain Driven Synthetic Data Generation,"['domain', 'eltex', 'data', 'domains', 'performance', 'specialized', 'specialized domains', 'synthetic', 'blockchain', 'cyberattack']",We present ELTEX Efficient LLM Token Extraction a domain driven framework for generating high quality synthetic training data in specialized domains.
2503.15647v1,Multi-Modal Gesture Recognition from Video and Surgical Tool Pose Information via Motion Invariants,"Recognizing surgical gestures in real-time is a stepping stone towards
automated activity recognition, skill assessment, intra-operative assistance,
and eventually surgical automation. The current robotic surgical systems
provide us with rich multi-modal data such as video and kinematics. While some
recent works in multi-modal neural networks learn the relationships between
vision and kinematics data, current approaches treat kinematics information as
independent signals, with no underlying relation between tool-tip poses.
However, instrument poses are geometrically related, and the underlying
geometry can aid neural networks in learning gesture representation. Therefore,
we propose combining motion invariant measures (curvature and torsion) with
vision and kinematics data using a relational graph network to capture the
underlying relations between different data streams. We show that gesture
recognition improves when combining invariant signals with tool position,
achieving 90.3\% frame-wise accuracy on the JIGSAWS suturing dataset. Our
results show that motion invariant signals coupled with position are better
representations of gesture motion compared to traditional position and
quaternion representations. Our results highlight the need for geometric-aware
modeling of kinematics for gesture recognition.","['cs.CV', 'cs.LG']","['Jumanh Atoum', 'Garrison L. H. Johnston', 'Nabil Simaan', 'Jie Ying Wu']",2025-03-19,2025-03-19,Recognizing surgical gestures in real time is a stepping stone towards automated activity recognition skill assessment intra operative assistance and eventually surgical automation. The current robotic surgical systems provide us with rich multi modal data such as video and kinematics. While some recent works in multi modal neural networks learn the relationships between vision and kinematics data current approaches treat kinematics information as independent signals with no underlying relation between tool tip poses. However instrument poses are geometrically related and the underlying geometry can aid neural networks in learning gesture representation. Therefore we propose combining motion invariant measures curvature and torsion with vision and kinematics data using a relational graph network to capture the underlying relations between different data streams. We show that gesture recognition improves when combining invariant signals with tool position achieving 90.3 frame wise accuracy on the JIGSAWS suturing dataset. Our results show that motion invariant signals coupled with position are better representations of gesture motion compared to traditional position and quaternion representations. Our results highlight the need for geometric aware modeling of kinematics for gesture recognition.,Multi Modal Gesture Recognition from Video and Surgical Tool Pose Information via Motion Invariants,"['kinematics', 'data', 'gesture', 'invariant', 'motion', 'position', 'recognition', 'signals', 'surgical', 'underlying']",Recognizing surgical gestures in real time is a stepping stone towards automated activity recognition skill assessment intra operative assistance and eventually surgical automation.
2503.15482v1,Natural Quantization of Neural Networks,"We propose a natural quantization of a standard neural network, where the
neurons correspond to qubits and the activation functions are implemented via
quantum gates and measurements. The simplest quantized neural network
corresponds to applying single-qubit rotations, with the rotation angles being
dependent on the weights and measurement outcomes of the previous layer. This
realization has the advantage of being smoothly tunable from the purely
classical limit with no quantum uncertainty (thereby reproducing the classical
neural network exactly) to a quantum case, where superpositions introduce an
intrinsic uncertainty in the network. We benchmark this architecture on a
subset of the standard MNIST dataset and find a regime of ""quantum advantage,""
where the validation error rate in the quantum realization is smaller than that
in the classical model. We also consider another approach where quantumness is
introduced via weak measurements of ancilla qubits entangled with the neuron
qubits. This quantum neural network also allows for smooth tuning of the degree
of quantumness by controlling an entanglement angle, $g$, with $g=\frac\pi 2$
replicating the classical regime. We find that validation error is also
minimized within the quantum regime in this approach. We also observe a quantum
transition, with sharp loss of the quantum network's ability to learn at a
critical point $g_c$. The proposed quantum neural networks are readily
realizable in present-day quantum computers on commercial datasets.","['quant-ph', 'cond-mat.dis-nn', 'cs.LG']","['Richard Barney', 'Djamil Lakhdar-Hamina', 'Victor Galitski']",2025-03-19,2025-03-19,We propose a natural quantization of a standard neural network where the neurons correspond to qubits and the activation functions are implemented via quantum gates and measurements. The simplest quantized neural network corresponds to applying single qubit rotations with the rotation angles being dependent on the weights and measurement outcomes of the previous layer. This realization has the advantage of being smoothly tunable from the purely classical limit with no quantum uncertainty thereby reproducing the classical neural network exactly to a quantum case where superpositions introduce an intrinsic uncertainty in the network. We benchmark this architecture on a subset of the standard MNIST dataset and find a regime of quantum advantage where the validation error rate in the quantum realization is smaller than that in the classical model. We also consider another approach where quantumness is introduced via weak measurements of ancilla qubits entangled with the neuron qubits. This quantum neural network also allows for smooth tuning of the degree of quantumness by controlling an entanglement angle g with g frac pi 2 replicating the classical regime. We find that validation error is also minimized within the quantum regime in this approach. We also observe a quantum transition with sharp loss of the quantum network s ability to learn at a critical point g_c . The proposed quantum neural networks are readily realizable in present day quantum computers on commercial datasets.,Natural Quantization of Neural Networks,"['quantum', 'network', 'neural', 'classical', 'neural network', 'qubits', 'regime', 'advantage', 'approach', 'error']",We propose a natural quantization of a standard neural network where the neurons correspond to qubits and the activation functions are implemented via quantum gates and measurements.
2503.15855v1,VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling,"We propose VideoRFSplat, a direct text-to-3D model leveraging a video
generation model to generate realistic 3D Gaussian Splatting (3DGS) for
unbounded real-world scenes. To generate diverse camera poses and unbounded
spatial extent of real-world scenes, while ensuring generalization to arbitrary
text prompts, previous methods fine-tune 2D generative models to jointly model
camera poses and multi-view images. However, these methods suffer from
instability when extending 2D generative models to joint modeling due to the
modality gap, which necessitates additional models to stabilize training and
inference. In this work, we propose an architecture and a sampling strategy to
jointly model multi-view images and camera poses when fine-tuning a video
generation model. Our core idea is a dual-stream architecture that attaches a
dedicated pose generation model alongside a pre-trained video generation model
via communication blocks, generating multi-view images and camera poses through
separate streams. This design reduces interference between the pose and image
modalities. Additionally, we propose an asynchronous sampling strategy that
denoises camera poses faster than multi-view images, allowing rapidly denoised
poses to condition multi-view generation, reducing mutual ambiguity and
enhancing cross-modal consistency. Trained on multiple large-scale real-world
datasets (RealEstate10K, MVImgNet, DL3DV-10K, ACID), VideoRFSplat outperforms
existing text-to-3D direct generation methods that heavily depend on post-hoc
refinement via score distillation sampling, achieving superior results without
such refinement.","['cs.CV', 'cs.AI']","['Hyojun Go', 'Byeongjun Park', 'Hyelin Nam', 'Byung-Hoon Kim', 'Hyungjin Chung', 'Changick Kim']",2025-03-20,2025-03-20,We propose VideoRFSplat a direct text to 3D model leveraging a video generation model to generate realistic 3D Gaussian Splatting 3DGS for unbounded real world scenes. To generate diverse camera poses and unbounded spatial extent of real world scenes while ensuring generalization to arbitrary text prompts previous methods fine tune 2D generative models to jointly model camera poses and multi view images. However these methods suffer from instability when extending 2D generative models to joint modeling due to the modality gap which necessitates additional models to stabilize training and inference. In this work we propose an architecture and a sampling strategy to jointly model multi view images and camera poses when fine tuning a video generation model. Our core idea is a dual stream architecture that attaches a dedicated pose generation model alongside a pre trained video generation model via communication blocks generating multi view images and camera poses through separate streams. This design reduces interference between the pose and image modalities. Additionally we propose an asynchronous sampling strategy that denoises camera poses faster than multi view images allowing rapidly denoised poses to condition multi view generation reducing mutual ambiguity and enhancing cross modal consistency. Trained on multiple large scale real world datasets RealEstate10K MVImgNet DL3DV 10K ACID VideoRFSplat outperforms existing text to 3D direct generation methods that heavily depend on post hoc refinement via score distillation sampling achieving superior results without such refinement.,VideoRFSplat Direct Scene Level Text to 3D Gaussian Splatting Generation with Flexible Pose and Multi View Joint Modeling,"['model', 'generation', 'poses', 'camera', 'camera poses', 'multi', 'multi view', 'view', 'generation model', 'images']",We propose VideoRFSplat a direct text to 3D model leveraging a video generation model to generate realistic 3D Gaussian Splatting 3DGS for unbounded real world scenes.
2503.16560v1,Early Prediction of Alzheimer's and Related Dementias: A Machine Learning Approach Utilizing Social Determinants of Health Data,"Alzheimer's disease and related dementias (AD/ADRD) represent a growing
healthcare crisis affecting over 6 million Americans. While genetic factors
play a crucial role, emerging research reveals that social determinants of
health (SDOH) significantly influence both the risk and progression of
cognitive functioning, such as cognitive scores and cognitive decline. This
report examines how these social, environmental, and structural factors impact
cognitive health trajectories, with a particular focus on Hispanic populations,
who face disproportionate risk for AD/ADRD. Using data from the Mexican Health
and Aging Study (MHAS) and its cognitive assessment sub study (Mex-Cog), we
employed ensemble of regression trees models to predict 4-year and 9-year
cognitive scores and cognitive decline based on SDOH. This approach identified
key predictive SDOH factors to inform potential multilevel interventions to
address cognitive health disparities in this population.","['q-bio.QM', 'cs.LG']","['Bereket Kindo', 'Arjee Restar', 'Anh Tran']",2025-03-20,2025-03-20,Alzheimer s disease and related dementias AD ADRD represent a growing healthcare crisis affecting over 6 million Americans. While genetic factors play a crucial role emerging research reveals that social determinants of health SDOH significantly influence both the risk and progression of cognitive functioning such as cognitive scores and cognitive decline. This report examines how these social environmental and structural factors impact cognitive health trajectories with a particular focus on Hispanic populations who face disproportionate risk for AD ADRD. Using data from the Mexican Health and Aging Study MHAS and its cognitive assessment sub study Mex Cog we employed ensemble of regression trees models to predict 4 year and 9 year cognitive scores and cognitive decline based on SDOH. This approach identified key predictive SDOH factors to inform potential multilevel interventions to address cognitive health disparities in this population.,Early Prediction of Alzheimer s and Related Dementias A Machine Learning Approach Utilizing Social Determinants of Health Data,"['cognitive', 'health', 'factors', 'sdoh', 'ad', 'ad adrd', 'adrd', 'cognitive decline', 'cognitive health', 'cognitive scores']",Alzheimer s disease and related dementias AD ADRD represent a growing healthcare crisis affecting over 6 million Americans.
2503.17287v1,FastCuRL: Curriculum Reinforcement Learning with Progressive Context Extension for Efficient Training R1-like Reasoning Models,"In this paper, we propose \textbf{\textsc{FastCuRL}}, a simple yet efficient
\textbf{Cu}rriculum \textbf{R}einforcement \textbf{L}earning approach with
context window extending strategy to accelerate the reinforcement learning
training efficiency for R1-like reasoning models while enhancing their
performance in tackling complex reasoning tasks with long chain-of-thought
rationales, particularly with a 1.5B parameter language model.
\textbf{\textsc{FastCuRL}} consists of two main procedures: length-aware
training data segmentation and context window extension training. Specifically,
the former first splits the original training data into three different levels
by the input prompt length, and then the latter leverages segmented training
datasets with a progressively increasing context window length to train the
reasoning model. Experimental results demonstrate that
\textbf{\textsc{FastCuRL}}-1.5B-Preview surpasses DeepScaleR-1.5B-Preview
across all five datasets (including MATH 500, AIME 2024, AMC 2023, Minerva
Math, and OlympiadBench) while only utilizing 50\% of training steps.
Furthermore, all training stages for FastCuRL-1.5B-Preview are completed using
just a single node with 8 GPUs.",['cs.CL'],"['Mingyang Song', 'Mao Zheng', 'Zheng Li', 'Wenjie Yang', 'Xuan Luo', 'Yue Pan', 'Feng Zhang']",2025-03-21,2025-03-21,In this paper we propose textbf textsc FastCuRL a simple yet efficient textbf Cu rriculum textbf R einforcement textbf L earning approach with context window extending strategy to accelerate the reinforcement learning training efficiency for R1 like reasoning models while enhancing their performance in tackling complex reasoning tasks with long chain of thought rationales particularly with a 1.5B parameter language model. textbf textsc FastCuRL consists of two main procedures length aware training data segmentation and context window extension training. Specifically the former first splits the original training data into three different levels by the input prompt length and then the latter leverages segmented training datasets with a progressively increasing context window length to train the reasoning model. Experimental results demonstrate that textbf textsc FastCuRL 1.5B Preview surpasses DeepScaleR 1.5B Preview across all five datasets including MATH 500 AIME 2024 AMC 2023 Minerva Math and OlympiadBench while only utilizing 50 of training steps. Furthermore all training stages for FastCuRL 1.5B Preview are completed using just a single node with 8 GPUs.,FastCuRL Curriculum Reinforcement Learning with Progressive Context Extension for Efficient Training R1 like Reasoning Models,"['training', 'textbf', '5b', 'fastcurl', '5b preview', 'context', 'context window', 'length', 'preview', 'reasoning']",In this paper we propose textbf textsc FastCuRL a simple yet efficient textbf Cu rriculum textbf R einforcement textbf L earning approach with context window extending strategy to accelerate the reinforcement learning training efficiency for R1 like reasoning models while enhancing their performance in tackling complex reasoning tasks with long chain of thought rationales particularly with a 1.5B parameter language model.
2503.16400v1,ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos,"Video diffusion models (VDMs) facilitate the generation of high-quality
videos, with current research predominantly concentrated on scaling efforts
during training through improvements in data quality, computational resources,
and model complexity. However, inference-time scaling has received less
attention, with most approaches restricting models to a single generation
attempt. Recent studies have uncovered the existence of ""golden noises"" that
can enhance video quality during generation. Building on this, we find that
guiding the scaling inference-time search of VDMs to identify better noise
candidates not only evaluates the quality of the frames generated in the
current step but also preserves the high-level object features by referencing
the anchor frame from previous multi-chunks, thereby delivering long-term
value. Our analysis reveals that diffusion models inherently possess flexible
adjustments of computation by varying denoising steps, and even a one-step
denoising approach, when guided by a reward signal, yields significant
long-term benefits. Based on the observation, we proposeScalingNoise, a
plug-and-play inference-time search strategy that identifies golden initial
noises for the diffusion sampling process to improve global content consistency
and visual diversity. Specifically, we perform one-step denoising to convert
initial noises into a clip and subsequently evaluate its long-term value,
leveraging a reward model anchored by previously generated content. Moreover,
to preserve diversity, we sample candidates from a tilted noise distribution
that up-weights promising noises. In this way, ScalingNoise significantly
reduces noise-induced errors, ensuring more coherent and spatiotemporally
consistent video generation. Extensive experiments on benchmark datasets
demonstrate that the proposed ScalingNoise effectively improves long video
generation.",['cs.LG'],"['Haolin Yang', 'Feilong Tang', 'Ming Hu', 'Yulong Li', 'Junjie Guo', 'Yexin Liu', 'Zelin Peng', 'Junjun He', 'Zongyuan Ge', 'Imran Razzak']",2025-03-20,2025-03-20,Video diffusion models VDMs facilitate the generation of high quality videos with current research predominantly concentrated on scaling efforts during training through improvements in data quality computational resources and model complexity. However inference time scaling has received less attention with most approaches restricting models to a single generation attempt. Recent studies have uncovered the existence of golden noises that can enhance video quality during generation. Building on this we find that guiding the scaling inference time search of VDMs to identify better noise candidates not only evaluates the quality of the frames generated in the current step but also preserves the high level object features by referencing the anchor frame from previous multi chunks thereby delivering long term value. Our analysis reveals that diffusion models inherently possess flexible adjustments of computation by varying denoising steps and even a one step denoising approach when guided by a reward signal yields significant long term benefits. Based on the observation we proposeScalingNoise a plug and play inference time search strategy that identifies golden initial noises for the diffusion sampling process to improve global content consistency and visual diversity. Specifically we perform one step denoising to convert initial noises into a clip and subsequently evaluate its long term value leveraging a reward model anchored by previously generated content. Moreover to preserve diversity we sample candidates from a tilted noise distribution that up weights promising noises. In this way ScalingNoise significantly reduces noise induced errors ensuring more coherent and spatiotemporally consistent video generation. Extensive experiments on benchmark datasets demonstrate that the proposed ScalingNoise effectively improves long video generation.,ScalingNoise Scaling Inference Time Search for Generating Infinite Videos,"['generation', 'long', 'noises', 'quality', 'video', 'denoising', 'diffusion', 'inference', 'inference time', 'long term']",Video diffusion models VDMs facilitate the generation of high quality videos with current research predominantly concentrated on scaling efforts during training through improvements in data quality computational resources and model complexity.
2503.16806v1,DyWA: Dynamics-adaptive World Action Model for Generalizable Non-prehensile Manipulation,"Nonprehensile manipulation is crucial for handling objects that are too thin,
large, or otherwise ungraspable in unstructured environments. While
conventional planning-based approaches struggle with complex contact modeling,
learning-based methods have recently emerged as a promising alternative.
However, existing learning-based approaches face two major limitations: they
heavily rely on multi-view cameras and precise pose tracking, and they fail to
generalize across varying physical conditions, such as changes in object mass
and table friction. To address these challenges, we propose the
Dynamics-Adaptive World Action Model (DyWA), a novel framework that enhances
action learning by jointly predicting future states while adapting to dynamics
variations based on historical trajectories. By unifying the modeling of
geometry, state, physics, and robot actions, DyWA enables more robust policy
learning under partial observability. Compared to baselines, our method
improves the success rate by 31.5% using only single-view point cloud
observations in the simulation. Furthermore, DyWA achieves an average success
rate of 68% in real-world experiments, demonstrating its ability to generalize
across diverse object geometries, adapt to varying table friction, and
robustness in challenging scenarios such as half-filled water bottles and
slippery surfaces.","['cs.RO', 'cs.AI']","['Jiangran Lyu', 'Ziming Li', 'Xuesong Shi', 'Chaoyi Xu', 'Yizhou Wang', 'He Wang']",2025-03-21,2025-03-21,Nonprehensile manipulation is crucial for handling objects that are too thin large or otherwise ungraspable in unstructured environments. While conventional planning based approaches struggle with complex contact modeling learning based methods have recently emerged as a promising alternative. However existing learning based approaches face two major limitations they heavily rely on multi view cameras and precise pose tracking and they fail to generalize across varying physical conditions such as changes in object mass and table friction. To address these challenges we propose the Dynamics Adaptive World Action Model DyWA a novel framework that enhances action learning by jointly predicting future states while adapting to dynamics variations based on historical trajectories. By unifying the modeling of geometry state physics and robot actions DyWA enables more robust policy learning under partial observability. Compared to baselines our method improves the success rate by 31.5 using only single view point cloud observations in the simulation. Furthermore DyWA achieves an average success rate of 68 in real world experiments demonstrating its ability to generalize across diverse object geometries adapt to varying table friction and robustness in challenging scenarios such as half filled water bottles and slippery surfaces.,DyWA Dynamics adaptive World Action Model for Generalizable Non prehensile Manipulation,"['based', 'learning', 'dywa', 'action', 'approaches', 'based approaches', 'dynamics', 'friction', 'generalize', 'learning based']",Nonprehensile manipulation is crucial for handling objects that are too thin large or otherwise ungraspable in unstructured environments.
2503.14929v1,ACE: A Cardinality Estimator for Set-Valued Queries,"Cardinality estimation is a fundamental functionality in database systems.
Most existing cardinality estimators focus on handling predicates over numeric
or categorical data. They have largely omitted an important data type,
set-valued data, which frequently occur in contemporary applications such as
information retrieval and recommender systems. The few existing estimators for
such data either favor high-frequency elements or rely on a partial
independence assumption, which limits their practical applicability. We propose
ACE, an Attention-based Cardinality Estimator for estimating the cardinality of
queries over set-valued data. We first design a distillation-based data encoder
to condense the dataset into a compact matrix. We then design an
attention-based query analyzer to capture correlations among query elements. To
handle variable-sized queries, a pooling module is introduced, followed by a
regression model (MLP) to generate final cardinality estimates. We evaluate ACE
on three datasets with varying query element distributions, demonstrating that
ACE outperforms the state-of-the-art competitors in terms of both accuracy and
efficiency.","['cs.DB', 'cs.LG']","['Yufan Sheng', 'Xin Cao', 'Kaiqi Zhao', 'Yixiang Fang', 'Jianzhong Qi', 'Wenjie Zhang', 'Christian S. Jensen']",2025-03-19,2025-03-19,Cardinality estimation is a fundamental functionality in database systems. Most existing cardinality estimators focus on handling predicates over numeric or categorical data. They have largely omitted an important data type set valued data which frequently occur in contemporary applications such as information retrieval and recommender systems. The few existing estimators for such data either favor high frequency elements or rely on a partial independence assumption which limits their practical applicability. We propose ACE an Attention based Cardinality Estimator for estimating the cardinality of queries over set valued data. We first design a distillation based data encoder to condense the dataset into a compact matrix. We then design an attention based query analyzer to capture correlations among query elements. To handle variable sized queries a pooling module is introduced followed by a regression model MLP to generate final cardinality estimates. We evaluate ACE on three datasets with varying query element distributions demonstrating that ACE outperforms the state of the art competitors in terms of both accuracy and efficiency.,ACE A Cardinality Estimator for Set Valued Queries,"['data', 'cardinality', 'ace', 'based', 'query', 'attention', 'attention based', 'design', 'elements', 'estimators']",Cardinality estimation is a fundamental functionality in database systems.
2503.17085v1,Deterministic AI Agent Personality Expression through Standard Psychological Diagnostics,"Artificial intelligence (AI) systems powered by large language models have
become increasingly prevalent in modern society, enabling a wide range of
applications through natural language interaction. As AI agents proliferate in
our daily lives, their generic and uniform expressiveness presents a
significant limitation to their appeal and adoption. Personality expression
represents a key prerequisite for creating more human-like and distinctive AI
systems. We show that AI models can express deterministic and consistent
personalities when instructed using established psychological frameworks, with
varying degrees of accuracy depending on model capabilities. We find that more
advanced models like GPT-4o and o1 demonstrate the highest accuracy in
expressing specified personalities across both Big Five and Myers-Briggs
assessments, and further analysis suggests that personality expression emerges
from a combination of intelligence and reasoning capabilities. Our results
reveal that personality expression operates through holistic reasoning rather
than question-by-question optimization, with response-scale metrics showing
higher variance than test-scale metrics. Furthermore, we find that model
fine-tuning affects communication style independently of personality expression
accuracy. These findings establish a foundation for creating AI agents with
diverse and consistent personalities, which could significantly enhance
human-AI interaction across applications from education to healthcare, while
additionally enabling a broader range of more unique AI agents. The ability to
quantitatively assess and implement personality expression in AI systems opens
new avenues for research into more relatable, trustworthy, and ethically
designed AI.","['cs.LG', 'cs.AI', 'cs.CY', 'cs.HC']","['J. M. Diederik Kruijssen', 'Nicholas Emmons']",2025-03-21,2025-03-21,Artificial intelligence AI systems powered by large language models have become increasingly prevalent in modern society enabling a wide range of applications through natural language interaction. As AI agents proliferate in our daily lives their generic and uniform expressiveness presents a significant limitation to their appeal and adoption. Personality expression represents a key prerequisite for creating more human like and distinctive AI systems. We show that AI models can express deterministic and consistent personalities when instructed using established psychological frameworks with varying degrees of accuracy depending on model capabilities. We find that more advanced models like GPT 4o and o1 demonstrate the highest accuracy in expressing specified personalities across both Big Five and Myers Briggs assessments and further analysis suggests that personality expression emerges from a combination of intelligence and reasoning capabilities. Our results reveal that personality expression operates through holistic reasoning rather than question by question optimization with response scale metrics showing higher variance than test scale metrics. Furthermore we find that model fine tuning affects communication style independently of personality expression accuracy. These findings establish a foundation for creating AI agents with diverse and consistent personalities which could significantly enhance human AI interaction across applications from education to healthcare while additionally enabling a broader range of more unique AI agents. The ability to quantitatively assess and implement personality expression in AI systems opens new avenues for research into more relatable trustworthy and ethically designed AI.,Deterministic AI Agent Personality Expression through Standard Psychological Diagnostics,"['ai', 'expression', 'personality', 'personality expression', 'accuracy', 'agents', 'ai agents', 'ai systems', 'models', 'personalities']",Artificial intelligence AI systems powered by large language models have become increasingly prevalent in modern society enabling a wide range of applications through natural language interaction.
2503.16086v1,Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly,"Ensuring food safety and quality is critical in the food processing industry,
where the detection of contaminants remains a persistent challenge. This study
presents an automated solution for detecting foreign objects on pork belly meat
using hyperspectral imaging (HSI). A hyperspectral camera was used to capture
data across various bands in the near-infrared (NIR) spectrum (900-1700 nm),
enabling accurate identification of contaminants that are often undetectable
through traditional visual inspection methods. The proposed solution combines
pre-processing techniques with a segmentation approach based on a lightweight
Vision Transformer (ViT) to distinguish contaminants from meat, fat, and
conveyor belt materials. The adopted strategy demonstrates high detection
accuracy and training efficiency, while also addressing key industrial
challenges such as inherent noise, temperature variations, and spectral
similarity between contaminants and pork belly. Experimental results validate
the effectiveness of hyperspectral imaging in enhancing food safety,
highlighting its potential for broad real-time applications in automated
quality control processes.","['cs.CV', 'cs.LG', 'I.2.6; I.2.10; J.7']","['Gabriela Ghimpeteanu', 'Hayat Rajani', 'Josep Quintana', 'Rafael Garcia']",2025-03-20,2025-03-20,Ensuring food safety and quality is critical in the food processing industry where the detection of contaminants remains a persistent challenge. This study presents an automated solution for detecting foreign objects on pork belly meat using hyperspectral imaging HSI . A hyperspectral camera was used to capture data across various bands in the near infrared NIR spectrum 900 1700 nm enabling accurate identification of contaminants that are often undetectable through traditional visual inspection methods. The proposed solution combines pre processing techniques with a segmentation approach based on a lightweight Vision Transformer ViT to distinguish contaminants from meat fat and conveyor belt materials. The adopted strategy demonstrates high detection accuracy and training efficiency while also addressing key industrial challenges such as inherent noise temperature variations and spectral similarity between contaminants and pork belly. Experimental results validate the effectiveness of hyperspectral imaging in enhancing food safety highlighting its potential for broad real time applications in automated quality control processes.,Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly,"['contaminants', 'food', 'hyperspectral', 'automated', 'belly', 'detection', 'food safety', 'hyperspectral imaging', 'imaging', 'meat']",Ensuring food safety and quality is critical in the food processing industry where the detection of contaminants remains a persistent challenge.
2503.15126v1,Text-Derived Relational Graph-Enhanced Network for Skeleton-Based Action Segmentation,"Skeleton-based Temporal Action Segmentation (STAS) aims to segment and
recognize various actions from long, untrimmed sequences of human skeletal
movements. Current STAS methods typically employ spatio-temporal modeling to
establish dependencies among joints as well as frames, and utilize one-hot
encoding with cross-entropy loss for frame-wise classification supervision.
However, these methods overlook the intrinsic correlations among joints and
actions within skeletal features, leading to a limited understanding of human
movements. To address this, we propose a Text-Derived Relational Graph-Enhanced
Network (TRG-Net) that leverages prior graphs generated by Large Language
Models (LLM) to enhance both modeling and supervision. For modeling, the
Dynamic Spatio-Temporal Fusion Modeling (DSFM) method incorporates Text-Derived
Joint Graphs (TJG) with channel- and frame-level dynamic adaptation to
effectively model spatial relations, while integrating spatio-temporal core
features during temporal modeling. For supervision, the Absolute-Relative
Inter-Class Supervision (ARIS) method employs contrastive learning between
action features and text embeddings to regularize the absolute class
distributions, and utilizes Text-Derived Action Graphs (TAG) to capture the
relative inter-class relationships among action features. Additionally, we
propose a Spatial-Aware Enhancement Processing (SAEP) method, which
incorporates random joint occlusion and axial rotation to enhance spatial
generalization. Performance evaluations on four public datasets demonstrate
that TRG-Net achieves state-of-the-art results.","['cs.CV', 'cs.AI']","['Haoyu Ji', 'Bowen Chen', 'Weihong Ren', 'Wenze Huang', 'Zhihao Yang', 'Zhiyong Wang', 'Honghai Liu']",2025-03-19,2025-03-19,Skeleton based Temporal Action Segmentation STAS aims to segment and recognize various actions from long untrimmed sequences of human skeletal movements. Current STAS methods typically employ spatio temporal modeling to establish dependencies among joints as well as frames and utilize one hot encoding with cross entropy loss for frame wise classification supervision. However these methods overlook the intrinsic correlations among joints and actions within skeletal features leading to a limited understanding of human movements. To address this we propose a Text Derived Relational Graph Enhanced Network TRG Net that leverages prior graphs generated by Large Language Models LLM to enhance both modeling and supervision. For modeling the Dynamic Spatio Temporal Fusion Modeling DSFM method incorporates Text Derived Joint Graphs TJG with channel and frame level dynamic adaptation to effectively model spatial relations while integrating spatio temporal core features during temporal modeling. For supervision the Absolute Relative Inter Class Supervision ARIS method employs contrastive learning between action features and text embeddings to regularize the absolute class distributions and utilizes Text Derived Action Graphs TAG to capture the relative inter class relationships among action features. Additionally we propose a Spatial Aware Enhancement Processing SAEP method which incorporates random joint occlusion and axial rotation to enhance spatial generalization. Performance evaluations on four public datasets demonstrate that TRG Net achieves state of the art results.,Text Derived Relational Graph Enhanced Network for Skeleton Based Action Segmentation,"['modeling', 'temporal', 'action', 'features', 'supervision', 'text', 'class', 'derived', 'graphs', 'method']",Skeleton based Temporal Action Segmentation STAS aims to segment and recognize various actions from long untrimmed sequences of human skeletal movements.
2503.17212v1,A Deep Learning Framework for Visual Attention Prediction and Analysis of News Interfaces,"News outlets' competition for attention in news interfaces has highlighted
the need for demographically-aware saliency prediction models. Despite recent
advancements in saliency detection applied to user interfaces (UI), existing
datasets are limited in size and demographic representation. We present a deep
learning framework that enhances the SaRa (Saliency Ranking) model with
DeepGaze IIE, improving Salient Object Ranking (SOR) performance by 10.7%. Our
framework optimizes three key components: saliency map generation, grid segment
scoring, and map normalization. Through a two-fold experiment using
eye-tracking (30 participants) and mouse-tracking (375 participants aged
13--70), we analyze attention patterns across demographic groups. Statistical
analysis reveals significant age-based variations (p < 0.05, {\epsilon^2} =
0.042), with older users (36--70) engaging more with textual content and
younger users (13--35) interacting more with images. Mouse-tracking data
closely approximates eye-tracking behavior (sAUC = 0.86) and identifies UI
elements that immediately stand out, validating its use in large-scale studies.
We conclude that saliency studies should prioritize gathering data from a
larger, demographically representative sample and report exact demographic
distributions.","['cs.CV', 'cs.HC']","['Matthew Kenely', 'Dylan Seychell', 'Carl James Debono', 'Chris Porter']",2025-03-21,2025-03-21,News outlets competition for attention in news interfaces has highlighted the need for demographically aware saliency prediction models. Despite recent advancements in saliency detection applied to user interfaces UI existing datasets are limited in size and demographic representation. We present a deep learning framework that enhances the SaRa Saliency Ranking model with DeepGaze IIE improving Salient Object Ranking SOR performance by 10.7 . Our framework optimizes three key components saliency map generation grid segment scoring and map normalization. Through a two fold experiment using eye tracking 30 participants and mouse tracking 375 participants aged 13 70 we analyze attention patterns across demographic groups. Statistical analysis reveals significant age based variations p 0.05 epsilon 2 0.042 with older users 36 70 engaging more with textual content and younger users 13 35 interacting more with images. Mouse tracking data closely approximates eye tracking behavior sAUC 0.86 and identifies UI elements that immediately stand out validating its use in large scale studies. We conclude that saliency studies should prioritize gathering data from a larger demographically representative sample and report exact demographic distributions.,A Deep Learning Framework for Visual Attention Prediction and Analysis of News Interfaces,"['saliency', 'tracking', 'demographic', '13', '70', 'attention', 'data', 'demographically', 'eye', 'eye tracking']",News outlets competition for attention in news interfaces has highlighted the need for demographically aware saliency prediction models.
2503.15417v1,Temporal Regularization Makes Your Video Generator Stronger,"Temporal quality is a critical aspect of video generation, as it ensures
consistent motion and realistic dynamics across frames. However, achieving high
temporal coherence and diversity remains challenging. In this work, we explore
temporal augmentation in video generation for the first time, and introduce
FluxFlow for initial investigation, a strategy designed to enhance temporal
quality. Operating at the data level, FluxFlow applies controlled temporal
perturbations without requiring architectural modifications. Extensive
experiments on UCF-101 and VBench benchmarks demonstrate that FluxFlow
significantly improves temporal coherence and diversity across various video
generation models, including U-Net, DiT, and AR-based architectures, while
preserving spatial fidelity. These findings highlight the potential of temporal
augmentation as a simple yet effective approach to advancing video generation
quality.","['cs.CV', 'cs.AI']","['Harold Haodong Chen', 'Haojian Huang', 'Xianfeng Wu', 'Yexin Liu', 'Yajing Bai', 'Wen-Jie Shu', 'Harry Yang', 'Ser-Nam Lim']",2025-03-19,2025-03-19,Temporal quality is a critical aspect of video generation as it ensures consistent motion and realistic dynamics across frames. However achieving high temporal coherence and diversity remains challenging. In this work we explore temporal augmentation in video generation for the first time and introduce FluxFlow for initial investigation a strategy designed to enhance temporal quality. Operating at the data level FluxFlow applies controlled temporal perturbations without requiring architectural modifications. Extensive experiments on UCF 101 and VBench benchmarks demonstrate that FluxFlow significantly improves temporal coherence and diversity across various video generation models including U Net DiT and AR based architectures while preserving spatial fidelity. These findings highlight the potential of temporal augmentation as a simple yet effective approach to advancing video generation quality.,Temporal Regularization Makes Your Video Generator Stronger,"['temporal', 'generation', 'video', 'video generation', 'fluxflow', 'quality', 'augmentation', 'coherence', 'coherence diversity', 'diversity']",Temporal quality is a critical aspect of video generation as it ensures consistent motion and realistic dynamics across frames.
2503.15940v1,UniCrossAdapter: Multimodal Adaptation of CLIP for Radiology Report Generation,"Automated radiology report generation aims to expedite the tedious and
error-prone reporting process for radiologists. While recent works have made
progress, learning to align medical images and textual findings remains
challenging due to the relative scarcity of labeled medical data. For example,
datasets for this task are much smaller than those used for image captioning in
computer vision. In this work, we propose to transfer representations from
CLIP, a large-scale pre-trained vision-language model, to better capture
cross-modal semantics between images and texts. However, directly applying CLIP
is suboptimal due to the domain gap between natural images and radiology. To
enable efficient adaptation, we introduce UniCrossAdapter, lightweight adapter
modules that are incorporated into CLIP and fine-tuned on the target task while
keeping base parameters fixed. The adapters are distributed across modalities
and their interaction to enhance vision-language alignment. Experiments on two
public datasets demonstrate the effectiveness of our approach, advancing
state-of-the-art in radiology report generation. The proposed transfer learning
framework provides a means of harnessing semantic knowledge from large-scale
pre-trained models to tackle data-scarce medical vision-language tasks. Code is
available at https://github.com/chauncey-tow/MRG-CLIP.",['cs.CV'],"['Yaxiong Chen', 'Chuang Du', 'Chunlei Li', 'Jingliang Hu', 'Yilei Shi', 'Shengwu Xiong', 'Xiao Xiang Zhu', 'Lichao Mou']",2025-03-20,2025-03-20,Automated radiology report generation aims to expedite the tedious and error prone reporting process for radiologists. While recent works have made progress learning to align medical images and textual findings remains challenging due to the relative scarcity of labeled medical data. For example datasets for this task are much smaller than those used for image captioning in computer vision. In this work we propose to transfer representations from CLIP a large scale pre trained vision language model to better capture cross modal semantics between images and texts. However directly applying CLIP is suboptimal due to the domain gap between natural images and radiology. To enable efficient adaptation we introduce UniCrossAdapter lightweight adapter modules that are incorporated into CLIP and fine tuned on the target task while keeping base parameters fixed. The adapters are distributed across modalities and their interaction to enhance vision language alignment. Experiments on two public datasets demonstrate the effectiveness of our approach advancing state of the art in radiology report generation. The proposed transfer learning framework provides a means of harnessing semantic knowledge from large scale pre trained models to tackle data scarce medical vision language tasks. Code is available at https github.com chauncey tow MRG CLIP.,UniCrossAdapter Multimodal Adaptation of CLIP for Radiology Report Generation,"['clip', 'vision', 'images', 'language', 'medical', 'radiology', 'vision language', 'data', 'datasets', 'generation']",Automated radiology report generation aims to expedite the tedious and error prone reporting process for radiologists.
2503.14926v1,Covering Cracks in Content Moderation: Delexicalized Distant Supervision for Illicit Drug Jargon Detection,"In light of rising drug-related concerns and the increasing role of social
media, sales and discussions of illicit drugs have become commonplace online.
Social media platforms hosting user-generated content must therefore perform
content moderation, which is a difficult task due to the vast amount of jargon
used in drug discussions. Previous works on drug jargon detection were limited
to extracting a list of terms, but these approaches have fundamental problems
in practical application. First, they are trivially evaded using word
substitutions. Second, they cannot distinguish whether euphemistic terms such
as ""pot"" or ""crack"" are being used as drugs or in their benign meanings. We
argue that drug content moderation should be done using contexts rather than
relying on a banlist. However, manually annotated datasets for training such a
task are not only expensive but also prone to becoming obsolete. We present
JEDIS, a framework for detecting illicit drug jargon terms by analyzing their
contexts. JEDIS utilizes a novel approach that combines distant supervision and
delexicalization, which allows JEDIS to be trained without human-labeled data
while being robust to new terms and euphemisms. Experiments on two manually
annotated datasets show JEDIS significantly outperforms state-of-the-art
word-based baselines in terms of F1-score and detection coverage in drug jargon
detection. We also conduct qualitative analysis that demonstrates JEDIS is
robust against pitfalls faced by existing approaches.",['cs.CL'],"['Minkyoo Song', 'Eugene Jang', 'Jaehan Kim', 'Seungwon Shin']",2025-03-19,2025-03-19,In light of rising drug related concerns and the increasing role of social media sales and discussions of illicit drugs have become commonplace online. Social media platforms hosting user generated content must therefore perform content moderation which is a difficult task due to the vast amount of jargon used in drug discussions. Previous works on drug jargon detection were limited to extracting a list of terms but these approaches have fundamental problems in practical application. First they are trivially evaded using word substitutions. Second they cannot distinguish whether euphemistic terms such as pot or crack are being used as drugs or in their benign meanings. We argue that drug content moderation should be done using contexts rather than relying on a banlist. However manually annotated datasets for training such a task are not only expensive but also prone to becoming obsolete. We present JEDIS a framework for detecting illicit drug jargon terms by analyzing their contexts. JEDIS utilizes a novel approach that combines distant supervision and delexicalization which allows JEDIS to be trained without human labeled data while being robust to new terms and euphemisms. Experiments on two manually annotated datasets show JEDIS significantly outperforms state of the art word based baselines in terms of F1 score and detection coverage in drug jargon detection. We also conduct qualitative analysis that demonstrates JEDIS is robust against pitfalls faced by existing approaches.,Covering Cracks in Content Moderation Delexicalized Distant Supervision for Illicit Drug Jargon Detection,"['drug', 'jedis', 'terms', 'jargon', 'content', 'detection', 'drug jargon', 'annotated', 'annotated datasets', 'approaches']",In light of rising drug related concerns and the increasing role of social media sales and discussions of illicit drugs have become commonplace online.
2503.15924v1,Towards Automatic Continual Learning: A Self-Adaptive Framework for Continual Instruction Tuning,"Continual instruction tuning enables large language models (LLMs) to learn
incrementally while retaining past knowledge, whereas existing methods
primarily focus on how to retain old knowledge rather than on selecting which
new knowledge to learn. In domain-specific contexts, maintaining data quality
and managing system constraints remain key challenges. To address these issues,
we propose an automated continual instruction tuning framework that dynamically
filters incoming data, which identify and reduce redundant data across
successive updates. Our approach utilizes a small proxy model for efficient
perplexity-based filtering, and updates the proxy to ensure that the filtering
criteria remain aligned with the evolving state of the deployed model. Compared
to existing static data selection methods, our framework can effectively handle
incrementally acquired data and shifting distributions. Additionally, it
addresses practical deployment challenges by enabling seamless model updates,
supporting version rollback and incorporating automatic checkpoint evaluation.
We evaluated the system in real-world medical scenarios. It reduced
computational costs by 66.7% and improved model performance, and achieved
autonomous updates, thus demonstrating its effectiveness for automatic
continual instruction tuning.","['cs.CL', 'cs.AI']","['Peiyi Lin', 'Fukai Zhang', 'Kai Niu', 'Hao Fu']",2025-03-20,2025-03-20,Continual instruction tuning enables large language models LLMs to learn incrementally while retaining past knowledge whereas existing methods primarily focus on how to retain old knowledge rather than on selecting which new knowledge to learn. In domain specific contexts maintaining data quality and managing system constraints remain key challenges. To address these issues we propose an automated continual instruction tuning framework that dynamically filters incoming data which identify and reduce redundant data across successive updates. Our approach utilizes a small proxy model for efficient perplexity based filtering and updates the proxy to ensure that the filtering criteria remain aligned with the evolving state of the deployed model. Compared to existing static data selection methods our framework can effectively handle incrementally acquired data and shifting distributions. Additionally it addresses practical deployment challenges by enabling seamless model updates supporting version rollback and incorporating automatic checkpoint evaluation. We evaluated the system in real world medical scenarios. It reduced computational costs by 66.7 and improved model performance and achieved autonomous updates thus demonstrating its effectiveness for automatic continual instruction tuning.,Towards Automatic Continual Learning A Self Adaptive Framework for Continual Instruction Tuning,"['data', 'model', 'updates', 'continual', 'continual instruction', 'instruction', 'instruction tuning', 'knowledge', 'tuning', 'automatic']",Continual instruction tuning enables large language models LLMs to learn incrementally while retaining past knowledge whereas existing methods primarily focus on how to retain old knowledge rather than on selecting which new knowledge to learn.
2503.17338v1,Capturing Individual Human Preferences with Reward Features,"Reinforcement learning from human feedback usually models preferences using a
reward model that does not distinguish between people. We argue that this is
unlikely to be a good design choice in contexts with high potential for
disagreement, like in the training of large language models. We propose a
method to specialise a reward model to a person or group of people. Our
approach builds on the observation that individual preferences can be captured
as a linear combination of a set of general reward features. We show how to
learn such features and subsequently use them to quickly adapt the reward model
to a specific individual, even if their preferences are not reflected in the
training data. We present experiments with large language models comparing the
proposed architecture with a non-adaptive reward model and also adaptive
counterparts, including models that do in-context personalisation. Depending on
how much disagreement there is in the training data, our model either
significantly outperforms the baselines or matches their performance with a
simpler architecture and more stable training.","['cs.AI', 'cs.LG', 'stat.ML']","['André Barreto', 'Vincent Dumoulin', 'Yiran Mao', 'Nicolas Perez-Nieves', 'Bobak Shahriari', 'Yann Dauphin', 'Doina Precup', 'Hugo Larochelle']",2025-03-21,2025-03-21,Reinforcement learning from human feedback usually models preferences using a reward model that does not distinguish between people. We argue that this is unlikely to be a good design choice in contexts with high potential for disagreement like in the training of large language models. We propose a method to specialise a reward model to a person or group of people. Our approach builds on the observation that individual preferences can be captured as a linear combination of a set of general reward features. We show how to learn such features and subsequently use them to quickly adapt the reward model to a specific individual even if their preferences are not reflected in the training data. We present experiments with large language models comparing the proposed architecture with a non adaptive reward model and also adaptive counterparts including models that do in context personalisation. Depending on how much disagreement there is in the training data our model either significantly outperforms the baselines or matches their performance with a simpler architecture and more stable training.,Capturing Individual Human Preferences with Reward Features,"['model', 'reward', 'models', 'reward model', 'training', 'preferences', 'adaptive', 'architecture', 'data', 'disagreement']",Reinforcement learning from human feedback usually models preferences using a reward model that does not distinguish between people.
2503.14786v1,SketchSplat: 3D Edge Reconstruction via Differentiable Multi-view Sketch Splatting,"Edges are one of the most basic parametric primitives to describe structural
information in 3D. In this paper, we study parametric 3D edge reconstruction
from calibrated multi-view images. Previous methods usually reconstruct a 3D
edge point set from multi-view 2D edge images, and then fit 3D edges to the
point set. However, noise in the point set may cause gaps among fitted edges,
and the recovered edges may not align with input multi-view images since the
edge fitting depends only on the reconstructed 3D point set. To mitigate these
problems, we propose SketchSplat, a method to reconstruct accurate, complete,
and compact 3D edges via differentiable multi-view sketch splatting. We
represent 3D edges as sketches, which are parametric lines and curves defined
by attributes including control points, scales, and opacity. During edge
reconstruction, we iteratively sample Gaussian points from a set of sketches
and rasterize the Gaussians onto 2D edge images. Then the gradient of the image
error with respect to the input 2D edge images can be back-propagated to
optimize the sketch attributes. Our method bridges 2D edge images and 3D edges
in a differentiable manner, which ensures that 3D edges align well with 2D
images and leads to accurate and complete results. We also propose a series of
adaptive topological operations and apply them along with the sketch
optimization. The topological operations help reduce the number of sketches
required while ensuring high accuracy, yielding a more compact reconstruction.
Finally, we contribute an accurate 2D edge detector that improves the
performance of both ours and existing methods. Experiments show that our method
achieves state-of-the-art accuracy, completeness, and compactness on a
benchmark CAD dataset.",['cs.CV'],"['Haiyang Ying', 'Matthias Zwicker']",2025-03-18,2025-03-18,Edges are one of the most basic parametric primitives to describe structural information in 3D. In this paper we study parametric 3D edge reconstruction from calibrated multi view images. Previous methods usually reconstruct a 3D edge point set from multi view 2D edge images and then fit 3D edges to the point set. However noise in the point set may cause gaps among fitted edges and the recovered edges may not align with input multi view images since the edge fitting depends only on the reconstructed 3D point set. To mitigate these problems we propose SketchSplat a method to reconstruct accurate complete and compact 3D edges via differentiable multi view sketch splatting. We represent 3D edges as sketches which are parametric lines and curves defined by attributes including control points scales and opacity. During edge reconstruction we iteratively sample Gaussian points from a set of sketches and rasterize the Gaussians onto 2D edge images. Then the gradient of the image error with respect to the input 2D edge images can be back propagated to optimize the sketch attributes. Our method bridges 2D edge images and 3D edges in a differentiable manner which ensures that 3D edges align well with 2D images and leads to accurate and complete results. We also propose a series of adaptive topological operations and apply them along with the sketch optimization. The topological operations help reduce the number of sketches required while ensuring high accuracy yielding a more compact reconstruction. Finally we contribute an accurate 2D edge detector that improves the performance of both ours and existing methods. Experiments show that our method achieves state of the art accuracy completeness and compactness on a benchmark CAD dataset.,SketchSplat 3D Edge Reconstruction via Differentiable Multi view Sketch Splatting,"['3d', 'edge', 'edges', 'images', '2d', '2d edge', '3d edges', 'set', 'edge images', 'multi']",Edges are one of the most basic parametric primitives to describe structural information in 3D.
2503.16674v1,"Through the LLM Looking Glass: A Socratic Self-Assessment of Donkeys, Elephants, and Markets","While detecting and avoiding bias in LLM-generated text is becoming
increasingly important, media bias often remains subtle and subjective, making
it particularly difficult to identify and mitigate. In this study, we assess
media bias in LLM-generated content and LLMs' ability to detect subtle
ideological bias. We conduct this evaluation using two datasets, PoliGen and
EconoLex, covering political and economic discourse, respectively. We evaluate
eight widely used LLMs by prompting them to generate articles and analyze their
ideological preferences via self-assessment. By using self-assessment, the
study aims to directly measure the models' biases rather than relying on
external interpretations, thereby minimizing subjective judgments about media
bias. Our results reveal a consistent preference of Democratic over Republican
positions across all models. Conversely, in economic topics, biases vary among
Western LLMs, while those developed in China lean more strongly toward
socialism.",['cs.CL'],"['Molly Kennedy', 'Ayyoob Imani', 'Timo Spinde', 'Hinrich Schütze']",2025-03-20,2025-03-20,While detecting and avoiding bias in LLM generated text is becoming increasingly important media bias often remains subtle and subjective making it particularly difficult to identify and mitigate. In this study we assess media bias in LLM generated content and LLMs ability to detect subtle ideological bias. We conduct this evaluation using two datasets PoliGen and EconoLex covering political and economic discourse respectively. We evaluate eight widely used LLMs by prompting them to generate articles and analyze their ideological preferences via self assessment. By using self assessment the study aims to directly measure the models biases rather than relying on external interpretations thereby minimizing subjective judgments about media bias. Our results reveal a consistent preference of Democratic over Republican positions across all models. Conversely in economic topics biases vary among Western LLMs while those developed in China lean more strongly toward socialism.,Through the LLM Looking Glass A Socratic Self Assessment of Donkeys Elephants and Markets,"['bias', 'llms', 'media', 'media bias', 'assessment', 'bias llm', 'biases', 'economic', 'generated', 'ideological']",While detecting and avoiding bias in LLM generated text is becoming increasingly important media bias often remains subtle and subjective making it particularly difficult to identify and mitigate.
2503.14493v2,State Space Model Meets Transformer: A New Paradigm for 3D Object Detection,"DETR-based methods, which use multi-layer transformer decoders to refine
object queries iteratively, have shown promising performance in 3D indoor
object detection. However, the scene point features in the transformer decoder
remain fixed, leading to minimal contributions from later decoder layers,
thereby limiting performance improvement. Recently, State Space Models (SSM)
have shown efficient context modeling ability with linear complexity through
iterative interactions between system states and inputs. Inspired by SSMs, we
propose a new 3D object DEtection paradigm with an interactive STate space
model (DEST). In the interactive SSM, we design a novel state-dependent SSM
parameterization method that enables system states to effectively serve as
queries in 3D indoor detection tasks. In addition, we introduce four key
designs tailored to the characteristics of point cloud and SSM: The
serialization and bidirectional scanning strategies enable bidirectional
feature interaction among scene points within the SSM. The inter-state
attention mechanism models the relationships between state points, while the
gated feed-forward network enhances inter-channel correlations. To the best of
our knowledge, this is the first method to model queries as system states and
scene points as system inputs, which can simultaneously update scene point
features and query features with linear complexity. Extensive experiments on
two challenging datasets demonstrate the effectiveness of our DEST-based
method. Our method improves the GroupFree baseline in terms of AP50 on ScanNet
V2 (+5.3) and SUN RGB-D (+3.2) datasets. Based on the VDETR baseline, Our
method sets a new SOTA on the ScanNetV2 and SUN RGB-D datasets.","['cs.CV', 'cs.AI']","['Chuxin Wang', 'Wenfei Yang', 'Xiang Liu', 'Tianzhu Zhang']",2025-03-18,2025-03-19,DETR based methods which use multi layer transformer decoders to refine object queries iteratively have shown promising performance in 3D indoor object detection. However the scene point features in the transformer decoder remain fixed leading to minimal contributions from later decoder layers thereby limiting performance improvement. Recently State Space Models SSM have shown efficient context modeling ability with linear complexity through iterative interactions between system states and inputs. Inspired by SSMs we propose a new 3D object DEtection paradigm with an interactive STate space model DEST . In the interactive SSM we design a novel state dependent SSM parameterization method that enables system states to effectively serve as queries in 3D indoor detection tasks. In addition we introduce four key designs tailored to the characteristics of point cloud and SSM The serialization and bidirectional scanning strategies enable bidirectional feature interaction among scene points within the SSM. The inter state attention mechanism models the relationships between state points while the gated feed forward network enhances inter channel correlations. To the best of our knowledge this is the first method to model queries as system states and scene points as system inputs which can simultaneously update scene point features and query features with linear complexity. Extensive experiments on two challenging datasets demonstrate the effectiveness of our DEST based method. Our method improves the GroupFree baseline in terms of AP50 on ScanNet V2 5.3 and SUN RGB D 3.2 datasets. Based on the VDETR baseline Our method sets a new SOTA on the ScanNetV2 and SUN RGB D datasets.,State Space Model Meets Transformer A New Paradigm for 3D Object Detection,"['method', 'ssm', 'state', 'scene', '3d', 'based', 'datasets', 'detection', 'features', 'object']",DETR based methods which use multi layer transformer decoders to refine object queries iteratively have shown promising performance in 3D indoor object detection.
2503.16068v1,PoseTraj: Pose-Aware Trajectory Control in Video Diffusion,"Recent advancements in trajectory-guided video generation have achieved
notable progress. However, existing models still face challenges in generating
object motions with potentially changing 6D poses under wide-range rotations,
due to limited 3D understanding. To address this problem, we introduce
PoseTraj, a pose-aware video dragging model for generating 3D-aligned motion
from 2D trajectories. Our method adopts a novel two-stage pose-aware
pretraining framework, improving 3D understanding across diverse trajectories.
Specifically, we propose a large-scale synthetic dataset PoseTraj-10K,
containing 10k videos of objects following rotational trajectories, and enhance
the model perception of object pose changes by incorporating 3D bounding boxes
as intermediate supervision signals. Following this, we fine-tune the
trajectory-controlling module on real-world videos, applying an additional
camera-disentanglement module to further refine motion accuracy. Experiments on
various benchmark datasets demonstrate that our method not only excels in 3D
pose-aligned dragging for rotational trajectories but also outperforms existing
baselines in trajectory accuracy and video quality.",['cs.CV'],"['Longbin Ji', 'Lei Zhong', 'Pengfei Wei', 'Changjian Li']",2025-03-20,2025-03-20,Recent advancements in trajectory guided video generation have achieved notable progress. However existing models still face challenges in generating object motions with potentially changing 6D poses under wide range rotations due to limited 3D understanding. To address this problem we introduce PoseTraj a pose aware video dragging model for generating 3D aligned motion from 2D trajectories. Our method adopts a novel two stage pose aware pretraining framework improving 3D understanding across diverse trajectories. Specifically we propose a large scale synthetic dataset PoseTraj 10K containing 10k videos of objects following rotational trajectories and enhance the model perception of object pose changes by incorporating 3D bounding boxes as intermediate supervision signals. Following this we fine tune the trajectory controlling module on real world videos applying an additional camera disentanglement module to further refine motion accuracy. Experiments on various benchmark datasets demonstrate that our method not only excels in 3D pose aligned dragging for rotational trajectories but also outperforms existing baselines in trajectory accuracy and video quality.,PoseTraj Pose Aware Trajectory Control in Video Diffusion,"['3d', 'pose', 'trajectories', 'trajectory', 'video', '10k', '3d understanding', 'accuracy', 'aligned', 'aware']",Recent advancements in trajectory guided video generation have achieved notable progress.
2503.16546v1,"A Comprehensive Survey on Architectural Advances in Deep CNNs: Challenges, Applications, and Emerging Research Directions","Deep Convolutional Neural Networks (CNNs) have significantly advanced deep
learning, driving breakthroughs in computer vision, natural language
processing, medical diagnosis, object detection, and speech recognition.
Architectural innovations including 1D, 2D, and 3D convolutional models,
dilated and grouped convolutions, depthwise separable convolutions, and
attention mechanisms address domain-specific challenges and enhance feature
representation and computational efficiency. Structural refinements such as
spatial-channel exploitation, multi-path design, and feature-map enhancement
contribute to robust hierarchical feature extraction and improved
generalization, particularly through transfer learning. Efficient preprocessing
strategies, including Fourier transforms, structured transforms, low-precision
computation, and weight compression, optimize inference speed and facilitate
deployment in resource-constrained environments. This survey presents a unified
taxonomy that classifies CNN architectures based on spatial exploitation,
multi-path structures, depth, width, dimensionality expansion, channel
boosting, and attention mechanisms. It systematically reviews CNN applications
in face recognition, pose estimation, action recognition, text classification,
statistical language modeling, disease diagnosis, radiological analysis,
cryptocurrency sentiment prediction, 1D data processing, video analysis, and
speech recognition. In addition to consolidating architectural advancements,
the review highlights emerging learning paradigms such as few-shot, zero-shot,
weakly supervised, federated learning frameworks and future research directions
include hybrid CNN-transformer models, vision-language integration, generative
learning, etc. This review provides a comprehensive perspective on CNN's
evolution from 2015 to 2025, outlining key innovations, challenges, and
opportunities.","['cs.CV', 'cs.AI', 'cs.LG', 'eess.IV']","['Saddam Hussain Khan', 'Rashid Iqbal']",2025-03-19,2025-03-19,Deep Convolutional Neural Networks CNNs have significantly advanced deep learning driving breakthroughs in computer vision natural language processing medical diagnosis object detection and speech recognition. Architectural innovations including 1D 2D and 3D convolutional models dilated and grouped convolutions depthwise separable convolutions and attention mechanisms address domain specific challenges and enhance feature representation and computational efficiency. Structural refinements such as spatial channel exploitation multi path design and feature map enhancement contribute to robust hierarchical feature extraction and improved generalization particularly through transfer learning. Efficient preprocessing strategies including Fourier transforms structured transforms low precision computation and weight compression optimize inference speed and facilitate deployment in resource constrained environments. This survey presents a unified taxonomy that classifies CNN architectures based on spatial exploitation multi path structures depth width dimensionality expansion channel boosting and attention mechanisms. It systematically reviews CNN applications in face recognition pose estimation action recognition text classification statistical language modeling disease diagnosis radiological analysis cryptocurrency sentiment prediction 1D data processing video analysis and speech recognition. In addition to consolidating architectural advancements the review highlights emerging learning paradigms such as few shot zero shot weakly supervised federated learning frameworks and future research directions include hybrid CNN transformer models vision language integration generative learning etc. This review provides a comprehensive perspective on CNN s evolution from 2015 to 2025 outlining key innovations challenges and opportunities.,A Comprehensive Survey on Architectural Advances in Deep CNNs Challenges Applications and Emerging Research Directions,"['learning', 'cnn', 'recognition', 'feature', 'language', '1d', 'analysis', 'architectural', 'attention', 'attention mechanisms']",Deep Convolutional Neural Networks CNNs have significantly advanced deep learning driving breakthroughs in computer vision natural language processing medical diagnosis object detection and speech recognition.
